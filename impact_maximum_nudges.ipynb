{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the maximum impacts for individual, local, synergistic and global nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import probability_distributions\n",
    "import maximum_nudges\n",
    "import evolutionary_algorithms as ea\n",
    "import maximum_synergistic_nudge_evolutionary as synergistic_nudge_ev\n",
    "import maximum_nudges_evolutionary as ev_max_nudges\n",
    "import nudge_non_causal\n",
    "import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook level constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUDGE_SIZE = 0.01\n",
    "PATH_TO_DISTRIBUTIONS = \"/home/joboti/azumi_derkjan/master_thesis/code/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the maximum impact of a nudge given its type the input and conditional output and nudge size\n",
    "\n",
    "The nudge sizes for individual and global are divided by 2 on purpose, since in their definitions its the \n",
    "amount subtracted AND added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_nudge_impacts(input_dists, cond_output_dists, nudge_size, nudge_type, \n",
    "                          backup_filename, parameters):\n",
    "    \"\"\"\n",
    "    Find the maximum impact of the nudges\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_dists: list of nd-arrays representing probability distributions\n",
    "    cond_output_dists: list of nd-arrays \n",
    "        Representing output distributions (the last axis) conditioned on the input \n",
    "        distributions\n",
    "    nudge_size: positive float\n",
    "    nudge_type: string\n",
    "        One of the following: {\"individual\", \"local\", \"synergistic\", \"global\"}\n",
    "    filename_to_save: string, \n",
    "        Should be a valid path\n",
    "    parameters: a dict,\n",
    "        The parameters used to find the maximum nudge\n",
    "    \n",
    "    \"\"\"\n",
    "    impacts = []\n",
    "    for input_dist, cond_output in zip(input_dists, cond_output_dists):\n",
    "        print(\"count {}\".format(len(impacts)))\n",
    "        if nudge_type == \"individual\":\n",
    "            impact = maximum_nudges.find_max_impact_individual_nudge_exactly(\n",
    "                input_dist, cond_output, nudge_size/2.0, True\n",
    "            )\n",
    "        elif nudge_type == \"local\":\n",
    "            max_local_nudge = ev_max_nudges.find_maximum_local_nudge(\n",
    "                input_dist, cond_output, nudge_size, \n",
    "                local_evolutionary_params, verbose=True\n",
    "            )\n",
    "            impact = max_local_nudge.score\n",
    "            nudge_vectors = [\n",
    "                weight*nudge.genes \n",
    "                for nudge, weight in zip(individual_nudges, max_local_nudge.weights)\n",
    "            ]\n",
    "            new_dist = nudge_non_causal.nudge_local(\n",
    "                input_dist, [0, 1], 0.01, nudge_vectors \n",
    "            )\n",
    "            l1_norm_to_old_distribution = np.sum(np.absolute(input_dist-new_dist))\n",
    "            if abs(l1_norm_to_old_distribution-NUDGE_SIZE) > 10**(-7):\n",
    "                print(\"WARNING size of nudge {}\".format(l1_norm_to_old_distribution))\n",
    "        elif nudge_type == \"synergistic\":\n",
    "            max_synergistic_nudge = synergistic_nudge_ev.find_synergistic_nudge_with_max_impact(\n",
    "                input_dist, cond_output, nudge_size, parameters\n",
    "            )\n",
    "            impact = max_synergistic_nudge.score\n",
    "            new_distribution = max_synergistic_nudge.new_distribution\n",
    "            l1_norm_to_old_distribution = np.sum(np.absolute(\n",
    "                input_dist-max_synergistic_nudge.new_distribution\n",
    "            ))\n",
    "            if abs(l1_norm_to_old_distribution-NUDGE_SIZE) > 10**(-7):\n",
    "                print(\"WARNING size of nudge {}\".format(l1_norm_to_old_distribution))\n",
    "        elif nudge_type == \"global\":\n",
    "            _, _, max_global_nudge_impact = maximum_nudges.find_max_control_impact(\n",
    "                input_dist, cond_output, nudge_size/2.0\n",
    "            )\n",
    "            impact = max_global_nudge_impact\n",
    "        else:\n",
    "            raise ValueError(\"provide a valid nudge type\")\n",
    "            \n",
    "        print(\"the max nudge impact {}\".format(impact))\n",
    "        impacts.append(impact)\n",
    "        with open(backup_filename, 'w') as f:\n",
    "            json.dump(impacts, f, indent=4)\n",
    "        \n",
    "    return impacts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the data and run the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First for system distributions with limited entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_MAX_ENTROPY_SIZE = 90\n",
    "NUMBER_OF_VARS = 4\n",
    "NUMBER_OF_STATES = 3\n",
    "FILENAME_FORMAT_INPUT = \"input_dist_{}.npy\"\n",
    "FILENAME_FORMAT_OUTPUT = \"cond_output_dist_{}.npy\"\n",
    "DIST_START = 100\n",
    "DIST_END = 200\n",
    "NUDGE_TYPE = \"synergistic\"\n",
    "\n",
    "distribution_numbers = list(range(DIST_START, DIST_END, 1))\n",
    "if NUDGE_TYPE == \"global\" or NUDGE_TYPE ==\"individual\":\n",
    "    parameter_file = None\n",
    "elif NUDGE_TYPE == \"local\":\n",
    "    parameter_folder = \"local_nudge_parameters/\"\n",
    "    parameter_file_name = \"entropy_percentage{}_{}vars_{}states_dist_{}_{}.json\".format(\n",
    "        PERCENTAGE_MAX_ENTROPY_SIZE, NUMBER_OF_VARS, NUMBER_OF_STATES, DIST_START, DIST_END\n",
    "    )    \n",
    "    parameter_file = parameter_folder + parameter_file_name \n",
    "elif NUDGE_TYPE == \"synergistic\":\n",
    "    parameter_folder = \"synergistic_nudge_parameters/\"\n",
    "    parameter_file_name = \"entropy_percentage{}_{}vars_{}states_dist_{}_{}.json\".format(\n",
    "        PERCENTAGE_MAX_ENTROPY_SIZE, NUMBER_OF_VARS, NUMBER_OF_STATES, DIST_START, DIST_END\n",
    "    )\n",
    "    parameter_file = parameter_folder + parameter_file_name \n",
    "else:\n",
    "    raise ValueError(\"provide a valid nudge type\")\n",
    "    \n",
    "if parameter_file is None:\n",
    "    parameters = None\n",
    "else:\n",
    "    with open(parameter_file) as f:\n",
    "        parameters = json.load(f)\n",
    "\n",
    "backup_filename = (\"data_experiments/\" + \n",
    "    \"backup_impacts_{}var_{}states_{}entropy_{}_nudge_dists{}-{}.json\".format(\n",
    "        NUMBER_OF_VARS, NUMBER_OF_STATES, PERCENTAGE_MAX_ENTROPY_SIZE, NUDGE_TYPE, DIST_START, DIST_END \n",
    "    )\n",
    ")\n",
    "path_to_limited_entropy_system_dists = (\n",
    "    PATH_TO_DISTRIBUTIONS + \"system_distributions/\" \n",
    "    + \"limited_entropy/\"\n",
    ")\n",
    "\n",
    "input_dists = get_data.get_system_distributions_limited_entropy(\n",
    "    path_to_limited_entropy_system_dists, PERCENTAGE_MAX_ENTROPY_SIZE,\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, FILENAME_FORMAT_INPUT, \n",
    "    distribution_numbers\n",
    ")\n",
    "output_dists = get_data.get_system_distributions_limited_entropy(\n",
    "    path_to_limited_entropy_system_dists, PERCENTAGE_MAX_ENTROPY_SIZE,\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, FILENAME_FORMAT_OUTPUT, \n",
    "    distribution_numbers\n",
    ")\n",
    "\n",
    "impacts = get_max_nudge_impacts(\n",
    "    input_dists, output_dists, NUDGE_SIZE, NUDGE_TYPE, \n",
    "    backup_filename, parameters\n",
    ")\n",
    "print(\"mean impact {}\".format(np.mean(impacts)))\n",
    "print(impacts)\n",
    "\n",
    "filename_to_save_impacts =  \"impacts_{}var_{}states_{}entropy_{}_nudge_dists{}-{}.json\".format(\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, PERCENTAGE_MAX_ENTROPY_SIZE, NUDGE_TYPE, DIST_START, DIST_END \n",
    ")\n",
    "with open(\"data_experiments/\" + filename_to_save_impacts, 'w') as f:\n",
    "    json.dump(impacts, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First generate a generic input distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution parameters\n",
    "input_variables = 2\n",
    "number_of_states = 5\n",
    "\n",
    "#generate both input and conditional output with Dirichlet weights\n",
    "distribution_shape = [number_of_states]*input_variables\n",
    "total_number_of_states = reduce(lambda x,y: x*y, distribution_shape)\n",
    "input_dist = np.random.dirichlet([1]*total_number_of_states)\n",
    "input_dist = np.reshape(input_dist, distribution_shape)\n",
    "cond_shape = [number_of_states]*(input_variables+1)\n",
    "cond_output = [\n",
    "    probability_distributions.compute_joint_uniform_random((number_of_states,))\n",
    "    for i in range(number_of_states**(input_variables))\n",
    "]\n",
    "cond_output = np.array(cond_output)\n",
    "cond_output = np.reshape(cond_output, cond_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the generated input and conditional output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/joboti/azumi_derkjan/master_thesis/code/\"\n",
    "\n",
    "\n",
    "def generate_distributions(path_to_files, file_format, number_of_distributions):\n",
    "    for i in range(number_of_distributions):\n",
    "        file_name = path_to_files + file_format.format(i)\n",
    "        with open(file_name, 'rb') as f:\n",
    "            yield np.load(f)\n",
    "            \n",
    "def generate_input_and_conditional_output(input_type, parameters, cond_output_type=\"dirichlet\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_type: string in set {\"dirichlet\", \"entropy_0.5\", \"entropy_0.75\"}\n",
    "    parameters: dict\n",
    "    cond_output: \n",
    "    \n",
    "    Returns: a dict with keys:\n",
    "    -------\n",
    "    number_of_var: a number\n",
    "    number_of_states: a number\n",
    "    input_dist: nd-array\n",
    "    cond_output: nd-array\n",
    "    \n",
    "    \"\"\"\n",
    "    if input_type == \"dirichlet\":\n",
    "        input_dirichlet_path = PATH + INPUT_FOLDER + DIRICHLET_FOLDER_INPUT\n",
    "    elif input_type == \"entropy_0.75\":\n",
    "        input_dirichlet_path = PATH + INPUT_FOLDER + ENTROPY_MEDIUM_FOLDER_INPUT\n",
    "    elif input_type == \"entropy_0.5\":\n",
    "        input_dirichlet_path = PATH + INPUT_FOLDER + ENTROPY_LOW_FOLDER_INPUT\n",
    "    else:\n",
    "        raise ValueError(\"supply valid input distribution type\")\n",
    "\n",
    "    cond_output_dirichlet_path = PATH + COND_OUTPUT_FOLDER + DIRICHLET_FOLDER_COND_OUTPUT\n",
    "\n",
    "    min_inputs = parameters[\"min_number_inputs\"]\n",
    "    max_inputs = parameters[\"max_number_inputs\"]\n",
    "    number_of_states = parameters[\"number_of_states\"]\n",
    "    for number_of_var in range(min_inputs, max_inputs, 1):\n",
    "        path_to_input_files = (\n",
    "            input_dirichlet_path \n",
    "            + FOLDER_FORMAT_INPUT.format(number_of_var, number_of_states)\n",
    "        )\n",
    "        path_to_cond_output_files = (\n",
    "            cond_output_dirichlet_path \n",
    "            + FOLDER_FORMAT_CONDITIONAL.format(number_of_var, number_of_states)\n",
    "        )\n",
    "        input_generator = generate_distributions(\n",
    "            path_to_input_files, FILE_FORMAT_INPUT, \n",
    "            parameters[\"number_of_distributions\"]\n",
    "        )\n",
    "        cond_output_generator = generate_distributions(\n",
    "            path_to_cond_output_files, FILE_FORMAT_COND_OUTPUT, \n",
    "            parameters[\"number_of_distributions\"]\n",
    "        )\n",
    "        input_shape = [number_of_states]*number_of_var\n",
    "        cond_output_shape = [number_of_states]*(number_of_var+1)\n",
    "        for sample in range(parameters[\"number_of_distributions\"]):\n",
    "            input_dist = next(input_generator)\n",
    "            input_dist = np.reshape(input_dist, input_shape)\n",
    "            cond_output = next(cond_output_generator)\n",
    "            cond_output = np.reshape(cond_output, cond_output_shape)\n",
    "            yield {\n",
    "                \"number_of_vars\": number_of_var,\n",
    "                \"number_of_states\": parameters[\"number_of_states\"],\n",
    "                \"input_dist\": input_dist,\n",
    "                \"cond_output\": cond_output\n",
    "            }\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
