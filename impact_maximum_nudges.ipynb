{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the maximum impacts for individual, local, synergistic and global nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import probability_distributions\n",
    "import maximum_nudges\n",
    "import evolutionary_algorithms as ea\n",
    "import maximum_nudges_evolutionary as ev_max_nudges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook level constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUDGE_SIZE = 0.01\n",
    "NUMBER_OF_STATES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First generate a generic input distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distribution parameters\n",
    "input_variables = 2\n",
    "number_of_states = 5\n",
    "\n",
    "#generate both input and conditional output with Dirichlet weights\n",
    "distribution_shape = [number_of_states]*input_variables\n",
    "total_number_of_states = reduce(lambda x,y: x*y, distribution_shape)\n",
    "input_dist = np.random.dirichlet([1]*total_number_of_states)\n",
    "input_dist = np.reshape(input_dist, distribution_shape)\n",
    "cond_shape = [number_of_states]*(input_variables+1)\n",
    "cond_output = [\n",
    "    probability_distributions.compute_joint_uniform_random((number_of_states,))\n",
    "    for i in range(number_of_states**(input_variables))\n",
    "]\n",
    "cond_output = np.array(cond_output)\n",
    "cond_output = np.reshape(cond_output, cond_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the generated input and conditional output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"/home/derkjan/Documents/academics_UVA/master_thesis/code/\"\n",
    "INPUT_FOLDER = \"input_distributions/\"\n",
    "COND_OUTPUT_FOLDER = \"conditional_output_distributions/\"\n",
    "FOLDER_FORMAT_INPUT = \"{}var_{}states/\"\n",
    "FOLDER_FORMAT_CONDITIONAL = \"{}var_{}states/\"\n",
    "FILE_FORMAT_INPUT = \"dist_{}.npy\"\n",
    "FILE_FORMAT_COND_OUTPUT = \"cond_dist_{}.npy\"\n",
    "\n",
    "DIRICHLET_FOLDER_INPUT = \"dirichlet/\"\n",
    "ENTROPY_LOW_FOLDER_INPUT = \"entropy_0.5/\"\n",
    "ENTROPY_MEDIUM_FOLDER_INPUT = \"entropy_0.75/\"\n",
    "\n",
    "DIRICHLET_FOLDER_COND_OUTPUT = \"dirichlet/\"\n",
    "\n",
    "\n",
    "def generate_distributions(path_to_files, file_format, number_of_distributions):\n",
    "    for i in range(number_of_distributions):\n",
    "        file_name = path_to_files + file_format.format(i)\n",
    "        with open(file_name, 'rb') as f:\n",
    "            yield np.load(f)\n",
    "            \n",
    "def generate_input_and_conditional_output(input_type, parameters, cond_output_type=\"dirichlet\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_type: string in set {\"dirichlet\", \"entropy_0.5\", \"entropy_0.75\"}\n",
    "    parameters: dict\n",
    "    cond_output: \n",
    "    \n",
    "    Returns: a dict with keys:\n",
    "    -------\n",
    "    number_of_var: a number\n",
    "    number_of_states: a number\n",
    "    input_dist: nd-array\n",
    "    cond_output: nd-array\n",
    "    \n",
    "    \"\"\"\n",
    "    if input_type == \"dirichlet\":\n",
    "        input_dirichlet_path = PATH + INPUT_FOLDER + DIRICHLET_FOLDER_INPUT\n",
    "    elif input_type == \"entropy_0.75\":\n",
    "        input_dirichlet_path = PATH + INPUT_FOLDER + ENTROPY_MEDIUM_FOLDER_INPUT\n",
    "    elif input_type == \"entropy_0.5\":\n",
    "        input_dirichlet_path = PATH + INPUT_FOLDER + ENTROPY_LOW_FOLDER_INPUT\n",
    "    else:\n",
    "        raise ValueError(\"supply valid input distribution type\")\n",
    "\n",
    "    cond_output_dirichlet_path = PATH + COND_OUTPUT_FOLDER + DIRICHLET_FOLDER_COND_OUTPUT\n",
    "\n",
    "    min_inputs = parameters[\"min_number_inputs\"]\n",
    "    max_inputs = parameters[\"max_number_inputs\"]\n",
    "    number_of_states = parameters[\"number_of_states\"]\n",
    "    for number_of_var in range(min_inputs, max_inputs, 1):\n",
    "        path_to_input_files = (\n",
    "            input_dirichlet_path \n",
    "            + FOLDER_FORMAT_INPUT.format(number_of_var, number_of_states)\n",
    "        )\n",
    "        path_to_cond_output_files = (\n",
    "            cond_output_dirichlet_path \n",
    "            + FOLDER_FORMAT_CONDITIONAL.format(number_of_var, number_of_states)\n",
    "        )\n",
    "        input_generator = generate_distributions(\n",
    "            path_to_input_files, FILE_FORMAT_INPUT, \n",
    "            parameters[\"number_of_distributions\"]\n",
    "        )\n",
    "        cond_output_generator = generate_distributions(\n",
    "            path_to_cond_output_files, FILE_FORMAT_COND_OUTPUT, \n",
    "            parameters[\"number_of_distributions\"]\n",
    "        )\n",
    "        input_shape = [number_of_states]*number_of_var\n",
    "        cond_output_shape = [number_of_states]*(number_of_var+1)\n",
    "        for sample in range(parameters[\"number_of_distributions\"]):\n",
    "            input_dist = next(input_generator)\n",
    "            input_dist = np.reshape(input_dist, input_shape)\n",
    "            cond_output = next(cond_output_generator)\n",
    "            cond_output = np.reshape(cond_output, cond_output_shape)\n",
    "            yield {\n",
    "                \"number_of_vars\": number_of_var,\n",
    "                \"number_of_states\": parameters[\"number_of_states\"],\n",
    "                \"input_dist\": input_dist,\n",
    "                \"cond_output\": cond_output\n",
    "            }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_distributions = {\n",
    "    \"max_number_inputs\": 6,\n",
    "    \"min_number_inputs\": 1,\n",
    "    \"number_of_states\": 5,\n",
    "    \"number_of_distributions\": 100\n",
    "}\n",
    "\n",
    "generator = generate_input_and_conditional_output(\n",
    "    'dirichlet', parameters_distributions, cond_output_type=\"dirichlet\"\n",
    ")\n",
    "\n",
    "for dist_dict in generator:\n",
    "    a = dist_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define the function to find max impact local nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimum_local_nudge(input_dist, cond_output, number_of_input_variables, \n",
    "                             number_of_states, nudge_size, parameters):\n",
    "    \"\"\"optimize local nudge\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_dist:nd-array\n",
    "    cond_output: nd-array, one axis more than input_dist\n",
    "    \n",
    "    \"\"\"\n",
    "    local_nudges = []\n",
    "    for _ in range(parameters[\"population_size\"]):\n",
    "        new_local_nudge = ev_max_nudges.LocalNudge.create_local_nudge(\n",
    "            parameters[\"nudged_vars_to_states\"], nudge_size, \n",
    "            parameters[\"mutation_size_weights\"], parameters[\"start_mutation_size\"],\n",
    "            parameters[\"change_mutation_size\"], timestamp=0\n",
    "        )\n",
    "        local_nudges.append(new_local_nudge)\n",
    "\n",
    "    for local_nudge in local_nudges:\n",
    "        local_nudge.evaluate(input_dist, cond_output)\n",
    "\n",
    "    initial_impact = ea.sort_individuals(local_nudges)[0].score\n",
    "\n",
    "    #start the optimization process\n",
    "    find_max_local_nudge = ev_max_nudges.FindMaximumLocalNudge(\n",
    "        input_dist, cond_output, nudge_size, \n",
    "        parameters[\"generational\"], parameters[\"number_of_children\"], \n",
    "        parameters[\"parent_selection_mode\"]\n",
    "    )\n",
    "    max_local_nudge_individual = find_max_local_nudge.get_max_nudge(\n",
    "        local_nudges, parameters[\"number_of_generations\"]\n",
    "    )\n",
    "    max_impact = max_local_nudge_individual.score \n",
    "    print(\"local nudge: initial impact {} max impact {}\".format(initial_impact, max_impact))\n",
    "    return max_impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: [-0.0029856260217090147, -0.0036625968978055978]}\n"
     ]
    }
   ],
   "source": [
    "ev_max_nudges.TEST = False\n",
    "\n",
    "parameters = {\n",
    "    \"number_of_generations\": 250, \n",
    "    \"population_size\": 10,\n",
    "    \"number_of_children\": 20, \n",
    "    \"generational\": True,\n",
    "    \"mutation_size\": NUDGE_SIZE/4,\n",
    "    \"parent_selection_mode\": \"rank_exponential\",\n",
    "    \"mutation_size_weights\": 0.025,\n",
    "    \"start_mutation_size\": NUDGE_SIZE/7.5,\n",
    "}\n",
    "parameters[\"change_mutation_size\"] = parameters[\"start_mutation_size\"]/12\n",
    "parameters[\"nudged_vars_to_states\"] = None\n",
    "\n",
    "parameters_distributions = {\n",
    "    \"max_number_inputs\": 6,\n",
    "    \"min_number_inputs\": 2,\n",
    "    \"number_of_states\": 5,\n",
    "    \"number_of_distributions\": 100\n",
    "}\n",
    "\n",
    "generator = generate_input_and_conditional_output(\n",
    "    'dirichlet', parameters_distributions, cond_output_type=\"dirichlet\"\n",
    ")\n",
    "\n",
    "#change file name before turning run on\n",
    "RUN = False\n",
    "FILE_NAME = \"max_impact_local_nudges_dirichlet2.json\"\n",
    "if RUN:\n",
    "    max_local_impact_dict = {}\n",
    "    prev_number_of_vars = -1\n",
    "    for count, dist_dict in enumerate(generator):\n",
    "        number_of_vars = dist_dict[\"number_of_vars\"]\n",
    "        number_of_states = dist_dict[\"number_of_states\"]\n",
    "        if number_of_vars != len(dist_dict[\"input_dist\"].shape):\n",
    "            print(\"WARNING in sample {} input dist has weird distribution\".format(count))\n",
    "        if number_of_vars != prev_number_of_vars:\n",
    "            prev_number_of_vars = number_of_vars \n",
    "            print(\"the number of vars {}\".format(number_of_vars))\n",
    "        #print(dist_dict[\"cond_output\"].shape)\n",
    "        parameters[\"nudged_vars_to_states\"] = {\n",
    "            nudged_var:number_of_states for nudged_var in range(number_of_vars)\n",
    "        }\n",
    "        max_impact = find_optimum_local_nudge(\n",
    "            dist_dict[\"input_dist\"], dist_dict[\"cond_output\"], number_of_vars,\n",
    "            number_of_states, NUDGE_SIZE, parameters=parameters\n",
    "        )\n",
    "        if number_of_vars in max_local_impact_dict:\n",
    "            max_local_impact_dict[number_of_vars].append(max_impact)\n",
    "        else:\n",
    "            max_local_impact_dict[number_of_vars] = [max_impact]\n",
    "\n",
    "        if (count+1)%5==0 and count != 0:\n",
    "            with open(FILE_NAME, 'w') as f:\n",
    "                json.dump(max_local_impact_dict, f, indent=4)\n",
    "                \n",
    "    with open(FILE_NAME, 'w') as f:\n",
    "        json.dump(max_local_impact_dict, f, indent=4)\n",
    "            \n",
    "print(max_local_impact_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the maximum individual impact evolutionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the maximum impact of an individual nudge exactly\n",
    "\n",
    "Due to different definitions of nudge size used, the nudge size needs to be divided by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the actual maximum individual nudge 0.00170966015807\n"
     ]
    }
   ],
   "source": [
    "def find_max_impact_individual_nudge_exactly(input_dist, cond_output, nudge_size):\n",
    "    new_input_dist = np.copy(input_dist)\n",
    "    max_impacts = []\n",
    "    for i in range(len(new_input_dist.shape)):\n",
    "        new_input_dist = np.swapaxes(new_input_dist, i,\n",
    "                                     len(new_input_dist.shape)-1)\n",
    "        max_impact = maximum_nudges.find_maximum_local_nudge(\n",
    "            new_input_dist, cond_output, nudge_size/2\n",
    "        )\n",
    "        max_impacts.append(max_impact)\n",
    "        new_input_dist = np.swapaxes(new_input_dist, i,\n",
    "                                     len(new_input_dist.shape)-1)\n",
    "        \n",
    "        return max(max_impacts)\n",
    "    \n",
    "max_impact = find_max_impact_individual_nudge_exactly(input_dist, cond_output, NUDGE_SIZE/2)\n",
    "print(\"the actual maximum individual nudge {}\".format(max_impact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "the number of vars 1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "the number of vars 2\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "the number of vars 3\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "the number of vars 4\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "the number of vars 5\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "the number of vars 6\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "{1: [0.002869980638571158, 0.002169285477040022, 0.0035808422126994187, 0.0035654225239459434, 0.0027033736880852314, 0.0033994825140872494, 0.0032391054510735218, 0.002757913774295114, 0.0034361881020422741, 0.00361568315274259, 0.0037654164995108985, 0.0028673101979885614, 0.0044499691569279652, 0.0034748688909535504, 0.0036615639735057062, 0.0036060728662983253, 0.0035358856959060627, 0.0031501643528031096, 0.002761603364405969, 0.0036561580319108365, 0.0029378347971284525, 0.0037794790684181558, 0.0033979392510503437, 0.0029686812890558278, 0.0037022255160396702, 0.0039224014728161142, 0.0031290339164652204, 0.0035580831507387055, 0.0040464932983326866, 0.0034007537062885288, 0.0027279737128037482, 0.0035418894539833382, 0.0035045615488586025, 0.0018339816865144986, 0.0035516301313285627, 0.0025002677468204592, 0.00398914475212172, 0.0031805433837213183, 0.0032834565407300568, 0.0032475476845783774, 0.0033839757131908631, 0.0037658291288527731, 0.0029655523012631826, 0.0034810343744358821, 0.0037109603394240125, 0.0030608639599223044, 0.0036207305203070986, 0.0035173894463882451, 0.0029629024675259887, 0.0024760288367207148, 0.003390593162524577, 0.003041514872349963, 0.0031786067788041874, 0.0028893720345036901, 0.0031988645448900619, 0.0036419991985507435, 0.0032617547458508415, 0.0023857613024473329, 0.0022398045757589264, 0.0029787770892292596, 0.0035734597067082698, 0.0030737560227647415, 0.0037964291900597228, 0.0033962711916763182, 0.0036053332227777299, 0.0022176342775839688, 0.0022238581407687244, 0.0027117451373922085, 0.0032523798521457239, 0.0038249843808986429, 0.0028957345150839872, 0.0029857554047151356, 0.0033017566646299699, 0.0040202425317148582, 0.0037464991194766347, 0.0040578865721571725, 0.0035406523493211363, 0.0028266324671732566, 0.0035172844554785818, 0.003036647890074678, 0.0026504940904544336, 0.002855874581465303, 0.0027250277826367684, 0.0028607372603578068, 0.0029089781225443419, 0.002333593191257415, 0.0029504286259276536, 0.0030123509297721586, 0.0042594656150929224, 0.0029527350013892639, 0.0036346540769480015, 0.0032895753769626953, 0.0030953597223029854, 0.0034897656811488671, 0.004763790748704126, 0.0032041521008868796, 0.0036072203438088286, 0.0025551158038498948, 0.0028919000981496744, 0.0029527112840737431], 2: [0.0013036341385248211, 0.0017673900242042577, 0.0016446912779908244, 0.0015026641763842012, 0.0018555686820451583, 0.0013243668128579541, 0.0016876351704459215, 0.0025373555469787776, 0.0016229544538939791, 0.0016599892135905586, 0.001780984922377802, 0.0017519435067696407, 0.0019500911362122474, 0.0015391510062692474, 0.0013596025480810407, 0.0015107322202037462, 0.0018524127359365538, 0.0021196299742525259, 0.0015226879751932371, 0.0018104704239539026, 0.0023263357560403286, 0.0017520523994877042, 0.0015918562652496812, 0.00198424242273346, 0.0011200437786098925, 0.0011756597258663656, 0.0016281277339167787, 0.0018666474903419395, 0.0014725443567491319, 0.001977332087773401, 0.0013701568397067533, 0.0014611145146094689, 0.0021213112452630411, 0.0019837198959881614, 0.0012130261711518736, 0.0013262697072335837, 0.001482284651836231, 0.0014391801873028173, 0.0022346659056293947, 0.0010601509037434901, 0.0024412103088727209, 0.0012737114069129129, 0.0018657752537305471, 0.0016243078851295866, 0.0014765094830602944, 0.0017845898485671359, 0.0017990215633918055, 0.0021418010318863204, 0.0014198299575336494, 0.0018059273065638161, 0.0018253223313187189, 0.0015908467971300351, 0.00186198660236715, 0.0018409400933704718, 0.0016256025490579897, 0.0016438316495508767, 0.0013438110036872288, 0.0011880050624179779, 0.0014838320799083582, 0.0018393398519816386, 0.0017836421188359658, 0.0016416309598493919, 0.0017241816125371297, 0.001610246671735765, 0.0018426864579886171, 0.0016694053876673194, 0.0021555470145910591, 0.0015231482541491381, 0.0017677251334463503, 0.0022319462424437659, 0.0011473428528059994, 0.0015300209324537806, 0.001568688241109058, 0.0010416780606268862, 0.0018926950657814014, 0.0019853211664228312, 0.0014950853301939383, 0.0016317671650911561, 0.0011998492662166032, 0.0015186861752343691, 0.0013448431315417517, 0.0018887276347977187, 0.0017487477714080372, 0.00120048483185899, 0.0012035658945597457, 0.0018785949565628681, 0.0015317239111429081, 0.0016137634679951299, 0.0016954896734797341, 0.0013496854502101756, 0.0019983979185372843, 0.001259340670915146, 0.0016757863275741807, 0.0014812741073919333, 0.0017187904279259458, 0.0013860556184884557, 0.0011560465295254241, 0.0021700966243123686, 0.0015739644507302367, 0.0017576228585183509], 3: [0.00072645550145436911, 0.00084887153312491049, 0.00080662611593862964, 0.00089160217360085951, 0.00048106940194579477, 0.00062035844487705165, 0.00065505650573540093, 0.0007033891934531951, 0.0010248152034322243, 0.0006749034511275043, 0.00054592858687147329, 0.00079024919297725324, 0.00061187447870440304, 0.000968738961978671, 0.000704370872356143, 0.00079342142926670323, 0.00055078716302172205, 0.00084836234004163631, 0.00062961518090445475, 0.00090794171253039189, 0.00061397299480874814, 0.00084745313891152905, 0.0008382912577203827, 0.00079742370608514176, 0.0010546757834880762, 0.00056468572910246817, 0.00075596109445266377, 0.00074389644179376061, 0.0008902638695715418, 0.00080594389449750302, 0.00085213106562635169, 0.00099309519184104201, 0.00098411571223641593, 0.00077095738061496864, 0.00077670184064829954, 0.00079087913333655163, 0.00080964952790174907, 0.00066268332607363647, 0.00052879409129378315, 0.00075596980623180972, 0.00072028638734543328, 0.00097174097292176389, 0.00067328497718280051, 0.0007580346914239786, 0.00060463095524287047, 0.0007087505685019833, 0.00047571992212584187, 0.00069457208668843558, 0.00080738116659701854, 0.00058824788105967993, 0.00081652759607170734, 0.00074183750091261821, 0.00088827309400699573, 0.0009196832523683244, 0.00084474560040464716, 0.00078305913901112749, 0.00062115072459497614, 0.00085799349801219229, 0.00065653478625741449, 0.00078589586572479393, 0.0010730689175884084, 0.00092646586931269964, 0.00053054985072147585, 0.00049540123411076237, 0.00068333395274132523, 0.00072349735941843721, 0.00092168638528065093, 0.00077347602732141482, 0.00082878473855936118, 0.00099767266038545857, 0.00083730249587122239, 0.00093899048998338612, 0.00060109028918693469, 0.0008117548552793708, 0.00071768987799045658, 0.00067445929334278233, 0.00074006513266693965, 0.00080482950796324445, 0.00098670018765153566, 0.00048286332696617678, 0.0007677457654711046, 0.00067017245384533644, 0.00084503165218185138, 0.00090451524988450485, 0.0008169178280856799, 0.00085774183464624651, 0.00055159748983178085, 0.00084566147035178155, 0.00051376646756501592, 0.00066033600804100588, 0.0010430073819486275, 0.00073228433839023243, 0.00076003141397208837, 0.00053777774410575067, 0.00084839152841994494, 0.00097011927523370624, 0.0008802570657871591, 0.0010470337773556078, 0.000927616721801133, 0.00074504132494229085], 4: [0.00036797780828097483, 0.00035196914702887187, 0.0003478034931616427, 0.00036804072528975765, 0.00051128705171757404, 0.00035483279591066346, 0.00030986753477206855, 0.00036034614442265439, 0.00037647256384937657, 0.00034934754809516362, 0.00037706957447166138, 0.00028244070809642141, 0.00040215554603757677, 0.00033757118255566112, 0.00037549577486198533, 0.00026982567796339637, 0.00034308492278331678, 0.00038872822787507468, 0.00024955909018393291, 0.00028415473522942704, 0.0003645534522356794, 0.00037388175133097655, 0.00028019293820398766, 0.00034336228557256256, 0.00027451131279196124, 0.00037881919957226184, 0.0003811286783657072, 0.00037679904216792912, 0.00043055966296676889, 0.0003883754732899767, 0.00034849828123148237, 0.00032044608716713777, 0.0002281603926505871, 0.00030932706570127436, 0.0003996516735473597, 0.00038688748337124276, 0.00022489633415418038, 0.00032710825588038903, 0.00037470033116628385, 0.00050005846482872082, 0.00039712187321097213, 0.0004574550929892772, 0.00029175383025254316, 0.00039970859354390953, 0.00022916052651085267, 0.00029975815485675997, 0.00029383160285734666, 0.00039549220437258933, 0.00034908808158902124, 0.00033686946871399373, 0.000365527440883578, 0.00037524031773039391, 0.00031385761333934488, 0.00036388906907978209, 0.00035493955467959259, 0.00031229214460310649, 0.00036190850316451611, 0.00026047460814117816, 0.00028976922286337798, 0.00034077672756841398, 0.00043347382519972309, 0.00039219167230613677, 0.00036752505411312712, 0.00047990561888288421, 0.00045585451912772481, 0.00044014963808406955, 0.00028636074278180833, 0.00033292770351843796, 0.0003251523763279574, 0.00041560009010150798, 0.00049240612707985329, 0.00036746785419486063, 0.00026028523966035289, 0.00031449860209079012, 0.00024668800649404316, 0.0002652796720075259, 0.00018549133779916828, 0.00039959319796430977, 0.00034766508854574012, 0.00040107106382795212, 0.00039145094962854507, 0.000317338675385826, 0.00038539950918463003, 0.00045589548108290924, 0.00028908504661119132, 0.00023405501770660977, 0.00030590794580882878, 0.00040695011146270115, 0.00026694134006200495, 0.00025398830388298596, 0.00035666141926404924, 0.00032707234329346226, 0.00043793214912402864, 0.00036589331366029983, 0.00026323472874267769, 0.00034796008210981181, 0.00022610239417244577, 0.00025887414093003476, 0.00047502781684891375, 0.00036819161467903735], 5: [0.00013301335900297407, 0.00011835371567397995, 0.00013395061072029235, 0.00014974272984254135, 0.00015538249981156011, 0.00017044050067796578, 0.00019551013250634891, 0.00013260145684407222, 0.00015946159641484471, 0.00015768395895487443, 0.00013622285688551835, 0.00012770512121036692, 0.00016636942506755204, 0.00015447608615473516, 0.00017494676846884107, 0.00014544387058406809, 0.00012724278502998705, 0.00019612979197359935, 0.00019030092917190502, 0.00013203705676770441, 0.00014698025395960715, 0.0001575852984501052, 0.00017583974687585739, 9.8933050270076563e-05, 0.00011811518642084205, 0.00014353306496309951, 0.00019787786058890515, 0.00014580529832832731, 0.0001340118788303683, 0.00013382582090263261, 0.00010790877349431616, 0.0001771660535071691, 0.00020778176942617667, 0.00011617683720070943, 0.00013230216050023967, 0.00011539642146683076, 0.0001846538498389341, 0.00012532380398213146, 0.00014864462155204727, 0.00016689225450750803, 0.00011887639974394559, 0.00015858280639960843, 0.00017281956557467124, 0.00017254909509586356, 0.00016639822653055023, 0.00017066942245986709, 0.000130594905966341, 0.00015157999091159387, 0.00015385198660001689, 0.00019860285090446774, 0.00016469067604920506, 0.00027815543561627594, 0.00018293858524346247, 0.00011437730345261095, 0.00016711886627603247, 0.00014642943825377344, 0.00010719355826520132, 0.00013664114476789684, 0.00022521533863706855, 0.00017584672978483685, 0.0001318115707609118, 0.00016020921251239518, 0.00014680443300567521, 0.00014833423556791009, 0.0001449114651519641, 0.00013872210068936356, 0.00011892644623032867, 0.0002000573444935627, 8.113088798502151e-05, 0.00017428060232137915, 0.00021818771359697025, 0.00013307270879187348, 0.0001115780438965854, 0.0001706384701825482, 9.8069189344343046e-05, 0.00013992502754784205, 0.0001581040032655571, 0.00018645138287236068, 0.00014102259488761143, 0.00020041255461616741, 0.00019090759491786837, 0.0001052173830595614, 0.00020653155681711025, 0.00014294553107616222, 0.00017247691313971317, 0.00011708347150373322, 0.00015909659076463552, 0.00013439011707426317, 0.00019545625951822358, 0.00018782830397851219, 0.00014775971857128442, 9.8391478993869444e-05, 0.00010924318670600252, 0.00021356013431366572, 0.00015811723369624935, 0.00010142654395271062, 0.00014506922380656047, 0.00016110423011157489, 0.00019857143270710868, 0.0001412894152479053], 6: [7.2837905355374892e-05, 4.9777028123452712e-05, 7.8946326698775603e-05, 5.769060638071582e-05, 7.7445774658705009e-05, 8.8100784919328779e-05, 8.4161000742366586e-05, 7.7669256400324791e-05, 6.6157538401892145e-05, 4.9460813694793921e-05, 5.5407694709241515e-05, 8.4411338020162806e-05, 5.1642604275951018e-05, 7.0108602390469362e-05, 5.591497842618383e-05, 8.5403121955084061e-05, 6.881852506891538e-05, 6.9006429493153536e-05, 6.7077237161385767e-05, 7.6665031357646689e-05, 5.5602592448277584e-05, 8.3005748781812903e-05, 8.5280284984757821e-05, 5.4548716793571947e-05, 9.1105661491225744e-05, 5.1992113682607056e-05, 9.0056139475971062e-05, 7.0174770430260166e-05, 7.8624194239627215e-05, 6.149215054125813e-05, 7.7739032059475743e-05, 5.9944669972969878e-05, 7.0087486170972656e-05, 6.3035038171198592e-05, 5.763847977034546e-05, 6.6603783345412285e-05, 7.3390493682347336e-05, 9.3271518947033588e-05, 5.941162272652149e-05, 6.5212648318619423e-05, 7.3954320204669085e-05, 6.1460489006613303e-05, 5.5328503383412261e-05, 8.5496851242212253e-05, 8.8748043734680629e-05, 6.2780885040558329e-05, 6.4542325413625957e-05, 6.0752617375448633e-05, 6.9384689252519451e-05, 4.7462843342022858e-05, 7.3252299300662321e-05, 8.003047043788074e-05, 8.0318472928479539e-05, 6.2273780075432098e-05, 9.0601485955609136e-05, 0.00012605755909012614, 5.1231824186642489e-05, 5.0265280299526286e-05, 0.00010143517739105495, 6.3129010332034366e-05, 8.0656376066813563e-05, 5.5742511436972209e-05, 5.275364738276594e-05, 5.6891067736583969e-05, 7.0699431070641769e-05, 6.5705807726300824e-05, 7.3919411484636385e-05, 3.1450169215221457e-05, 4.7351916181382931e-05, 8.81411092445158e-05, 8.7557685930766277e-05, 8.3541621525904221e-05, 8.4884371823094472e-05, 5.1301722788820727e-05, 0.0001036179630053846, 7.2343262919367045e-05, 5.0433031988806362e-05, 6.8106936668178039e-05, 5.0007340126041451e-05, 4.5417157886600728e-05, 8.7935661631010156e-05, 6.0866538272312759e-05, 5.1093491873786324e-05, 5.746905251089292e-05, 7.4599676638670016e-05, 8.0916987617614096e-05, 9.3072902518423744e-05, 6.7593161445967233e-05, 6.1343667452676731e-05, 7.8476914064928578e-05, 5.7776613098311754e-05, 8.3393145570407636e-05, 6.0778231335864195e-05, 6.5341927942207513e-05, 5.1107542247626843e-05, 7.9184553890635444e-05, 7.7205957611718821e-05, 9.0673898277332933e-05, 5.6977228898724675e-05, 6.4121465172695276e-05]}\n"
     ]
    }
   ],
   "source": [
    "parameters_distributions = {\n",
    "    \"max_number_inputs\": 7,\n",
    "    \"min_number_inputs\": 1,\n",
    "    \"number_of_states\": 5,\n",
    "    \"number_of_distributions\": 100\n",
    "}\n",
    "\n",
    "generator = generate_input_and_conditional_output(\n",
    "    'dirichlet', parameters_distributions, cond_output_type=\"dirichlet\"\n",
    ")\n",
    "\n",
    "#set new file name before turning run on\n",
    "RUN = False\n",
    "FILE_NAME = \"max_impact_individual_nudges_dirichlet2_first100samples.json\"\n",
    "if RUN:\n",
    "    max_individual_impact_dict = {}\n",
    "    prev_number_of_vars = -1\n",
    "    for count, dist_dict in enumerate(generator):\n",
    "        print(count)\n",
    "        number_of_vars = dist_dict[\"number_of_vars\"]\n",
    "        number_of_states = dist_dict[\"number_of_states\"]\n",
    "        if number_of_vars != len(dist_dict[\"input_dist\"].shape):\n",
    "            print(\"WARNING in sample {} input dist has weird distribution\".format(count))\n",
    "        if number_of_vars != prev_number_of_vars:\n",
    "            prev_number_of_vars = number_of_vars \n",
    "            print(\"the number of vars {}\".format(number_of_vars))\n",
    "        #print(dist_dict[\"cond_output\"].shape)\n",
    "        max_impact = find_max_impact_individual_nudge_exactly(\n",
    "            dist_dict[\"input_dist\"], dist_dict[\"cond_output\"], NUDGE_SIZE/2\n",
    "        )\n",
    "        if number_of_vars in max_individual_impact_dict:\n",
    "            max_individual_impact_dict[number_of_vars].append(max_impact)\n",
    "        else:\n",
    "            max_individual_impact_dict[number_of_vars] = [max_impact]\n",
    "\n",
    "        if (count+1)%5==0 and count != 0:\n",
    "            with open(FILE_NAME, 'w') as f:\n",
    "                json.dump(max_individual_impact_dict, f, indent=4)\n",
    "\n",
    "    with open(FILE_NAME, 'w') as f:\n",
    "        json.dump(max_individual_impact_dict, f, indent=4)\n",
    "\n",
    "    print(max_individual_impact_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the maximum global nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, max_global_nudge_impact = maximum_nudges.find_max_control_impact(input_dist, cond_output, NUDGE_SIZE/2)\n",
    "print(max_global_nudge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_distributions = {\n",
    "    \"max_number_inputs\": 7,\n",
    "    \"min_number_inputs\": 2,\n",
    "    \"number_of_states\": 5,\n",
    "    \"number_of_distributions\": 200\n",
    "}\n",
    "\n",
    "generator = generate_input_and_conditional_output(\n",
    "    'dirichlet', parameters_distributions, cond_output_type=\"dirichlet\"\n",
    ")\n",
    "\n",
    "#change file name before turning RUN on\n",
    "RUN = False\n",
    "FILE_NAME = \"max_impact_global_nudges_dirichlet_first200samples2.json\"\n",
    "if RUN:\n",
    "    max_global_impact_dict = {}\n",
    "    prev_number_of_vars = -1\n",
    "    for count, dist_dict in enumerate(generator):\n",
    "        print(count)\n",
    "        number_of_vars = dist_dict[\"number_of_vars\"]\n",
    "        number_of_states = dist_dict[\"number_of_states\"]\n",
    "        if number_of_vars != len(dist_dict[\"input_dist\"].shape):\n",
    "            print(\"WARNING in sample {} input dist has weird distribution\".format(count))\n",
    "        if number_of_vars != prev_number_of_vars:\n",
    "            prev_number_of_vars = number_of_vars \n",
    "            print(\"the number of vars {}\".format(number_of_vars))\n",
    "        #print(dist_dict[\"cond_output\"].shape)\n",
    "        _, _, max_global_nudge_impact = maximum_nudges.find_max_control_impact(\n",
    "            dist_dict[\"input_dist\"], dist_dict[\"cond_output\"], NUDGE_SIZE/2\n",
    "        )\n",
    "\n",
    "        if number_of_vars in max_global_impact_dict:\n",
    "            max_global_impact_dict[number_of_vars].append(max_global_nudge_impact)\n",
    "        else:\n",
    "            max_global_impact_dict[number_of_vars] = [max_global_nudge_impact]\n",
    "\n",
    "        if (count+1)%5==0 and count != 0:\n",
    "            with open(FILE_NAME, 'w') as f:\n",
    "                json.dump(max_global_impact_dict, f, indent=4)\n",
    "\n",
    "    with open(FILE_NAME, 'w') as f:\n",
    "        json.dump(max_global_impact_dict, f, indent=4)\n",
    "\n",
    "    print(max_global_impact_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
