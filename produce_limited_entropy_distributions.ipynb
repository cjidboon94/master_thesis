{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook sets out to produce distributions that are randomly sampled from the space of\n",
    "distributions which entropy is set to a fixed percentage of the maximum entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import probability_distributions\n",
    "import limited_entropy_distributions as limited_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"/home/derkjan/Documents/academics_UVA/master_thesis/code/\"\n",
    "PERCENTAGE_MAX_ENTROPY = 90 \n",
    "TOP_FOLDER = \"limited_entropy_distributions/\"\n",
    "FOLDER_PERCENTAGE_MAX_ENTROPY = \"entropy{}/\".format(PERCENTAGE_MAX_ENTROPY)\n",
    "FOLDER_DISTRIBUTION_SHAPE_FORMAT = \"{}var_{}states/\"\n",
    "FILENAME_DISTRIBUTION_FORMAT = \"dist_{}.npy\"\n",
    "MIN_NUMBER_VARIABLES = 1\n",
    "MAX_NUMBER_VARIABLES = 9\n",
    "NUMBER_OF_STATES = 3\n",
    "\n",
    "FILENAME_INPUT_FORMAT = \"input_dist_{}.npy\"\n",
    "FILENAME_COND_OUTPUT_FORMAT = \"cond_output_dist_{}.npy\" \n",
    "\n",
    "NUMBER_OF_SAMPLES = 1\n",
    "START_NUMBER_SAMPLES = 0\n",
    "END_NUMBER_SAMPLES = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate the folder structure (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH+TOP_FOLDER):\n",
    "    os.makedirs(PATH+TOP_FOLDER)\n",
    "    \n",
    "if not os.path.exists(PATH+TOP_FOLDER+FOLDER_PERCENTAGE_MAX_ENTROPY):\n",
    "    os.makedirs(PATH+TOP_FOLDER+FOLDER_PERCENTAGE_MAX_ENTROPY)\n",
    "\n",
    "for number_of_variables in range(MIN_NUMBER_VARIABLES, MAX_NUMBER_VARIABLES+1, 1):\n",
    "    directory = (PATH+TOP_FOLDER+FOLDER_PERCENTAGE_MAX_ENTROPY\n",
    "                 + FOLDER_DISTRIBUTION_SHAPE_FORMAT.format(number_of_variables, NUMBER_OF_STATES))\n",
    "                 \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the settings to generate the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_vars_to_evolution_params = {\n",
    "    1: {\n",
    "        \"number_of_generations\": 10,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 3,\n",
    "        \"mutation_size\": 0.05,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    2: {\n",
    "        \"number_of_generations\": 10,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 9,\n",
    "        \"mutation_size\": 0.01,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    3: {\n",
    "        \"number_of_generations\": 5,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 20,\n",
    "        \"mutation_size\": 0.01,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    4: {\n",
    "        \"number_of_generations\": 5,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 30,\n",
    "        \"mutation_size\": 0.001,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    5: {\n",
    "        \"number_of_generations\": 20,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 40,\n",
    "        \"mutation_size\": 0.001,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    6: {\n",
    "        \"number_of_generations\": 75,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 100,\n",
    "        \"mutation_size\": 0.0005,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    7: {\n",
    "        \"number_of_generations\": 80,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 100,\n",
    "        \"mutation_size\": 0.0005,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    8: {\n",
    "        \"number_of_generations\": 250,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 200,\n",
    "        \"mutation_size\": 0.0002,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    },\n",
    "    9: {\n",
    "        \"number_of_generations\": 700,\n",
    "        \"population_size\": 20,\n",
    "        \"number_of_children\": 80,\n",
    "        \"generational\": False,\n",
    "        \"mutation_method\": \"step_wise_after\",\n",
    "        \"number_of_mutations\": 400,\n",
    "        \"mutation_size\": 0.00009,\n",
    "        \"parent_selection_mode\": \"rank_exponential\",\n",
    "        \"early_stopping_criterium\": 0.01\n",
    "    }\n",
    "}\n",
    "file_name = \"evolution_settings_{}states.pkl\".format(NUMBER_OF_STATES)\n",
    "with open(PATH+TOP_FOLDER+FOLDER_PERCENTAGE_MAX_ENTROPY+file_name, 'w') as f:\n",
    "    pickle.dump(number_of_vars_to_evolution_params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN = True\n",
    "if RUN:\n",
    "    for number_of_variables in range(MIN_NUMBER_VARIABLES, MAX_NUMBER_VARIABLES+1, 1):\n",
    "        print(\"number of variables {}\".format(number_of_variables))\n",
    "        directory = (\n",
    "            PATH + TOP_FOLDER + FOLDER_PERCENTAGE_MAX_ENTROPY\n",
    "            + FOLDER_DISTRIBUTION_SHAPE_FORMAT.format(number_of_variables, NUMBER_OF_STATES)\n",
    "        )\n",
    "        dist_shape = [NUMBER_OF_STATES]*number_of_variables\n",
    "        evolution_params = number_of_vars_to_evolution_params[number_of_variables]\n",
    "        for sample_number in range(START_NUMBER_SAMPLES, END_NUMBER_SAMPLES, 1):\n",
    "            print(\"sample number {}\".format(sample_number))\n",
    "            dist = limited_entropy.get_dist_percentage_max_entropy(\n",
    "                dist_shape, PERCENTAGE_MAX_ENTROPY/100.0, evolution_params, \n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            #save distribution\n",
    "            file_name = FILENAME_DISTRIBUTION_FORMAT.format(sample_number)\n",
    "            with open(directory+file_name, 'wb') as f:\n",
    "                np.save(f, dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### From the joint distribution take the input distribution (the marginal of the first N-1 axis) and the output (the Nth axis) conditioned on the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True\n",
    "RUN = True\n",
    "limited_entropy.PRINT = False\n",
    "\n",
    "evolutionary_params_generate_conditional_output_stats = {\n",
    "    \"number_of_generations\": 700,\n",
    "    \"population_size\": 20,\n",
    "    \"number_of_children\": 80,\n",
    "    \"generational\": False,\n",
    "    \"mutation_method\": \"step_wise_after\",\n",
    "    \"number_of_mutations\": 3,\n",
    "    \"mutation_size\": 0.01,\n",
    "    \"parent_selection_mode\": \"rank_exponential\",\n",
    "    \"early_stopping_criterium\": 0.01\n",
    "}\n",
    "\n",
    "def produce_conditional_states(entropy_size, evolution_params, number_of_states=NUMBER_OF_STATES):\n",
    "    while True:\n",
    "        new_entropy_size = entropy_size + np.random.uniform(-0.15*entropy_size, 0.15*entropy_size) \n",
    "        yield limited_entropy.get_dist_with_entropy(\n",
    "            NUMBER_OF_STATES, new_entropy_size, \n",
    "            evolution_params, verbose=False    \n",
    "        )\n",
    "\n",
    "if RUN:\n",
    "    min_number_of_variables = max(MIN_NUMBER_VARIABLES, 2)\n",
    "    for number_of_variables in range(min_number_of_variables, MAX_NUMBER_VARIABLES+1, 1):\n",
    "        print(\"number of variables {}\".format(number_of_variables))\n",
    "        directory = (\n",
    "            PATH + TOP_FOLDER + FOLDER_PERCENTAGE_MAX_ENTROPY\n",
    "            + FOLDER_DISTRIBUTION_SHAPE_FORMAT.format(number_of_variables, NUMBER_OF_STATES)\n",
    "        )\n",
    "        dist_shape = [NUMBER_OF_STATES]*number_of_variables\n",
    "        input_labels = set(range(number_of_variables-1))\n",
    "        output_label = set([number_of_variables-1])\n",
    "        for sample_number in range(START_NUMBER_SAMPLES, END_NUMBER_SAMPLES, 1):\n",
    "            print(\"sample number {}\".format(sample_number))\n",
    "            #load the distribution\n",
    "            file_name = FILENAME_DISTRIBUTION_FORMAT.format(sample_number)\n",
    "            with open(directory+file_name, 'rb') as f:\n",
    "                joint = np.load(f)\n",
    "                \n",
    "            #produce the marginal\n",
    "            joint_dist = probability_distributions.ProbabilityArray(joint)\n",
    "            input_dist = joint_dist.marginalize(input_labels)\n",
    "            \n",
    "            #save the marginal (representing the input distribution)\n",
    "            file_name = FILENAME_INPUT_FORMAT.format(sample_number)\n",
    "            with open(directory+file_name, 'wb') as f:\n",
    "                np.save(f, input_dist)\n",
    "                \n",
    "            print(\"number of input states with zero probability {}\".format(\n",
    "                input_dist.flatten().shape[0]-np.count_nonzero(input_dist.flatten())\n",
    "            ))\n",
    "            \n",
    "            #produce the conditional output\n",
    "            entropies = [stats.entropy(joint[tuple(state)], base=2) for state in np.argwhere(input_dist != 0)]\n",
    "            average_entropy = np.mean(entropies)\n",
    "            print(average_entropy)\n",
    "            generator = produce_conditional_states(\n",
    "                average_entropy, evolutionary_params_generate_conditional_output_stats\n",
    "            )\n",
    "            cond_output , mar_labels, cond_labels = joint_dist.find_conditional_accounting_for_zero_marginals(\n",
    "                output_label, input_labels, generator\n",
    "            )\n",
    "            \n",
    "            #save cond_output\n",
    "            file_name = FILENAME_COND_OUTPUT_FORMAT.format(sample_number)\n",
    "            with open(directory+file_name, 'wb') as f:\n",
    "                np.save(f, cond_output)\n",
    "                \n",
    "            if TEST:\n",
    "                computed_joint = probability_distributions.compute_joint(input_dist, cond_output, cond_labels)\n",
    "                if not np.allclose(computed_joint, joint):\n",
    "                    raise ValueError()\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
