{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the data from several files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from simulate import find_mean_std_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data_experiments/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data for the maximum nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_keys_from_string_to_int(dictionary):\n",
    "    return {int(k):v for k,v in dictionary.items()}\n",
    "\n",
    "def files_to_dict(file_names):\n",
    "    \"\"\" Load the data from the files and make keys into ints\"\"\"\n",
    "    dictionaries = []\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, 'r') as f:\n",
    "            dictionaries.append(json.load(f))\n",
    "\n",
    "    dictionaries = [dict_keys_from_string_to_int(i) for i in dictionaries]\n",
    "    return dictionaries\n",
    "\n",
    "def compare_settings(value_to_scores, min_value, max_value):\n",
    "    value_to_average_scores = {}\n",
    "    for i in range(min_value, max_value+1, 1):\n",
    "        average_impacts = []\n",
    "        for count, dirichlet_dict in enumerate(value_to_scores):\n",
    "            try:\n",
    "                average_impacts.append(np.mean(dirichlet_dict[i]))\n",
    "            except KeyError:\n",
    "                print(\"the {} file has variable {} missing\".format(i, count))\n",
    "\n",
    "        value_to_average_scores[i] = average_impacts\n",
    "\n",
    "    return value_to_average_scores\n",
    "\n",
    "def flip_sign_values_dict(dictionary):\n",
    "    for key, values in dictionary.items():\n",
    "        dictionary[key] = [-value for value in values]\n",
    "        \n",
    "    return dictionary\n",
    "\n",
    "def find_max_scores_per_value(dictionaries, min_value, max_value):\n",
    "    value_to_maximum_scores = {}\n",
    "    for i in range(min_value, max_value+1, 1):\n",
    "        impacts = []\n",
    "        for count, dictionary in enumerate(dictionaries):\n",
    "            try:\n",
    "                impacts.append(dictionary[i])\n",
    "            except KeyError:\n",
    "                print(\"the {} file has variable {} missing\".format(i, count))\n",
    "\n",
    "        max_impacts = [max(scores) for scores in list(zip(*impacts))]\n",
    "        value_to_maximum_scores[i] = max_impacts\n",
    "\n",
    "    return value_to_maximum_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#max local impact files\n",
    "local_dirichlet_file_format = PATH + \"max_impact_local_nudges{}_dirichlet.json\" \n",
    "local_entropy_file_format = PATH + \"max_impact_local_nudges{}_entropy0.75.json\"\n",
    "local_dirichlet_files = [local_dirichlet_file_format.format(i) for i in [2, 3, 7]]\n",
    "local_dirichlet_files.append(PATH + \"max_impact_local_nudges_dirichlet_ex9.json\")\n",
    "local_entropy75_files = [local_entropy_file_format.format(i) for i in [4,5,6,8]]\n",
    "\n",
    "#max synergistic impact files\n",
    "synergistic_dirichlet_file_format = PATH + \"max_impact_synergistic_nudges_dirichlet_ex{}3.json\"\n",
    "synergistic_entropy75_file_format = PATH + \"max_impact_synergistic_nudges_entropy0.75_ex{}3.json\"\n",
    "synergistic_dirichlet_files = [synergistic_dirichlet_file_format.format(i) for i in range(5, 9, 1)]\n",
    "synergistic_entropy75_files = [synergistic_entropy75_file_format.format(i) for i in range(1, 5, 1)]\n",
    "\n",
    "local_dirichlet_dicts = files_to_dict(local_dirichlet_files)\n",
    "local_entropy75_dicts = files_to_dict(local_entropy75_files)\n",
    "synergistic_dirichlet_dicts = files_to_dict(synergistic_dirichlet_files)\n",
    "synergistic_entropy75_dicts = files_to_dict(synergistic_entropy75_files)\n",
    "\n",
    "\n",
    "for local_dict in local_dirichlet_dicts:\n",
    "    flip_sign_values_dict(local_dict)\n",
    "for local_dict in local_entropy75_dicts:\n",
    "    flip_sign_values_dict(local_dict)\n",
    "for synergistic_dict in synergistic_dirichlet_dicts:\n",
    "    flip_sign_values_dict(synergistic_dict)\n",
    "for synergistic_dict in synergistic_entropy75_dicts:\n",
    "    flip_sign_values_dict(synergistic_dict)\n",
    "\n",
    "    \n",
    "#load individual maximum nudges\n",
    "\n",
    "individual_dirichlet_file = \"max_impact_individual_nudges_dirichlet_first100samples.json\"\n",
    "individual_entropy75_file = \"max_impact_individual_nudges_entropy75_first200samples.json\"\n",
    "individual_dirichlet_dict = files_to_dict([PATH+individual_dirichlet_file])[0]\n",
    "individual_entropy75_dict = files_to_dict([PATH+individual_entropy75_file])[0]\n",
    "\n",
    "#load global maximum nudges\n",
    "\n",
    "global_dirichlet_file = \"max_impact_global_nudges_dirichlet_first200samples.json\"\n",
    "global_entropy75_file = \"max_impact_global_nudges_entropy75_first200samples.json\"\n",
    "global_dirichlet_dict = files_to_dict([PATH + global_dirichlet_file])[0]\n",
    "global_entropy75_dict = files_to_dict([PATH + global_entropy75_file])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First inspect the local maximum nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inspect local dirichlet file\")\n",
    "average_scores_per_file_local_dirichlet = compare_settings(local_dirichlet_dicts, min_value=2, max_value=5)\n",
    "print(\"inspect local entropy 75 file\")\n",
    "average_scores_per_file_local_entropy75 = compare_settings(local_entropy75_dicts, min_value=2, max_value=5)\n",
    "\n",
    "print(\"the max local nudge impacts per file for dirichlet inputs\")\n",
    "print(average_scores_per_file_local_dirichlet)\n",
    "print(\"\")\n",
    "\n",
    "print(\"the max local nudge impacts per file for entropy 75 inputs\")\n",
    "print(average_scores_per_file_local_entropy75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### inspect maximal synergistic nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inspect synergistic dirichet file\")\n",
    "average_scores_per_file_synergistic_dirichlet = compare_settings(\n",
    "    synergistic_dirichlet_dicts, min_value=2, max_value=6\n",
    ")\n",
    "print(\"inspect synergistic entropy 75 file\")\n",
    "average_scores_per_file_synergistic_entropy75 = compare_settings(\n",
    "    synergistic_entropy75_dicts, min_value=2, max_value=6\n",
    ")\n",
    "\n",
    "print(\"the max synergistic nudge impacts per file for dirichlet inputs\")\n",
    "print(average_scores_per_file_synergistic_dirichlet)\n",
    "print(\"\")\n",
    "\n",
    "print(\"the max synergistic nudge impacts per file for entropy 75 inputs\")\n",
    "print(average_scores_per_file_synergistic_entropy75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_local_dirichlet_dict = find_max_scores_per_value(local_dirichlet_dicts, min_value=2, max_value=5)\n",
    "max_local_entropy75_dict = find_max_scores_per_value(local_entropy75_dicts, min_value=2, max_value=5)\n",
    "max_synergistic_dirichlet_dict = find_max_scores_per_value(synergistic_dirichlet_dicts, min_value=2, max_value=6)\n",
    "max_synergistic_entropy75_dict = find_max_scores_per_value(synergistic_entropy75_dicts, min_value=2, max_value=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range_local_dirichlet, mean_local_dirichlet, std_local_dirichlet, batches_std_local_dirichlet = (\n",
    "    find_mean_std_mse(max_local_dirichlet_dict, batch_size=10)\n",
    ")\n",
    "plot_range_local_entropy75, mean_local_entropy75, std_local_entropy75, batches_std_local_entropy75 = (\n",
    "    find_mean_std_mse(max_local_entropy75_dict, batch_size=1)\n",
    ")\n",
    "plot_range_synergistic_dirichlet, mean_synergistic_dirichlet, std_synergistic_dirichlet, batches_std_synergistic_dirichlet = (\n",
    "    find_mean_std_mse(max_synergistic_dirichlet_dict, batch_size=10)\n",
    ")\n",
    "plot_range_synergistic_entropy75, mean_synergistic_entropy75, std_synergistic_entropy75, batches_std_synergistic_entropy75 = (\n",
    "    find_mean_std_mse(max_synergistic_entropy75_dict, batch_size=10)\n",
    ")\n",
    "plot_range_individual_dirichlet, mean_individual_dirichlet, std_individual_dirichlet, batches_std_individual_dirichlet = (\n",
    "    find_mean_std_mse(individual_dirichlet_dict, batch_size=10)\n",
    ")\n",
    "plot_range_individual_entropy75, mean_individual_entropy75, std_individual_entropy75, batches_std_individual_entropy75 = (\n",
    "    find_mean_std_mse(individual_entropy75_dict, batch_size=10)\n",
    ")\n",
    "plot_range_global_dirichlet, mean_global_dirichlet, std_global_dirichlet, batches_std_global_dirichlet = (\n",
    "    find_mean_std_mse(global_dirichlet_dict, batch_size=10)\n",
    ")\n",
    "plot_range_global_entropy75, mean_global_entropy75, std_global_entropy75, batches_std_global_entropy75 = (\n",
    "    find_mean_std_mse(global_dirichlet_dict, batch_size=10)\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "\n",
    "#play with this for better figure sizes \n",
    "mpl.rcParams['figure.figsize'] = (7,7)\n",
    "mpl.legend.loc = \"upper_left\"\n",
    "\n",
    "plt.plot(plot_range_local_dirichlet, mean_local_dirichlet, label=\"local\")\n",
    "plt.plot(plot_range_synergistic_dirichlet, mean_synergistic_dirichlet, label=\"synergistic\")\n",
    "plt.plot(plot_range_individual_dirichlet, mean_individual_dirichlet, label=\"individual\")\n",
    "plt.plot(plot_range_global_dirichlet, mean_global_dirichlet, label=\"global\")\n",
    "\n",
    "lower_bound_synergistic_dirichlet = np.array(mean_synergistic_dirichlet)-np.array(std_synergistic_dirichlet)\n",
    "upper_bound_synergistic_dirichlet = np.array(mean_synergistic_dirichlet)+np.array(std_synergistic_dirichlet)\n",
    "plt.fill_between(plot_range_synergistic_dirichlet, lower_bound_synergistic_dirichlet, \n",
    "                 upper_bound_synergistic_dirichlet, \n",
    "                 alpha=0.2)\n",
    "\n",
    "lower_bound_individual_dirichlet = np.array(mean_individual_dirichlet)-np.array(std_individual_dirichlet)\n",
    "upper_bound_individual_dirichlet = np.array(mean_individual_dirichlet)+np.array(std_individual_dirichlet)\n",
    "plt.fill_between(plot_range_individual_dirichlet, lower_bound_individual_dirichlet, \n",
    "                 upper_bound_individual_dirichlet, \n",
    "                 alpha=0.2)\n",
    "\n",
    "lower_bound_global_dirichlet = np.array(mean_global_dirichlet)-np.array(std_global_dirichlet)\n",
    "upper_bound_global_dirichlet = np.array(mean_global_dirichlet)+np.array(std_global_dirichlet)\n",
    "plt.fill_between(plot_range_global_dirichlet, lower_bound_global_dirichlet, upper_bound_global_dirichlet, \n",
    "                 alpha=0.2)\n",
    "\n",
    "lower_bound_local_dirichlet = np.array(mean_local_dirichlet)-np.array(std_local_dirichlet)\n",
    "upper_bound_local_dirichlet = np.array(mean_local_dirichlet)+np.array(std_local_dirichlet)\n",
    "plt.fill_between(plot_range_local_dirichlet, lower_bound_local_dirichlet, upper_bound_local_dirichlet, \n",
    "                 alpha=0.2)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lower_bound_random_control = np.array(mean_random_control)-np.array(std_random_control)\n",
    "# upper_bound_random_control = np.array(mean_random_control)+np.array(std_random_control)\n",
    "# plt.fill_between(plot_range, lower_bound_random_control, upper_bound_random_control, \n",
    "#                  label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(plot_range_local_entropy75, mean_local_entropy75, label=\"local\")\n",
    "plt.plot(plot_range_synergistic_entropy75, mean_synergistic_entropy75, label=\"synergistic\")\n",
    "plt.plot(plot_range_individual_entropy75, mean_individual_entropy75, label=\"individual\")\n",
    "plt.plot(plot_range_global_entropy75, mean_global_entropy75, label=\"global\")\n",
    "\n",
    "lower_bound_synergistic_entropy75 = np.array(mean_synergistic_entropy75)-np.array(std_synergistic_entropy75)\n",
    "upper_bound_synergistic_entropy75 = np.array(mean_synergistic_entropy75)+np.array(std_synergistic_entropy75)\n",
    "plt.fill_between(plot_range_synergistic_entropy75, lower_bound_synergistic_entropy75, \n",
    "                 upper_bound_synergistic_entropy75, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "\n",
    "lower_bound_individual_entropy75 = np.array(mean_individual_entropy75)-np.array(std_individual_entropy75)\n",
    "upper_bound_individual_entropy75 = np.array(mean_individual_entropy75)+np.array(std_individual_entropy75)\n",
    "plt.fill_between(plot_range_individual_entropy75, lower_bound_individual_entropy75, \n",
    "                 upper_bound_individual_entropy75, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "\n",
    "lower_bound_global_entropy75 = np.array(mean_global_entropy75)-np.array(std_global_entropy75)\n",
    "upper_bound_global_entropy75 = np.array(mean_global_entropy75)+np.array(std_global_entropy75)\n",
    "plt.fill_between(plot_range_global_entropy75, lower_bound_global_entropy75, upper_bound_global_entropy75, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "\n",
    "lower_bound_local_entropy75 = np.array(mean_local_entropy75)-np.array(std_local_entropy75)\n",
    "upper_bound_local_entropy75 = np.array(mean_local_entropy75)+np.array(std_local_entropy75)\n",
    "plt.fill_between(plot_range_local_entropy75, lower_bound_local_entropy75, upper_bound_local_entropy75, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data experiment impact on MI of minimalizing individual nudge impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files_json(file_names):\n",
    "    dicts = []\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, 'r') as f:\n",
    "            dicts.append(json.load(f))\n",
    "            \n",
    "    return dicts\n",
    "\n",
    "def update_dictkeys_unicode2string(dictionary):\n",
    "    return {str(k):v for k,v in dictionary.items()}\n",
    "\n",
    "def combine_data_dicts(dictionaries):\n",
    "    \"\"\"\n",
    "    Combine data dicts, meaning that all data of the same key are merged into a new dict\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionaries: a list of dicts\n",
    "        Every key of the dicts should have a list as values \n",
    "\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for dictionary in dictionaries:\n",
    "        for key, values in dictionary.items():\n",
    "            if key in new_dict:\n",
    "                new_dict[key].extend(values)\n",
    "            else:\n",
    "                new_dict[key] = values\n",
    "                \n",
    "    return new_dict\n",
    "\n",
    "def get_average_values_dict(dictionary):\n",
    "    \"\"\"take average of all values dictionary\"\"\"\n",
    "    return {k:np.mean(v) for k, v in dictionary.items()}\n",
    "\n",
    "#for 2 input vars with 5 states\n",
    "file_name_format2 = \"minimize_individual_focused_nudge_impact_kl_divergence_inspect_change_MI_2var_5states{}.json\"\n",
    "files_vars2 = [PATH + file_name_format2.format(i) for i in [\"\", 1, 3, 4, 5, 6]]\n",
    "dictionaries_vars2 = load_files_json(files_vars2)\n",
    "dictionaries_vars2 = [update_dictkeys_unicode2string(dictionary) for dictionary in dictionaries_vars2]\n",
    "dictionary_vars2 = combine_data_dicts(dictionaries_vars2)\n",
    "print(get_average_values_dict(dictionary_vars2))\n",
    "\n",
    "#for 3 input vars with 5 states\n",
    "file_name_format3 = \"minimize_individual_focused_nudge_impact_inspect_change_MI_3var_5states{}.json\"\n",
    "files_vars3 = [PATH + file_name_format3.format(i) for i in [\"\", 2, 3, 4, 5]]\n",
    "dictionaries_vars3 = load_files_json(files_vars3)\n",
    "dictionaries_vars3 = [update_dictkeys_unicode2string(dictionary) for dictionary in dictionaries_vars3]\n",
    "dictionary_vars3 = combine_data_dicts(dictionaries_vars3)\n",
    "print(get_average_values_dict(dictionary_vars3))\n",
    "\n",
    "file_vars4 = \"minimize_individual_focused_nudge_impact_inspect_change_MI_4var_5states.json\"\n",
    "dictionaries_vars4 = load_files_json([PATH + file_vars4])\n",
    "dictionary_vars4 = update_dictkeys_unicode2string(dictionaries_vars4[0])\n",
    "print(get_average_values_dict(dictionary_vars4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation MI and individual nudge impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_correlation_MI_nudge_impact(var_to_file_names):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    var_to_files: a dict\n",
    "    \n",
    "    \"\"\"\n",
    "    var_to_MI_and_nudge_impact = {}\n",
    "    for number_of_var, file_names in var_to_file_names.items():\n",
    "        file_names = [PATH+file_name for file_name in file_names]\n",
    "        if number_of_var == 5:\n",
    "            mi_and_nudge_impact_lists = load_files_json(file_names)\n",
    "            var_to_MI_and_nudge_impact[number_of_var] = [\n",
    "                list(itertools.chain.from_iterable(mi_and_nudge_impact_lists))\n",
    "            ]\n",
    "        else:\n",
    "            var_to_MI_and_nudge_impact[number_of_var] = load_files_json(file_names)[0]\n",
    "\n",
    "    return var_to_MI_and_nudge_impact\n",
    "\n",
    "focused_nudge_kl_divergence_impact_and_MI_var_to_files = {\n",
    "    1: [\"correlation_MI_individual_nudge_impact_1var_5states_min_output001_ex1.json\"],\n",
    "    2: [\"correlation_MI_individual_nudge_impact_2var_5states_min_output001_ex2.json\"],\n",
    "    3: [\"correlation_MI_individual_nudge_impact_3var_5states_min_output001_exp3.json\"],\n",
    "    4: [\"correlation_MI_individual_nudge_impact_4var_5states_min_output001_exp4.json\"],\n",
    "    5: [\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_min_output001_exp5_points0_20.json\",\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_min_output001_exp6_point20_40.json\",\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_min_output001_exp3_points40_60.json\",\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_min_output001_ex2_points60_80.json\",\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_min_output001_ex1_points80_100.json\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "focused_nudge_l1norm_impact_and_MI_var_to_files = {\n",
    "    1: [\"correlation_MI_individual_nudge_impact_1var_5states_l1norm_ex1.json\"],\n",
    "    2: [\"correlation_MI_individual_nudge_impact_2var_5states_l1norm_ex2.json\"],\n",
    "    3: [\"correlation_MI_individual_nudge_impact_3var_5states_l1norm_exp3.json\"],\n",
    "    4: [\"correlation_MI_individual_nudge_impact_4var_5states_l1norm_exp4.json\"],\n",
    "    5: [\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_l1norm_exp5_points0_20.json\",\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_l1norm_exp6_point20_40.json\",\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_l1norm_ex1_points40_60.json\",\n",
    "        \"correlation_MI_individual_nudge_impact_5var_5states_l1norm_ex2_points60_80.json\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "vector_nudge_kl_divergence_impact_and_MI_var_to_files = {\n",
    "    1: [\"correlation_MI_individual_vector_nudge_impact_1var_5states_min_output001_ex1.json\"],\n",
    "    2: [\"correlation_MI_individual_vector_nudge_impact_2var_5states_kl-divergence_ex2.json\"],\n",
    "    3: [\"correlation_MI_individual_vector_nudge_impact_3var_5states_kl-divergence_ex1.json\"],\n",
    "    4: [\"correlation_MI_individual_vector_nudge_impact_4var_5states_kl-divergence_ex2.json\"],\n",
    "    5: [\n",
    "        \"correlation_MI_individual_vector_nudge_impact_5var_5states_kl-divergence_ex3_points0_30.json\",\n",
    "        \"correlation_MI_individual_vector_nudge_impact_5var_5states_kl-divergence_ex1_points30_60.json\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "vector_nudge_l1norm_impact_and_MI_var_to_files = {\n",
    "    1: [\"correlation_MI_individual_vector_nudge_impact_1var_5states_l1norm_ex1.json\"],\n",
    "    2: [\"correlation_MI_individual_vector_nudge_impact_2var_5states_l1norm_ex2.json\"],\n",
    "    3: [\"correlation_MI_individual_vector_nudge_impact_3var_5states_l1norm_ex3.json\"],\n",
    "    4: [\"correlation_MI_individual_vector_nudge_impact_4var_5states_l1norm_ex4.json\"],\n",
    "    5: [\n",
    "        \"correlation_MI_individual_vector_nudge_impact_5var_5states_l1norm_ex5_point0_30.json\",\n",
    "        \"correlation_MI_individual_vector_nudge_impact_5var_5states_l1norm_exp6_points30_60.json\",\n",
    "        \"correlation_MI_individual_vector_nudge_impact_5var_5states_l1norm_ex5_point60_90.json\",\n",
    "        \"correlation_MI_individual_vector_nudge_impact_5var_5states_l1norm_exp6_points90_120.json\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "var_to_focused_nudge_kl_divergence_impact_and_MI = load_data_correlation_MI_nudge_impact(\n",
    "    focused_nudge_kl_divergence_impact_and_MI_var_to_files\n",
    ")\n",
    "\n",
    "var_to_focused_nudge_l1norm_impact_and_MI = load_data_correlation_MI_nudge_impact(\n",
    "    focused_nudge_l1norm_impact_and_MI_var_to_files\n",
    ")\n",
    "\n",
    "var_to_vector_nudge_kl_divergence_impact_and_MI = load_data_correlation_MI_nudge_impact(\n",
    "    vector_nudge_kl_divergence_impact_and_MI_var_to_files\n",
    ")\n",
    "\n",
    "var_to_vector_nudge_l1norm_impact_and_MI = load_data_correlation_MI_nudge_impact(\n",
    "    focused_nudge_kl_divergence_impact_and_MI_var_to_files\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import seaborn as sb\n",
    "#add seaborn linregress on own computer\n",
    "\n",
    "# dict_to_use = var_to_focused_nudge_kl_divergence_impact_and_MI\n",
    "dict_to_use = var_to_focused_nudge_l1norm_impact_and_MI\n",
    "# dict_to_use = var_to_vector_nudge_kl_divergence_impact_and_MI\n",
    "# dict_to_use = var_to_vector_nudge_l1norm_impact_and_MI\n",
    "\n",
    "for var, impact_nudges_and_mi in dict_to_use.items():\n",
    "    if var == 5:\n",
    "        impact_nudges_and_mi=impact_nudges_and_mi[0]\n",
    "\n",
    "    impact_nudges = [item[0] for item in impact_nudges_and_mi] \n",
    "    mutual_information_sizes = [item[1] for item in impact_nudges_and_mi]\n",
    "        \n",
    "    plt.plot(mutual_information_sizes, impact_nudges, 'o')\n",
    "    plt.xlabel(\"mutual information\")\n",
    "    plt.ylabel(\"nudge impact\")\n",
    "    plt.show()\n",
    "    print(stats.linregress(impact_nudges, mutual_information_sizes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation MI and nudge impact for 1 input and 1 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_experiments/relation_MI_nudge_impact_1input_non_biased1.json\", 'r') as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "with open(\"data_experiments/relation_MI_nudge_impact_1input_non_biased2.json\", 'r') as f:\n",
    "    data_dict1 = json.load(f)\n",
    "    \n",
    "for mi_value, values in data_dict1.items():\n",
    "    data_dict1[round((float(mi_value)*1000.0))/1000.0] = values\n",
    "    data_dict1.pop(mi_value, None)\n",
    "    \n",
    "for mi_value, values in data_dict.items():\n",
    "    data_dict[round((float(mi_value)*100.0))/100.0] = values\n",
    "    data_dict.pop(mi_value, None)\n",
    "    \n",
    "data_dict.update(data_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print({k:len(v) for k,v in data_dict.items()})\n",
    "plot_range, mean, std, batches_std = find_mean_std_mse(data_dict, batch_size=1)\n",
    "print(np.array(data_dict[0.85]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = np.array(mean)-np.array(std)\n",
    "upper_bound = np.array(mean)+np.array(std)\n",
    "print(lower_bound)\n",
    "print(upper_bound)\n",
    "print(plot_range)\n",
    "plt.plot(plot_range, mean, label=\"mean\")\n",
    "plt.fill_between(plot_range, lower_bound, upper_bound, \n",
    "                 label='{}'.format(\"std\"),\n",
    "                 alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"mutual information\")\n",
    "plt.ylabel(\"KL-divergence\")\n",
    "#plt.legend()\n",
    "plt.title('Individual nudge impact for set mutual information')\n",
    "plt.show()\n",
    "\n",
    "stats.linregress(np.array(plot_range), np.array(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
