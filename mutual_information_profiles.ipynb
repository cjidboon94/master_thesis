{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install astroML\n",
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import probability_distributions\n",
    "\n",
    "import simple_set_functions\n",
    "from probability_distributions import ProbabilityDict\n",
    "from probability_distributions import JointProbabilityMatrixExtended\n",
    "from jointpdf.jointpdf import JointProbabilityMatrix\n",
    "from jointpdf.jointpdf import FullNestedArrayOfProbabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "marginal_distributions = np.array([[0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5,  0.5]])\n",
    "\n",
    "def compute_joint(multi_index, marginal_distributions):\n",
    "    return reduce(lambda x, y: x*y, [marginal_distributions[combination] for\n",
    "            combination in zip(range(len(multi_index)), multi_index)])\n",
    "\n",
    "def compute_joint_from_marginals(marginal_distributions):\n",
    "    \"\"\"compute full joint probability matrix given independent marginals\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    marginal_distributions: numpy array \n",
    "        A 2 dimensional array where the first axis are the variables\n",
    "        and the second axis the number of states\n",
    "        \n",
    "    Returns: \n",
    "    -------\n",
    "    A numpy array where every dimension is one variable, it can be seen as \n",
    "    a tree build from the variables \n",
    "    \"\"\"\n",
    "    dimension_joint_distribution = [len(dist) for dist in marginal_distributions]\n",
    "    full_distribution_temp = np.zeros(dimension_joint_distribution)\n",
    "    full_distribution = np.zeros(dimension_joint_distribution)\n",
    "\n",
    "    it = np.nditer(full_distribution, flags=['multi_index'], op_flags=[['readwrite']])\n",
    "    while not it.finished:\n",
    "        full_distribution[it.multi_index]= compute_joint(it.multi_index, marginal_distributions)\n",
    "        it.iternext()\n",
    "\n",
    "    return full_distribution\n",
    "\n",
    "def create_uniform_marginal_distributions(num_states, num_variables):\n",
    "    \"\"\"create a list of uniform probability distributions \n",
    "    \n",
    "    params:\n",
    "        num_states: how many states the variables have\n",
    "        num_variables: how many variables to create\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array([[1.0/num_states]*num_states]*num_variables)\n",
    "    \n",
    "#print(compute_joint_from_marginals(create_uniform_marginal_distributions(3, 3)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tryout whether the implementation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "first dict\n",
      "(0, 0, 0): 0.1\n",
      "(0, 0, 1): 0.2\n",
      "(0, 0, 2): 0.25\n",
      "(1, 0, 0): 0.2\n",
      "(1, 0, 1): 0.1\n",
      "(1, 0, 2): 0.15\n",
      "second dict\n",
      "(0, 0, 0): 0.1\n",
      "(0, 0, 1): 0.2\n",
      "(0, 0, 2): 0.25\n",
      "(1, 0, 0): 0.2\n",
      "(1, 0, 1): 0.1\n",
      "(1, 0, 2): 0.15\n"
     ]
    }
   ],
   "source": [
    "pdf = JointProbabilityMatrix(4, 2, compute_joint_from_marginals(marginal_distributions))\n",
    "pdf_extended = JointProbabilityMatrixExtended(\n",
    "    4, 2, FullNestedArrayOfProbabilities(compute_joint_from_marginals(marginal_distributions))\n",
    ")\n",
    "pdf_extended.adjust_to_old_format()\n",
    "\n",
    "marginal_extended = pdf_extended.marginalize_distribution([0, 1])\n",
    "marginal = pdf.marginalize_distribution([0, 1])\n",
    "\n",
    "pdf_extended.append_determinstic_function(simple_set_functions.double_xor, [2, 2])\n",
    "pdf_extended.adjust_to_old_format()\n",
    "marginal_extended = pdf_extended.marginalize_distribution([0, 1])\n",
    "\n",
    "print(np.all(\n",
    "        marginal_extended.joint_probabilities.joint_probabilities==marginal.joint_probabilities.joint_probabilities\n",
    "))\n",
    "\n",
    "probability_array = np.array(\n",
    "    [\n",
    "        [\n",
    "            [0.1, 0.2, 0.25]\n",
    "        ],\n",
    "        [\n",
    "            [0.2, 0.1, 0.15]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "pdf_extended = JointProbabilityMatrixExtended(\n",
    "    3, 3, FullNestedArrayOfProbabilities(probability_array)\n",
    ")\n",
    "first_dict = ProbabilityDict(pdf_extended.to_dict())\n",
    "pdf_extended.adjust_to_old_format()\n",
    "second_dict = ProbabilityDict(pdf_extended.to_dict())\n",
    "\n",
    "print(\"first dict\")\n",
    "first_dict.print_distribution(True)\n",
    "print(\"second dict\")\n",
    "second_dict.print_distribution(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def calculate_mi_profile(joint_distribution, function_labels, testing=False):\n",
    "    \"\"\"create a mutual information profile\n",
    "    \n",
    "    params:\n",
    "        joint_distribution: A JointProbabilityMatrix object from the jointpdf package.\n",
    "        The joint probabilities properties should be of both all the variables and the\n",
    "        function.\n",
    "        function_labels: The labels in the joint distribution which the function represents\n",
    "        \n",
    "    returns: a 1-d nd-array where every value represents the average normalized mutual information\n",
    "        between subsets of variables (of the size of the index) and the ouput variable. \n",
    "    \"\"\"\n",
    "\n",
    "    number_of_arguments = joint_distribution.numvariables-len(function_labels)\n",
    "    if testing:\n",
    "        print(\"the number of arguments is {}\".format(number_of_arguments))\n",
    "    mi_values = np.zeros(number_of_arguments+1)\n",
    "    for number_of_variables in np.arange(1, number_of_arguments+1, 1):\n",
    "        combinations = itertools.combinations(range(number_of_arguments), \n",
    "                                              number_of_variables)\n",
    "        \n",
    "        mi_values[number_of_variables] = np.mean(\n",
    "            [joint_distribution.mutual_information(list(combination), function_labels) \n",
    "             for combination in combinations]\n",
    "        )\n",
    "        \n",
    "        if testing:\n",
    "            for comb in itertools.combinations(range(number_of_arguments), number_of_variables):\n",
    "                print(\"input variables {} function labels {} mi value {}\".format(\n",
    "                    list(comb), \n",
    "                    function_labels,\n",
    "                    joint_distribution.mutual_information(list(comb), function_labels)\n",
    "                ))\n",
    "        \n",
    "    return mi_values\n",
    "   \n",
    "def create_mutual_information_profile(pdf, function, dim_output_function, \n",
    "                                      num_states_output_function, testing=False):\n",
    "    \"\"\"create mutual information profile values\n",
    "    \n",
    "    params:\n",
    "        pdf: An object of the JointProbabilityMatrixExtendedClass\n",
    "        function: a function object that takes an iterable of the same length\n",
    "        as the number of variables in the pdf_extended object\n",
    "        dim_output_function: the dimension (number of variables) the function outputs\n",
    "        num_states_output_function: a list, where every entry represents the amount of \n",
    "        states that variable has. The length should be equal to dim_output_function\n",
    "        \n",
    "    returns: An array representing the MI profile values for number of variables \n",
    "    starting at zero and going to the total amount of variables in the distribution\n",
    "    \"\"\"\n",
    "\n",
    "    pdf.append_determinstic_function(double_xor, dim_output_function, num_states_output_function)\n",
    "    pdf.adjust_to_old_format()\n",
    "    \n",
    "    function_indices = list(range(pdf.numvariables-dim_output_function, pdf.numvariables))\n",
    "    \n",
    "    if testing:\n",
    "        print(\"the function indices are {}\".format(function_indices))\n",
    "    \n",
    "    return calculate_mi_profile(pdf_extended, function_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some testing. I found out that xor for i.i.d variables has mutual information with the individual variables.\n",
    "This was a huge surprise so I tested it with multiple implementation and also using playground.ipnb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf_extended = JointProbabilityMatrixExtended(\n",
    "    4, 2, FullNestedArrayOfProbabilities(compute_joint_from_marginals(marginal_distributions))\n",
    ")\n",
    "\n",
    "pdf_extended.append_determinstic_function(double_xor, num_variables=2, num_states=[2, 2])\n",
    "pdf_extended.adjust_to_old_format()\n",
    "print(calculate_mi_profile(pdf_extended, [4, 5]))\n",
    "\n",
    "print(\"now using the create function\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "pdf_extended2 = JointProbabilityMatrixExtended(\n",
    "    4, 2, FullNestedArrayOfProbabilities(compute_joint_from_marginals(marginal_distributions))\n",
    ")\n",
    "\n",
    "print(create_mutual_information_profile(pdf_extended2, double_xor, 2, [2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"first examining the double xor function on uniform distribution\")\n",
    "pdf_extended3 = JointProbabilityMatrixExtended(\n",
    "    4, 2, FullNestedArrayOfProbabilities(compute_joint_from_marginals(marginal_distributions[:4]))\n",
    ")\n",
    "print(create_mutual_information_profile(pdf_extended3, double_xor, 2, [2,2]))\n",
    "\n",
    "print(\"now examining the subset and function on uniform distribution\")\n",
    "num_states1 = 2\n",
    "num_variables1 = 4\n",
    "probabilities_arr = FullNestedArrayOfProbabilities(\n",
    "    compute_joint_from_marginals(create_uniform_marginal_distributions(2, 4))\n",
    ")\n",
    "pdf_extended4 = JointProbabilityMatrixExtended(num_variables1, num_states1, probabilities_arr)\n",
    "subset_and_func = subset_and([(0,2), (1,3)])  \n",
    "print(create_mutual_information_profile(pdf_extended4, subset_and_func, 2, [2,2]))\n",
    "\n",
    "print(\"now examining the sum function\")\n",
    "num_states1 = 2\n",
    "num_variables1 = 4\n",
    "probabilities_arr = FullNestedArrayOfProbabilities(\n",
    "    compute_joint_from_marginals(create_uniform_marginal_distributions(2, 4))\n",
    ")\n",
    "pdf_extended5 = JointProbabilityMatrixExtended(num_variables1, num_states1, probabilities_arr)\n",
    "pdf_extended5.append_determinstic_function(sum, 1, [5])\n",
    "\n",
    "probabability_dict5 = pdf_extended5.to_dict()\n",
    "#ProbabilityDict(probabability_dict5).print_dict(True)\n",
    "\n",
    "pdf_extended5.adjust_to_old_format()\n",
    "probabability_dict5 = ProbabilityDict(pdf_extended5.to_dict())\n",
    "print(\"max entropy is: {}\".format(probabability_dict5.calculate_entropy([4])))\n",
    "print(\"the synergy in the distribution is {}\".format(\n",
    "    sum([probabability_dict5.calulate_mutual_information([i], [4]) for i in range(4)])\n",
    "))\n",
    "#print(pdf_extended5.joint_probabilities.joint_probabilities.shape)\n",
    "print(calculate_mi_profile(pdf_extended5, [4]))\n",
    "\n",
    "\n",
    "num_states1 = 2\n",
    "num_variables1 = 2\n",
    "marginal_distributions = np.array(\n",
    "    [\n",
    "        [0.3, 0.7],\n",
    "        [0.5, 0.5],\n",
    "        [0.6, 0.4],\n",
    "        [0.6, 0.4]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"now examing the copy function\")\n",
    "\n",
    "probabilities_arr = FullNestedArrayOfProbabilities(\n",
    "    compute_joint_from_marginals(marginal_distributions[2:])\n",
    ")\n",
    "pdf_extended6 = JointProbabilityMatrixExtended(num_variables1, num_states1, probabilities_arr)\n",
    "pdf_extended6.append_determinstic_function(copy, 2, [2, 2])\n",
    "pdf_extended6.adjust_to_old_format()\n",
    "prob_dict = ProbabilityDict(pdf_extended6.to_dict())\n",
    "prob_dict.print_dict()\n",
    "print(calculate_mi_profile(pdf_extended6, [2, 3], testing=False))\n",
    "\n",
    "print(\"now for the xor function\")\n",
    "\n",
    "probabilities_arr = FullNestedArrayOfProbabilities(\n",
    "    compute_joint_from_marginals(marginal_distributions[2:])\n",
    ")\n",
    "pdf_extended_xor = JointProbabilityMatrixExtended(num_variables1, num_states1, probabilities_arr)\n",
    "pdf_extended_xor.append_determinstic_function(xor, 1, [2])\n",
    "pdf_extended_xor.adjust_to_old_format()\n",
    "prob_dict = ProbabilityDict(pdf_extended_xor.to_dict())\n",
    "prob_dict.print_dict()\n",
    "print(\"the synergy in the distribution is {}\".format(\n",
    "    sum([prob_dict.calulate_mutual_information([i], [2]) for i in range(2)])\n",
    "))\n",
    "\n",
    "print(calculate_mi_profile(pdf_extended_xor, [2], testing=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought: already information about function for zero variables, how to deal with that? Entropy in function would make sense but how to use it I do not know. How far is entropy in function from entropy in totally uniform distributed function? Seems like a reasonable idea, for the zeroth level mi-profile value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add function to go from MI-Profile to information levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def choose(n, m):\n",
    "    if m > n or m < 0 or n < 0:\n",
    "        raise ValueError(\"please provide integers and n bigger equal to m\")\n",
    "        \n",
    "    return math.factorial(n)/(math.factorial(m)*math.factorial(n-m))   \n",
    "\n",
    "mutual_info_profile = [0, 0, 1.0/3.0, 1, 2]\n",
    "mutual_info_profile = mutual_info_profile[1:]\n",
    "number_of_variables = len(mutual_info_profile)\n",
    "\n",
    "first_level = choose(number_of_variables, 1) * mutual_info_profile[0] \n",
    "second_level = (choose(number_of_variables, 2) * mutual_info_profile[1] - \n",
    "                choose(number_of_variables, 2) * choose(2,1) / choose(number_of_variables, 1) * first_level)\n",
    "\n",
    "third_level = (choose(number_of_variables, 3) * mutual_info_profile[2] - \n",
    "               choose(number_of_variables, 3) * choose(3, 2) / choose(number_of_variables, 2) * second_level -\n",
    "               choose(number_of_variables, 3) * choose(3, 1) / choose(number_of_variables, 1) * first_level)\n",
    "\n",
    "third_level = (choose(number_of_variables, 3) * mutual_info_profile[2] - \n",
    "               choose(number_of_variables, 3) * choose(3, 2) / choose(number_of_variables, 2) * second_level -\n",
    "               choose(number_of_variables, 3) * choose(3, 1) / choose(number_of_variables, 1) * first_level)\n",
    "\n",
    "fourth_level = (choose(number_of_variables, 4) * mutual_info_profile[3] - \n",
    "               choose(number_of_variables, 4) * choose(4, 3) / choose(number_of_variables, 3) * third_level -\n",
    "               choose(number_of_variables, 4) * choose(4, 2) / choose(number_of_variables, 2) * second_level -\n",
    "               choose(number_of_variables, 4) * choose(4, 1) * first_level)\n",
    "\n",
    "print(second_level)\n",
    "print(third_level)\n",
    "print(fourth_level)\n",
    "\n",
    "def calculate_information_levels(mutual_information_profile):\n",
    "    information_levels = []\n",
    "    number_of_variables = len(mutual_info_profile)\n",
    "    for i in range(number_of_variables):\n",
    "        print(\"i equals {}\".format(i))\n",
    "        information_level = choose(number_of_variables, i+1) * mutual_info_profile[i]\n",
    "        j = i\n",
    "        while j > 0: \n",
    "            information_level = information_level - (choose(number_of_variables, i+1) * choose(i+1, j) / \n",
    "                                choose(number_of_variables, j) * information_levels[j-1])\n",
    "            j = j-1\n",
    "            \n",
    "        information_levels.append(information_level)\n",
    "    \n",
    "    return information_levels\n",
    "        \n",
    "print(calculate_information_levels(mutual_info_profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marginal_distributions = np.array(\n",
    "    [\n",
    "        [0.3, 0.7],\n",
    "        [0.4, 0.6],\n",
    "        [0.6, 0.4],\n",
    "        [0.6, 0.4]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"now examing the copy function\")\n",
    "probabilities_arr = FullNestedArrayOfProbabilities(\n",
    "    compute_joint_from_marginals(marginal_distributions[2:])\n",
    ")\n",
    "pdf_extended6 = JointProbabilityMatrixExtended(num_variables1, num_states1, probabilities_arr)\n",
    "pdf_extended6.append_determinstic_function(copy, 2, [2, 2])\n",
    "pdf_extended6.adjust_to_old_format()\n",
    "prob_dict = ProbabilityDict(pdf_extended6.to_dict())\n",
    "prob_dict.print_dict()\n",
    "print(calculate_mi_profile(pdf_extended6, [2, 3], testing=False))\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"now for the xor function\")\n",
    "probabilities_arr = FullNestedArrayOfProbabilities(\n",
    "    compute_joint_from_marginals(marginal_distributions[2:])\n",
    ")\n",
    "pdf_extended7 = JointProbabilityMatrixExtended(num_variables1, num_states1, probabilities_arr)\n",
    "pdf_extended7.append_determinstic_function(xor, 1, [2])\n",
    "pdf_extended7.adjust_to_old_format()\n",
    "prob_dict = ProbabilityDict(pdf_extended7.to_dict())\n",
    "prob_dict.print_dict()\n",
    "print(\"the synergy in the distribution is {}\".format(\n",
    "    sum([prob_dict.calulate_mutual_information([i], [2]) for i in range(2)])\n",
    "))\n",
    "\n",
    "print(calculate_mi_profile(pdf_extended7, [2], testing=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
