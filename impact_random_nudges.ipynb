{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook aims to find the impact of random nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import probability_distributions\n",
    "import maximum_nudges\n",
    "import evolutionary_algorithms as ea\n",
    "import maximum_synergistic_nudge_evolutionary as synergistic_nudge_ev\n",
    "import maximum_nudges_evolutionary as ev_max_nudges\n",
    "import nudge\n",
    "import nudge_non_causal\n",
    "import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook level constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUDGE_SIZE = 0.01\n",
    "PATH_TO_DISTRIBUTIONS = \"/home/joboti/azumi_derkjan/master_thesis/code/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_amount_and_size_nudges(total_nudge_size, number_of_states, threshold=10):\n",
    "    \"\"\"\n",
    "    Calculate the nudge size and the number of nudges that need to be performed \n",
    "    to nudge a variable with the total nudge size. Assuming the distribution is\n",
    "    not too peaked, in other words, not too many states should have a probability\n",
    "    that is 10 times smaller than normal.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    total_nudge_size: a number\n",
    "        How much the variable need to be nudged\n",
    "    number_of_states: a number\n",
    "        The total number of states of the joint distribution\n",
    "    threshold: a float \n",
    "        Indicating how much smaller than uniform the value of the number\n",
    "        at the 95-99 percentile of points is. Defaults to 10 \n",
    "        \n",
    "    Returns: local_nudge, number_of_nudges\n",
    "    -------\n",
    "    local_nudge: a number \n",
    "        The size of the local nudge to be performed on the joint distribution\n",
    "    number_of_nudges: integer\n",
    "        How often the nudge need to be performed\n",
    "    \n",
    "    \"\"\"\n",
    "    assumed_min_size = 1.0/threshold\n",
    "    max_local_nudge = min(total_nudge_size, 0.1/number_of_states)\n",
    "    number_of_nudges = int(np.ceil(total_nudge_size/max_local_nudge))\n",
    "    local_nudge = total_nudge_size/float(number_of_nudges) \n",
    "    return local_nudge, number_of_nudges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the random impact of a nudge given the nudge type, the input and conditional output, and nudge size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_nudge_impacts(input_dists, cond_output_dists, nudge_size, nudge_type, \n",
    "                             number_of_samples, backup_filename, parameters):\n",
    "    \"\"\"\n",
    "    Find the maximum impact of the nudges\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    input_dists: list of nd-arrays representing probability distributions\n",
    "    cond_output_dists: list of nd-arrays \n",
    "        Representing output distributions (the last axis) conditioned on the input \n",
    "        distributions\n",
    "    nudge_size: positive float\n",
    "    nudge_type: string\n",
    "        One of the following: {\"individual\", \"focused\", \"local\", \"synergistic\", \"global\"}\n",
    "    number_of_samples: int\n",
    "    filename_to_save: string, \n",
    "        Should be a valid path\n",
    "    parameters: a dict,\n",
    "        The parameters used to find the maximum nudge\n",
    "    \n",
    "    \"\"\"\n",
    "    dist_impacts = []\n",
    "    missed_weight_dist = 0\n",
    "    for input_dist, cond_output in zip(input_dists, cond_output_dists):\n",
    "        print(\"count {}\".format(len(dist_impacts)))\n",
    "        impacts = []\n",
    "        missed_weights = []\n",
    "        for _ in range(number_of_samples):\n",
    "            if nudge_type == \"individual\":\n",
    "                new_dist = nudge_non_causal.nudge_individual_without_conditional(input_dist, nudge_size)\n",
    "            elif nudge_type == \"focused\":\n",
    "                local_nudge_size, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "                    nudge_size/2, input_dist.flatten().shape[0], threshold=parameters[\"threshold\"]\n",
    "                )\n",
    "                num_vars = len(input_dist.shape)\n",
    "                new_dist = nudge.nudge_distribution_local_non_causal(\n",
    "                    input_dist, num_vars-1, local_nudge_size, number_of_nudges\n",
    "                )\n",
    "            elif nudge_type == \"local\":\n",
    "                new_dist = nudge_non_causal.nudge_local(\n",
    "                    input_dist, nudged_vars=parameters[\"nudged_vars\"], nudge_size=nudge_size,\n",
    "                    without_conditional=True\n",
    "                )\n",
    "            elif nudge_type == \"synergistic\":\n",
    "                new_dist = np.copy(input_dist)\n",
    "                for _ in range(parameters[\"max_number_of_mutations\"]):\n",
    "                    nudge_non_causal.synergistic_mutate(\n",
    "                        new_dist, parameters[\"mutation_size\"]\n",
    "                    )\n",
    "                    new_nudge_size = np.sum(abs(new_dist-input_dist))\n",
    "                    adjustment_factor = nudge_size/new_nudge_size\n",
    "                    if adjustment_factor <= 1:\n",
    "                        new_dist = input_dist + (new_dist-input_dist)*adjustment_factor\n",
    "                        break\n",
    "\n",
    "                if adjustment_factor > 1:\n",
    "                    print(\"WARNING: nudge size only {} percent of intended nudge size\".format(adjustment_factor))\n",
    "            elif nudge_type == \"global\":\n",
    "                new_dist = nudge_non_causal.nudge_global(input_dist, nudge_size, without_conditional=True)\n",
    "            else:\n",
    "                raise ValueError(\"provide a valid nudge type\")\n",
    "\n",
    "            l1_norm_to_old_distribution = np.sum(np.absolute(input_dist-new_dist))\n",
    "            impacts.append(nudge_non_causal.find_nudge_impact(input_dist, new_dist, cond_output))\n",
    "            missed_weights.append(abs(l1_norm_to_old_distribution-NUDGE_SIZE))\n",
    "\n",
    "        print(\"the nudge impact {}\".format(np.mean(impacts)))\n",
    "        if np.mean(missed_weights) > nudge_size/100:\n",
    "            print(\"WARNING missed weight equals {} percentage of nudge_size\".format(\n",
    "                (np.mean(missed_weights)/nudge_size) * 100\n",
    "            ))\n",
    "        \n",
    "        missed_weight_dist += np.mean(missed_weights)\n",
    "        dist_impacts.append(np.mean(impacts))\n",
    "        with open(backup_filename, 'w') as f:\n",
    "            json.dump(impacts, f, indent=4)\n",
    "        \n",
    "    print(\"total missed weight {}\".format(missed_weight_dist))\n",
    "    return dist_impacts, missed_weight_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the data and run the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First for system distributions with limited entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_MAX_ENTROPY_SIZE = 90\n",
    "NUMBER_OF_VARS = 7\n",
    "NUMBER_OF_STATES = 3\n",
    "FILENAME_FORMAT_INPUT = \"input_dist_{}.npy\"\n",
    "FILENAME_FORMAT_OUTPUT = \"cond_output_dist_{}.npy\"\n",
    "DIST_START = 100\n",
    "DIST_END = 200\n",
    "NUDGE_TYPE = \"synergistic\"\n",
    "NUMBER_OF_SAMPLES = 100\n",
    "\n",
    "MAX_NUMBER_OF_MUTATIONS = 729\n",
    "MUTATION_SIZE = NUDGE_SIZE/243\n",
    "THRESHOLD = 150\n",
    "\n",
    "distribution_numbers = list(range(DIST_START, DIST_END, 1))\n",
    "if NUDGE_TYPE == \"global\" or NUDGE_TYPE ==\"individual\": \n",
    "    parameters = None\n",
    "elif NUDGE_TYPE== \"focused\":\n",
    "    parameters = {\n",
    "        \"threshold\": THRESHOLD\n",
    "    }\n",
    "elif NUDGE_TYPE == \"local\":\n",
    "    parameters = {\n",
    "        \"nudged_vars\": list(range(NUMBER_OF_VARS-1))\n",
    "    }\n",
    "elif NUDGE_TYPE == \"synergistic\":\n",
    "    parameters = {\n",
    "        \"max_number_of_mutations\": MAX_NUMBER_OF_MUTATIONS,\n",
    "        \"mutation_size\": MUTATION_SIZE\n",
    "    }\n",
    "\n",
    "backup_filename = (\"data_experiments/\" + \n",
    "    \"backup_random_impacts_{}var_{}states_{}entropy_{}_nudge_dists{}-{}.json\".format(\n",
    "        NUMBER_OF_VARS, NUMBER_OF_STATES, PERCENTAGE_MAX_ENTROPY_SIZE, NUDGE_TYPE, DIST_START, DIST_END \n",
    "    )\n",
    ")\n",
    "path_to_limited_entropy_system_dists = (\n",
    "    PATH_TO_DISTRIBUTIONS + \"system_distributions/\" \n",
    "    + \"limited_entropy/\"\n",
    ")\n",
    "\n",
    "input_dists = get_data.get_system_distributions_limited_entropy(\n",
    "    path_to_limited_entropy_system_dists, PERCENTAGE_MAX_ENTROPY_SIZE,\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, FILENAME_FORMAT_INPUT, \n",
    "    distribution_numbers\n",
    ")\n",
    "output_dists = get_data.get_system_distributions_limited_entropy(\n",
    "    path_to_limited_entropy_system_dists, PERCENTAGE_MAX_ENTROPY_SIZE,\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, FILENAME_FORMAT_OUTPUT, \n",
    "    distribution_numbers\n",
    ")\n",
    "\n",
    "impacts, missed_weight = get_random_nudge_impacts(\n",
    "    input_dists, output_dists, NUDGE_SIZE, NUDGE_TYPE, \n",
    "    NUMBER_OF_SAMPLES, backup_filename, parameters\n",
    ")\n",
    "\n",
    "print(impacts)\n",
    "filename_to_save_impacts =  \"random_impacts_{}var_{}states_{}entropy_{}_nudge_dists{}-{}.json\".format(\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, PERCENTAGE_MAX_ENTROPY_SIZE, NUDGE_TYPE, DIST_START, DIST_END \n",
    ")\n",
    "with open(\"data_experiments/\" + filename_to_save_impacts, 'w') as f:\n",
    "    json.dump(impacts, f)\n",
    "    \n",
    "filename_to_save_missed_weight =  \"missed_weight_{}var_{}states_{}entropy_{}_nudge_dists{}-{}.json\".format(\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, PERCENTAGE_MAX_ENTROPY_SIZE, NUDGE_TYPE, DIST_START, DIST_END \n",
    ")\n",
    "with open(\"data_experiments/\" + filename_to_save_missed_weight, 'w') as f:\n",
    "    json.dump(missed_weight, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "PERCENTAGE_MAX_ENTROPY_SIZE = 75\n",
    "input_dists = get_data.get_system_distributions_limited_entropy(\n",
    "    path_to_limited_entropy_system_dists, PERCENTAGE_MAX_ENTROPY_SIZE,\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, FILENAME_FORMAT_INPUT, \n",
    "    distribution_numbers\n",
    ")\n",
    "\n",
    "output_dists = get_data.get_system_distributions_limited_entropy(\n",
    "    path_to_limited_entropy_system_dists, PERCENTAGE_MAX_ENTROPY_SIZE,\n",
    "    NUMBER_OF_VARS, NUMBER_OF_STATES, FILENAME_FORMAT_OUTPUT, \n",
    "    distribution_numbers\n",
    ")\n",
    "\n",
    "for input_dist, cond_output in zip(input_dists, output_dists):\n",
    "    joint = probability_distributions.compute_joint(input_dist, cond_output, set(list(range(NUMBER_OF_VARS-1)))) \n",
    "    print(\"goal entropy {}\".format(0.75*np.log2(joint.flatten().shape[0])))\n",
    "    print(stats.entropy(joint.flatten(), base=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
