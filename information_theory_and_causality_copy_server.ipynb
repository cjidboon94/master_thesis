{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information theory and nudge impact\n",
    "\n",
    "This notebook has as purpose to research the relation between information theoretical measures \n",
    "(mostly mutual information) and nudge impact of different nudges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from jointpdf.jointpdf import JointProbabilityMatrix\n",
    "from jointpdf.jointpdf import NestedArrayOfProbabilities\n",
    "from jointpdf.jointpdf import FullNestedArrayOfProbabilities\n",
    "from extension_probability_matrix import JointProbabilityMatrixExtended\n",
    "\n",
    "import probability_distributions\n",
    "from probability_distributions import ProbabilityArray\n",
    "import nudge\n",
    "import nudge_non_causal as nudge_new\n",
    "import plotting\n",
    "import simulate\n",
    "from information_theory import calculate_mutual_information\n",
    "import information_theory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_amount_and_size_nudges(total_nudge_size, number_of_states, threshold=10):\n",
    "    \"\"\"\n",
    "    Calculate the nudge size and the number of nudges that need to be performed \n",
    "    to nudge a variable with the total nudge size. Assuming the distribution is\n",
    "    not too peaked, in other words, not too many states should have a probability\n",
    "    that is 10 times smaller than normal.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    total_nudge_size: a number\n",
    "        How much the variable need to be nudged\n",
    "    number_of_states: a number\n",
    "        The total number of states of the joint distribution\n",
    "    threshold: a float \n",
    "        Indicating how much smaller than uniform the value of the number\n",
    "        at the 95-99 percentile of points is. Defaults to 10 \n",
    "        \n",
    "    Returns: local_nudge, number_of_nudges\n",
    "    -------\n",
    "    local_nudge: a number \n",
    "        The size of the local nudge to be performed on the joint distribution\n",
    "    number_of_nudges: integer\n",
    "        How often the nudge need to be performed\n",
    "    \n",
    "    \"\"\"\n",
    "    assumed_min_size = 1.0/threshold\n",
    "    max_local_nudge = min(total_nudge_size, 0.1/number_of_states)\n",
    "    number_of_nudges = int(np.ceil(total_nudge_size/max_local_nudge))\n",
    "    local_nudge = total_nudge_size/float(number_of_nudges) \n",
    "    return local_nudge, number_of_nudges\n",
    "\n",
    "def generate_distribution(shape, method, arguments=None):\n",
    "    if method=='random_biased':\n",
    "        distribution = np.random.random(shape)\n",
    "        distribution = distribution/np.sum(distribution)\n",
    "        return distribution\n",
    "    elif method=='random_dirichlet':\n",
    "        return probability_distributions.compute_joint_uniform_random(shape)\n",
    "    elif method=='fixed_entropy':\n",
    "        return probability_distributions.generate_probability_distribution_with_certain_entropy(\n",
    "            shape, arguments['entropy_size']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('provide a valid method')\n",
    "        \n",
    "def percentage_max_entropy(shape, percentage):\n",
    "    \"\"\" \n",
    "    Return the percentage of the max-entropy given the shape\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    shape: iterable\n",
    "    percentage: float\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.log2(reduce(lambda x,y: x*y, shape)) * percentage\n",
    "\n",
    "def percentage_states_max_entropy(shape, percentage):\n",
    "    \"\"\" \n",
    "    Return the percentage of the max-entropy given the shape\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    shape: iterable\n",
    "    percentage: float\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.log2(reduce(lambda x,y: x*y, shape) * percentage)\n",
    "\n",
    "def transfer_ndarray_to_joint_probability_matrix(array):\n",
    "    \"\"\"\n",
    "    array: nd-array\n",
    "        All axis should have the same size\n",
    "        \n",
    "    \"\"\"\n",
    "    shape = array.shape\n",
    "    if not all([item==shape[0] for item in shape]):\n",
    "        raise ValueError(\"all variables need to have same number of states\")\n",
    "    \n",
    "    number_of_variables = len(shape) \n",
    "    number_of_states = shape[0]\n",
    "    return JointProbabilityMatrix(number_of_variables, number_of_states, array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1:\n",
    "\n",
    "How do mutual information and nudge impact relate for one input variable and one output variable.\n",
    "The joint of the input and output variables is generated randomly biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_of_nudge_1d(distribution, nudge_size):\n",
    "    \"\"\"\n",
    "    Nudge the input variable and calculate the effect on the output variable\n",
    "    (the KL-devergence of the output variable)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a numpy array\n",
    "        It should represent the joint probability distribution of 1 input\n",
    "        (the first axis) and 1 output variable (the second axis).\n",
    "    nudge_size: a number\n",
    "    \n",
    "    Returns: a number\n",
    "    \"\"\"\n",
    "    probability_array_old = ProbabilityArray(distribution)\n",
    "    marginal_variable_old = probability_array_old.marginalize(set([0]))\n",
    "    marginal_function_old = probability_array_old.marginalize(set([1]))\n",
    "    conditional_joint_old, marginal_labels_old, conditional_labels_old = (\n",
    "        probability_array_old.find_conditional(set([1]), set([0]))\n",
    "    )\n",
    "    marginal_variable_nudged, nudges_states = nudge.nudge(\n",
    "        marginal_variable_old, nudge_size\n",
    "    )\n",
    "    joint_new = ProbabilityArray(probability_distributions.compute_joint(\n",
    "        marginal_variable_nudged, conditional_joint_old, conditional_labels_old\n",
    "    ))\n",
    "    marginal_function_new = joint_new.marginalize(set([1]))  \n",
    "    kl_variable = entropy(marginal_variable_old, marginal_variable_nudged)\n",
    "    kl_function = entropy(marginal_function_old, marginal_function_new) \n",
    "    return kl_variable, kl_function\n",
    "\n",
    "#this is a biased result replace by dirichlet distribution\n",
    "#pdf = JointProbabilityMatrix(1, 10, 'random')\n",
    "\n",
    "#non-biased result\n",
    "number_of_input_vars = 1\n",
    "number_of_states = 5\n",
    "dist = np.random.dirichlet([1] * number_of_states**number_of_input_vars)\n",
    "pdf = transfer_ndarray_to_joint_probability_matrix(dist)\n",
    "\n",
    "print(\"looking for targer mi\")\n",
    "pdf.append_variables_with_target_mi(1, 0.5)\n",
    "print(\"found target mi\")\n",
    "distribution = pdf.joint_probabilities.joint_probabilities\n",
    "effect_of_nudge_1d(distribution, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform actual experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see whether and how mutual information and response to the nudge co-depend\n",
    "NUMBER_OF_STATES, NUDGE_SIZE = 5, 0.01\n",
    "number_of_input_vars = 1\n",
    "mutual_information_sizes = np.arange(0.05, 1, 0.05)\n",
    "#mutual_information_sizes = np.arange(0.5, 1, 0.05)\n",
    "sample_size = 5\n",
    "effect_nudge_given_mi = {}\n",
    "\n",
    "RUN = False\n",
    "if RUN:\n",
    "    for mutual_information_size in mutual_information_sizes:\n",
    "        print(\"the mutual information size is {}\".format(mutual_information_size))\n",
    "        nudge_effects = []\n",
    "        for sample in range(sample_size):\n",
    "            #pdf = JointProbabilityMatrix(1, NUMBER_OF_STATES, 'random')\n",
    "            dist = np.random.dirichlet([1] * NUMBER_OF_STATES**number_of_input_vars)\n",
    "            pdf = transfer_ndarray_to_joint_probability_matrix(dist)\n",
    "\n",
    "            pdf.append_variables_with_target_mi(1, mutual_information_size)\n",
    "            distribution = pdf.joint_probabilities.joint_probabilities\n",
    "            output_marginal = probability_distributions.ProbabilityArray(distribution).marginalize(set([1]))\n",
    "            if np.any(output_marginal < 0.01):\n",
    "                continue\n",
    "\n",
    "            nudge_impact = np.mean([effect_of_nudge_1d(distribution, 0.01)[1] for _ in range(30)])\n",
    "            nudge_effects.append(nudge_impact)\n",
    "\n",
    "        effect_nudge_given_mi[mutual_information_size] = nudge_effects\n",
    "        with open(\"data_experiments/relation_MI_nudge_impact_1input_non_biased3.json\", 'w') as f:\n",
    "            json.dump(effect_nudge_given_mi, f)\n",
    "\n",
    "    #print(effect_nudge_given_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    plot_range, mean, std, batches_stc = simulate.find_mean_std_mse(\n",
    "        effect_nudge_given_mi, \n",
    "    )\n",
    "    print(mean)\n",
    "    import scipy\n",
    "    print()\n",
    "    scipy.stats.linregress(plot_range, mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "#### mutual information between output and individual input for fixed total entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "The relation between nudge impact and the mutual information between the output variable and\n",
    "the nudged input variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 1, 5, 0.01\n",
    "shape = tuple([NUMBER_OF_STATES]*(NUMBER_OF_VARIABLES+1))\n",
    "NUMBER_OF_SAMPLES = 200\n",
    "\n",
    "PERCENTAGE_MAX_ENTROPY = 0.75\n",
    "SAMPLES_TO_ESTIMATE_NUDGE_IMPACT = 1000\n",
    "MIN_PROBABILITY_OUTPUT_STATE = 0.01\n",
    "\n",
    "local_nudge_size, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "    TOTAL_NUDGE_SIZE, NUMBER_OF_STATES**NUMBER_OF_VARIABLES\n",
    ")\n",
    "impact_nudges_and_mi = []\n",
    "\n",
    "DATA_PATH = \"data_experiments/\"\n",
    "FILE_NAME = \"correlation_MI_individual_nudge_impact_1var_5states_min_output001.json\"\n",
    "RUN = False\n",
    "if RUN:\n",
    "    for i in range(NUMBER_OF_SAMPLES):\n",
    "        if i%2==0 and i != 0:\n",
    "            print(\"sample number {}\".format(i))\n",
    "\n",
    "        #calculate the distribution\n",
    "        #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "        distribution = ProbabilityArray(generate_distribution(\n",
    "                shape, 'fixed_entropy', \n",
    "                {\"entropy_size\":percentage_max_entropy(shape, PERCENTAGE_MAX_ENTROPY)}\n",
    "        ))\n",
    "        function_label, label_nudged_variable = NUMBER_OF_VARIABLES, 0\n",
    "        function_labels = set([function_label])\n",
    "        input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "        \n",
    "        output_marginal = distribution.marginalize(function_labels)\n",
    "        if np.any(output_marginal < MIN_PROBABILITY_OUTPUT_STATE):\n",
    "            continue\n",
    "            print(\"dismissing output\")\n",
    "\n",
    "        #calculate mutual information\n",
    "        mutual_information = calculate_mutual_information(distribution, \n",
    "                                                          set([function_label]),\n",
    "                                                          set([label_nudged_variable]))\n",
    "\n",
    "        #calculate_nudge_impact\n",
    "        input_distribution = distribution.marginalize(input_variable_labels)\n",
    "        nudge_impacts = []\n",
    "        for _ in range(SAMPLES_TO_ESTIMATE_NUDGE_IMPACT):\n",
    "            new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "                input_distribution, 0, local_nudge_size, number_of_nudges\n",
    "            )\n",
    "            nudge_impacts.append(nudge.impact_nudge_causal_output(\n",
    "                distribution, function_labels, new_input_distribution\n",
    "            ))\n",
    "        nudge_impact = np.mean(nudge_impacts)\n",
    "        impact_nudges_and_mi.append((nudge_impact, mutual_information))\n",
    "        with open(DATA_PATH + FILE_NAME, 'w') as f:\n",
    "            json.dump(impact_nudges_and_mi, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "if RUN:\n",
    "    impact_nudges = [item[0] for item in impact_nudges_and_mi] \n",
    "    mutual_information_sizes = [item[1] for item in impact_nudges_and_mi]\n",
    "    plt.plot(mutual_information_sizes, impact_nudges, 'o')\n",
    "    plt.show()\n",
    "\n",
    "    scipy.stats.linregress(impact_nudges, mutual_information_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same experiment for vector nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 1, 5, 0.01\n",
    "shape = tuple([NUMBER_OF_STATES]*(NUMBER_OF_VARIABLES+1))\n",
    "NUMBER_OF_SAMPLES = 6\n",
    "\n",
    "PERCENTAGE_MAX_ENTROPY = 0.75\n",
    "SAMPLES_TO_ESTIMATE_NUDGE_IMPACT = 500\n",
    "MIN_PROBABILITY_OUTPUT_STATE = 0.01\n",
    "\n",
    "local_nudge_size, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "    TOTAL_NUDGE_SIZE, NUMBER_OF_STATES**NUMBER_OF_VARIABLES\n",
    ")\n",
    "impact_nudges_and_mi = []\n",
    "\n",
    "DATA_PATH = \"data_experiments/\"\n",
    "FILE_NAME = \"correlation_MI_individual_vector_nudge_impact_1var_5states_min_output001.json\"\n",
    "RUN = True\n",
    "if RUN:\n",
    "    for i in range(NUMBER_OF_SAMPLES):\n",
    "        if i%2==0 and i != 0:\n",
    "            print(\"sample number {}\".format(i))\n",
    "\n",
    "        #calculate the distribution\n",
    "        #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "        distribution = ProbabilityArray(generate_distribution(\n",
    "                shape, 'fixed_entropy', \n",
    "                {\"entropy_size\":percentage_max_entropy(shape, PERCENTAGE_MAX_ENTROPY)}\n",
    "        ))\n",
    "        function_label, label_nudged_variable = NUMBER_OF_VARIABLES, 0\n",
    "        function_labels = set([function_label])\n",
    "        input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "        \n",
    "        output_marginal = distribution.marginalize(function_labels)\n",
    "        if np.any(output_marginal < MIN_PROBABILITY_OUTPUT_STATE):\n",
    "            continue\n",
    "            print(\"dismissing output\")\n",
    "\n",
    "        #calculate mutual information\n",
    "        mutual_information = calculate_mutual_information(distribution, \n",
    "                                                          set([function_label]),\n",
    "                                                          set([label_nudged_variable]))\n",
    "\n",
    "        #calculate_nudge_impact\n",
    "        input_distribution = distribution.marginalize(input_variable_labels)\n",
    "        cond_output, marginal_labels, cond_labels = distribution.find_conditional(\n",
    "            function_labels, input_variable_labels\n",
    "        )\n",
    "        nudge_impacts = []\n",
    "        for _ in range(SAMPLES_TO_ESTIMATE_NUDGE_IMPACT):\n",
    "            new_input_distribution = nudge_new.nudge_individual_without_conditional(\n",
    "                input_distribution, TOTAL_NUDGE_SIZE\n",
    "            )\n",
    "            nudge_impact = nudge_new.find_nudge_impact(\n",
    "                input_distribution, new_input_distribution, cond_output, measure=\"kl-divergence\"\n",
    "            )\n",
    "            nudge_impacts.append(nudge_impact)\n",
    "            \n",
    "        nudge_impact = np.mean(nudge_impacts)\n",
    "        impact_nudges_and_mi.append((nudge_impact, mutual_information))\n",
    "        with open(DATA_PATH + FILE_NAME, 'w') as f:\n",
    "            json.dump(impact_nudges_and_mi, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "if RUN:\n",
    "    impact_nudges = [item[0] for item in impact_nudges_and_mi] \n",
    "    mutual_information_sizes = [item[1] for item in impact_nudges_and_mi]\n",
    "    plt.plot(mutual_information_sizes, impact_nudges, 'o')\n",
    "    plt.show()\n",
    "\n",
    "    print(scipy.stats.linregress(impact_nudges, mutual_information_sizes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
