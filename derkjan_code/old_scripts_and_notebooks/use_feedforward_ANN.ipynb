{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired on the notebook for the first assignment of the deep learning part of the AI master program of the University of Amsterdam. However, I made several changes to it (adjusting it to python 3, adding and deleting things etc.). The main purpose of the notebook is to check whether my own implementation of a neural network is correct and has the accuracy it should have.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting configuration for matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "\n",
    "from feedforward_ANN.cifar10_utils import get_cifar10_raw_data, preprocess_cifar10_data\n",
    "from feedforward_ANN.cifar10_utils import transform_label_encoding_to_one_hot\n",
    "from feedforward_ANN.layer import LinearLayer, ReLuLayer, TanHLayer\n",
    "from feedforward_ANN.network import Network\n",
    "from feedforward_ANN.train import SGD\n",
    "from feedforward_ANN.loss import SoftmaxCrossEntropyLoss\n",
    "from feedforward_ANN.score import get_accuracy as get_accuracy2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_raw, Y_train_raw, X_test_raw, Y_test_raw = get_cifar10_raw_data()\n",
    "\n",
    "#Checking shapes, should be (50000, 32, 32, 3), (50000, ), (10000, 32, 32, 3), (10000, )\n",
    "print('Train data shape: {}'.format(X_train_raw.shape))\n",
    "print('Train labels shape: {}'.format(Y_train_raw.shape))\n",
    "print('Test data shape: {}'.format(X_test_raw.shape))\n",
    "print('Test labels shape: {}'.format(Y_test_raw.shape))\n",
    "#Y_train_raw, Y_test_raw have values ranging from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize CIFAR10 data\n",
    "samples_per_class = 10\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "num_classes = len(classes)\n",
    "can = np.zeros((320, 320, 3),dtype='uint8')\n",
    "for i, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(Y_train_raw == i) \n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace = False)\n",
    "    for j in range(samples_per_class):\n",
    "        can[32 * i:32 * (i + 1), 32 * j:32 * (j + 1),:] = X_train_raw[idxs[j]]\n",
    "plt.xticks([], [])\n",
    "plt.yticks(range(16, 320, 32), classes)\n",
    "plt.title('CIFAR10', fontsize = 20)\n",
    "plt.imshow(can)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = preprocess_cifar10_data(\n",
    "    X_train_raw, Y_train_raw, X_test_raw, Y_test_raw, num_val = 1000\n",
    ")\n",
    "\n",
    "#Checking shapes, should be (49000, 3072), (49000, ), (1000, 3072), (1000, ), (10000, 3072), (10000, ) \n",
    "print('Train data shape: {}'.format(X_train.shape))\n",
    "print('Train labels shape: {}'.format(Y_train.shape))\n",
    "print('Val data shape: {}'.format(X_val.shape))\n",
    "print('Val labels shape: {}'.format(Y_val.shape))\n",
    "print('Test data shape: {}'.format(X_test.shape))\n",
    "print('Test labels shape: {}'.format(Y_test.shape))\n",
    "\n",
    "num_classes = 10\n",
    "Y_train_one_hot = transform_label_encoding_to_one_hot(Y_train, num_classes)\n",
    "Y_val_one_hot = transform_label_encoding_to_one_hot(Y_val, num_classes)\n",
    "Y_test_one_hot = transform_label_encoding_to_one_hot(Y_test, num_classes)\n",
    "\n",
    "print('Train labels one hot shape: {}'.format(Y_train_one_hot.shape))\n",
    "print('Val labels one hot shape: {}'.format(Y_val_one_hot.shape))\n",
    "print('Test labels one hot shape: {}'.format(Y_test_one_hot.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_accuracy(network, X, y):\n",
    "    network.update_batch_size(1)\n",
    "    correct_classified = 0\n",
    "    for count in range(X.shape[0]):\n",
    "        if np.argmax(network.forward(np.array([X[count]])))==y[count]:\n",
    "            correct_classified += 1\n",
    "\n",
    "    #print(\"the accuracy on the dataset is {}\".format(correct_classified/X.shape[0]))\n",
    "    network.update_batch_size(network.batch_size)\n",
    "    return correct_classified/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default parameters. \n",
    "num_iterations = 25\n",
    "val_iteration = 100\n",
    "batch_size = 200\n",
    "learning_rate = 1e-7\n",
    "weight_decay = 3e+4\n",
    "weight_scale = 0.0001\n",
    "N = X_train[0].shape[0]\n",
    "\n",
    "params_lin_layer = {\n",
    "    \"w_std\": weight_scale\n",
    "}\n",
    "\n",
    "network = Network(batch_size, weight_decay, train_mode=True)\n",
    "network.add_layer('linear', num_classes, input_dim=N, \n",
    "                  params=params_lin_layer)\n",
    "network.add_loss(SoftmaxCrossEntropyLoss())\n",
    "sgd = SGD(network, X_train, Y_train_one_hot, batch_size)\n",
    "\n",
    "accuracy = get_accuracy(network, X_val, Y_val)\n",
    "for i in range(12):\n",
    "    sgd.train(num_iterations, learning_rate)\n",
    "    print(get_accuracy(network, X_val, Y_val))\n",
    "\n",
    "    \n",
    "def check_derivative():\n",
    "    batch_data = get_batch_data()\n",
    "\n",
    "    z = network.forward(batch_data[0])\n",
    "    network.loss.compute_loss(z, batch_data[1])\n",
    "    network.backward()\n",
    "    dW = np.mean(network.layers[0].dW, axis=0)\n",
    "    print(dW[1,1])\n",
    "\n",
    "    delta = 0.0001\n",
    "\n",
    "    network.layers[0].W[0,0] += delta\n",
    "    z = network.forward(batch_data[0])\n",
    "    loss1 = network.loss.compute_loss(z, batch_data[1])\n",
    "\n",
    "    network.layers[0].W[0,0] -= 2*delta\n",
    "    z = network.forward(batch_data[0])\n",
    "    loss2 = network.loss.compute_loss(z, batch_data[1])\n",
    "\n",
    "    print(loss1)\n",
    "    print(loss2)\n",
    "    print((loss1-loss2) / (2*delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network.layers[0].data[\"batch_size\"] = 1\n",
    "\n",
    "correct_classified = 0\n",
    "for count in range(X_val.shape[0]):\n",
    "    if np.argmax(network.forward(np.array([X_val[count]])))==Y_val[count]:\n",
    "        correct_classified += 1\n",
    "        \n",
    "print(\"the accuracy is {}\".format(correct_classified/X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now try tuning the parameters to get the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default parameters. \n",
    "num_iterations = 50\n",
    "val_iteration = 100\n",
    "batch_size = 100\n",
    "weight_scale = 0.0001\n",
    "N = X_train[0].shape[0]\n",
    "\n",
    "learning_rates = [1e-6, 5*1e-6, 1e-7, 5*1e-7, 1e-8]\n",
    "weight_decays = np.linspace(0, 3e+04, 5)\n",
    "\n",
    "best_val_acc = -1\n",
    "best_solver = None\n",
    "for learning_rate in learning_rates:\n",
    "    for weight_decay in weight_decays:\n",
    "        network = Network(batch_size, weight_decay, train_mode=True)\n",
    "        network.add_layer(LinearLayer(input_dim=N, output_dim=num_classes, \n",
    "                          batch_size=100, weight_scale=weight_scale))\n",
    "        network.add_loss(SoftmaxCrossEntropyLoss())\n",
    "        sgd = SGD(network, X_train, Y_train_one_hot, batch_size)\n",
    "\n",
    "        for i in range(10):\n",
    "            sgd.train(num_iterations, learning_rate)\n",
    "            accuracy = get_accuracy(network, X_val, Y_val)\n",
    "        \n",
    "        print(accuracy)\n",
    "        print(best_val_acc)\n",
    "        if best_val_acc < accuracy:\n",
    "            best_val_acc = accuracy\n",
    "            print(\"the best accuracy is now {:.4f}\".format(accuracy))\n",
    "            best_solver = (learning_rate, weight_decay)\n",
    "        \n",
    "print(\"Learning rate = {0:e}, weight decay = {1:e}: Validation Accuracy = {2:.3f}\".format(\n",
    "    learning_rate, weight_decay, cur_val_acc)\n",
    ")    \n",
    "\n",
    "########################################################################################\n",
    "# TODO:                                                                                #\n",
    "# Compute the accuracy on the test set for the best solver.                          #\n",
    "########################################################################################\n",
    "test_acc = None\n",
    "########################################################################################\n",
    "#                              END OF YOUR CODE                                        #\n",
    "########################################################################################\n",
    "print(\"Best Test Accuracy = {0:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a multilayer ANN by adding 1 ReLu layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default parameters. \n",
    "num_iterations = 25\n",
    "val_iteration = 100\n",
    "batch_size = 200\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 0\n",
    "weight_scale = 0.0001\n",
    "num_hidden_units = 100\n",
    "\n",
    "N = X_train[0].shape[0]\n",
    "params_lin_layer = {\n",
    "    \"w_std\": weight_scale\n",
    "}\n",
    "\n",
    "network = Network(batch_size, weight_decay, train_mode=True)\n",
    "network.add_layer('linear', num_hidden_units, input_dim=N,\n",
    "                  params=params_lin_layer)\n",
    "network.add_layer('relu')\n",
    "network.add_layer('linear', num_classes, params=params_lin_layer)\n",
    "network.add_loss(SoftmaxCrossEntropyLoss())\n",
    "\n",
    "sgd = SGD(network, X_train, Y_train_one_hot, batch_size)\n",
    "\n",
    "accuracy = get_accuracy(network, X_val, Y_val)\n",
    "for i in range(20):\n",
    "    sgd.train(num_iterations, learning_rate)\n",
    "    train_accuracy = get_accuracy(network, X_train, Y_train)\n",
    "    print(\"the train accuracy is {}\".format(train_accuracy))\n",
    "    val_accuracy = get_accuracy(network, X_val, Y_val)\n",
    "    print(\"the validation accuracy is {}\".format(val_accuracy))\n",
    "    print(get_accuracy2(network, X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
