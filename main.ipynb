{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is inspired on the notebook for the first assignment of the deep learning part of the AI master program of the University of Amsterdam. However, I made several changes to it (adjusting it to python 3, adding and deleting things etc.). The main purpose of the notebook is to check whether my own implementation of a neural network is correct and has the accuracy it should have.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting configuration for matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "\n",
    "from feedforward_ANN.cifar10_utils import get_cifar10_raw_data, preprocess_cifar10_data\n",
    "from feedforward_ANN.cifar10_utils import transform_label_encoding_to_one_hot\n",
    "from feedforward_ANN.layer import LinearLayer, ReLuLayer, TanHLayer\n",
    "from feedforward_ANN.network import Network\n",
    "from feedforward_ANN.train import SGD\n",
    "from feedforward_ANN.loss import SoftmaxCrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_raw, Y_train_raw, X_test_raw, Y_test_raw = get_cifar10_raw_data()\n",
    "\n",
    "#Checking shapes, should be (50000, 32, 32, 3), (50000, ), (10000, 32, 32, 3), (10000, )\n",
    "print('Train data shape: {}'.format(X_train_raw.shape))\n",
    "print('Train labels shape: {}'.format(Y_train_raw.shape))\n",
    "print('Test data shape: {}'.format(X_test_raw.shape))\n",
    "print('Test labels shape: {}'.format(Y_test_raw.shape))\n",
    "#Y_train_raw, Y_test_raw have values ranging from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize CIFAR10 data\n",
    "samples_per_class = 10\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "num_classes = len(classes)\n",
    "can = np.zeros((320, 320, 3),dtype='uint8')\n",
    "for i, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(Y_train_raw == i) \n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace = False)\n",
    "    for j in range(samples_per_class):\n",
    "        can[32 * i:32 * (i + 1), 32 * j:32 * (j + 1),:] = X_train_raw[idxs[j]]\n",
    "plt.xticks([], [])\n",
    "plt.yticks(range(16, 320, 32), classes)\n",
    "plt.title('CIFAR10', fontsize = 20)\n",
    "plt.imshow(can)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = preprocess_cifar10_data(\n",
    "    X_train_raw, Y_train_raw, X_test_raw, Y_test_raw, num_val = 1000\n",
    ")\n",
    "\n",
    "#Checking shapes, should be (49000, 3072), (49000, ), (1000, 3072), (1000, ), (10000, 3072), (10000, ) \n",
    "print('Train data shape: {}'.format(X_train.shape))\n",
    "print('Train labels shape: {}'.format(Y_train.shape))\n",
    "print('Val data shape: {}'.format(X_val.shape))\n",
    "print('Val labels shape: {}'.format(Y_val.shape))\n",
    "print('Test data shape: {}'.format(X_test.shape))\n",
    "print('Test labels shape: {}'.format(Y_test.shape))\n",
    "\n",
    "num_classes = 10\n",
    "Y_train_one_hot = transform_label_encoding_to_one_hot(Y_train, num_classes)\n",
    "Y_val_one_hot = transform_label_encoding_to_one_hot(Y_val, num_classes)\n",
    "Y_test_one_hot = transform_label_encoding_to_one_hot(Y_test, num_classes)\n",
    "\n",
    "print('Train labels one hot shape: {}'.format(Y_train_one_hot.shape))\n",
    "print('Val labels one hot shape: {}'.format(Y_val_one_hot.shape))\n",
    "print('Test labels one hot shape: {}'.format(Y_test_one_hot.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_accuracy(network, X, y):\n",
    "    network.update_batch_size(1)\n",
    "    correct_classified = 0\n",
    "    for count in range(X.shape[0]):\n",
    "        if np.argmax(network.forward(np.array([X_val[count]])))==Y_val[count]:\n",
    "            correct_classified += 1\n",
    "\n",
    "    print(\"the accuracy on the validation set is {}\".format(correct_classified/X_val.shape[0]))\n",
    "    network.update_batch_size(100)\n",
    "    return correct_classified/X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Default parameters. \n",
    "num_iterations = 50\n",
    "val_iteration = 100\n",
    "batch_size = 100\n",
    "learning_rate = 1e-6\n",
    "weight_decay = 3e+4\n",
    "weight_scale = 0.0001\n",
    "N = X_train[0].shape[0]\n",
    "\n",
    "\n",
    "network = Network(train_mode=True)\n",
    "network.add_layer(LinearLayer(input_dim=N, output_dim=num_classes, batch_size=100))\n",
    "network.add_loss(SoftmaxCrossEntropyLoss())\n",
    "sgd = SGD(network, X_train, Y_train_one_hot, batch_size)\n",
    "\n",
    "accuracy = get_accuracy(network, X_val, Y_val)\n",
    "for i in range(10):\n",
    "    sgd.train(num_iterations, learning_rate)\n",
    "    print(\"the accuracy is\")\n",
    "    accuracy = get_accuracy(network, X_val, Y_val)\n",
    "\n",
    "    \n",
    "\n",
    "#def get_batch_data():\n",
    "#    \"\"\"return a batch of data points and classes (of X and y)\"\"\"\n",
    "#    chosen_data_points = np.random.choice(X_train.shape[1], 1)\n",
    "#    return X_train[chosen_data_points], Y_train_one_hot[chosen_data_points]\n",
    "\n",
    "\"\"\"\n",
    "batch_data = get_batch_data()\n",
    "\n",
    "z = network.forward(batch_data[0])\n",
    "network.loss.compute_loss(z, batch_data[1])\n",
    "network.backward()\n",
    "dW = np.mean(network.layers[0].dW, axis=0)\n",
    "print(dW[1,1])\n",
    "\n",
    "delta = 0.0001\n",
    "\n",
    "network.layers[0].W[0,0] += delta\n",
    "z = network.forward(batch_data[0])\n",
    "loss1 = network.loss.compute_loss(z, batch_data[1])\n",
    "\n",
    "network.layers[0].W[0,0] -= 2*delta\n",
    "z = network.forward(batch_data[0])\n",
    "loss2 = network.loss.compute_loss(z, batch_data[1])\n",
    "\n",
    "print(loss1)\n",
    "print(loss2)\n",
    "\n",
    "print((loss1-loss2) / (2*delta))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network.layers[0].data[\"batch_size\"] = 1\n",
    "\n",
    "correct_classified = 0\n",
    "for count in range(X_val.shape[0]):\n",
    "    if np.argmax(network.forward(np.array([X_val[count]])))==Y_val[count]:\n",
    "        correct_classified += 1\n",
    "        \n",
    "print(\"the accuracy is {}\".format(correct_classified/X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
