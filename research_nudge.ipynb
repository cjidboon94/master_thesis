{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import json\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "import powerlaw\n",
    "from jointpdf.jointpdf import JointProbabilityMatrix\n",
    "from jointpdf.jointpdf import FullNestedArrayOfProbabilities\n",
    "\n",
    "from probability_distributions import JointProbabilityMatrixExtended\n",
    "import probability_distributions\n",
    "from probability_distributions import ProbabilityArray\n",
    "from simulate import find_mean_std_mse\n",
    "import nudge\n",
    "\n",
    "import information_theory\n",
    "from information_theory import calculate_mutual_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_of_nudge_1d(distribution, nudge_size):\n",
    "    \"\"\"\n",
    "    Nudge the input variable and calculate the effect on the output variable\n",
    "    (the KL-devergence of the output variable)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a numpy array\n",
    "        It should represent the joint probability distribution of 1 input\n",
    "        (the first axis) and 1 output variable (the second axis).\n",
    "    nudge_size: a number\n",
    "    \n",
    "    Returns: a number\n",
    "    \"\"\"\n",
    "    probability_array_old = ProbabilityArray(distribution)\n",
    "    marginal_variable_old = probability_array_old.marginalize(set([0]))\n",
    "    marginal_function_old = probability_array_old.marginalize(set([1]))\n",
    "    conditional_joint_old, marginal_labels_old, conditional_labels_old = (\n",
    "        probability_array_old.find_conditional(set([1]), set([0]))\n",
    "    )\n",
    "    marginal_variable_nudged, nudges_states = nudge.nudge(\n",
    "        marginal_variable_old, nudge_size\n",
    "    )\n",
    "    joint_new = ProbabilityArray(probability_distributions.compute_joint(\n",
    "        marginal_variable_nudged, conditional_joint_old, conditional_labels_old\n",
    "    ))\n",
    "    marginal_function_new = joint_new.marginalize(set([1]))  \n",
    "    kl_variable = entropy(marginal_variable_old, marginal_variable_nudged)\n",
    "    kl_function = entropy(marginal_function_old, marginal_function_new) \n",
    "    return kl_variable, kl_function\n",
    "\n",
    "pdf = JointProbabilityMatrix(1, 10, 'random')\n",
    "pdf.append_variables_with_target_mi(1, 0.5)\n",
    "distribution = pdf.joint_probabilities.joint_probabilities\n",
    "effect_of_nudge_1d(distribution, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:  \n",
    "How do mutual information and nudge impact relate for one input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see whether and how mutual information and response to the nudge co-depend\n",
    "NUMBER_OF_STATES, NUDGE_SIZE = 6, 0.01\n",
    "mutual_information_sizes = np.arange(0.05, 1, 0.05)\n",
    "sample_size = 1\n",
    "effect_nudge_given_mi = {}\n",
    "for mutual_information_size in mutual_information_sizes:\n",
    "    print(\"the mutual information size is {}\".format(mutual_information_size))\n",
    "    nudge_effects = []\n",
    "    for sample in range(sample_size):\n",
    "        pdf = JointProbabilityMatrix(1, NUMBER_OF_STATES, 'random')\n",
    "        pdf.append_variables_with_target_mi(1, mutual_information_size)\n",
    "        distribution = pdf.joint_probabilities.joint_probabilities\n",
    "        nudge_effects.append(effect_of_nudge_1d(distribution, 0.01)[1])\n",
    "        \n",
    "    effect_nudge_given_mi[mutual_information_size] = nudge_effects\n",
    "    #with open(\"back_up2.json\", 'w') as f:\n",
    "    #    json.dump(effect_nudge_given_mi, f)\n",
    "    \n",
    "#print(effect_nudge_given_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "\n",
    "with open(\"data_1_random_input_1_output_diff_MI.json\", 'r') as f:\n",
    "    first = json.load(f)\n",
    "\n",
    "effect_nudge_given_mi = {}\n",
    "    \n",
    "for k, v in first.items():\n",
    "    effect_nudge_given_mi[float(k)] = v\n",
    "    \n",
    "average_effect_nudge_dict = {k:np.mean(v) for k,v in effect_nudge_given_mi.items()}\n",
    "standard_deviation_effect_nudge_dict = {k:np.std(v) for k,v in effect_nudge_given_mi.items()}\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "batches_mean_squared_error = {}\n",
    "for mi, effect_nudge_list in effect_nudge_given_mi.items():\n",
    "    batched_estimates = []\n",
    "    for i in range(len(effect_nudge_list)/BATCH_SIZE):\n",
    "        batched_estimates.append(\n",
    "            np.mean(effect_nudge_list[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "        )\n",
    "    batches_mean_squared_error[mi] = np.std(batched_estimates)\n",
    "\n",
    "batch_std_effect_nudge_ord_dict = collections.OrderedDict(\n",
    "    sorted(batches_mean_squared_error.items(), key= lambda x: x[0])\n",
    ")    \n",
    "average_effect_nudge_ord_dict = collections.OrderedDict(\n",
    "    sorted(average_effect_nudge_dict.items(), key= lambda x: x[0])\n",
    ")\n",
    "std_effect_nudge_ord_dict = collections.OrderedDict(\n",
    "    sorted(standard_deviation_effect_nudge_dict.items(), key= lambda x: x[0])\n",
    ")\n",
    "\n",
    "mi_values = average_effect_nudge_ord_dict.keys()\n",
    "mean_effect_nudge = average_effect_nudge_ord_dict.values()\n",
    "std_effect_nudge = std_effect_nudge_ord_dict.values()\n",
    "batch_std_effect_nudge = batch_std_effect_nudge_ord_dict.values()\n",
    "\n",
    "xlabel = \"mutual information\"\n",
    "ylabel = \"effect of the nudge\"\n",
    "title = \"Effect of a nudge on input variable on output variable for certain MI\"\n",
    "plotting.plot_mean_and_confidence(\n",
    "    mi_values, mean_effect_nudge, std_effect_nudge,\n",
    "    \"std\", xlabel, ylabel, title\n",
    ")\n",
    "plotting.plot_mean_and_confidence(\n",
    "    mi_values, mean_effect_nudge, batch_std_effect_nudge,\n",
    "    \"MSE\", xlabel, ylabel, title\n",
    ")\n",
    "\n",
    "mi_values1, mean_effect_nudge1, std_effect_nudge1, batch_std_effect_nudge1 = (\n",
    "    find_mean_std_mse(effect_nudge_given_mi, batch_size=30)\n",
    ")\n",
    "\n",
    "#print(np.allclose(mi_values1, mi_values))\n",
    "#print(np.allclose(mean_effect_nudge1, mean_effect_nudge))\n",
    "#print(np.allclose(std_effect_nudge1, std_effect_nudge))\n",
    "#print(np.allclose(batch_std_effect_nudge1, batch_std_effect_nudge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def nudge_distribution_local_non_causal_assume_independence(joint, nudge_label, nudge_size):\n",
    "    \"\"\"\n",
    "    Nudge the marginal and assume independence after the nudge to find the\n",
    "    new joint.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    joint: a numpy array\n",
    "        Representing a discrete probability distribution\n",
    "    nudge_label: an integer\n",
    "    nudge_size: a (small) number\n",
    "    number_of_nudges: an integer\n",
    "    \n",
    "    \"\"\"\n",
    "    other_variables_labels = set(range(len(joint.shape))) - set([nudge_label]) \n",
    "    marginal_nudge_variable = ProbabilityArray(joint).marginalize(nudge_label)\n",
    "    marginal_other_variables = ProbabilityArray(joint).marginalize(other_variables_labels)\n",
    "    marginal_variable_nudged, nudged_states = nudge.nudge(marginal_nudge_variable, nudge_size)\n",
    "    return probability_distributions.compute_joint_from_independent_marginals(\n",
    "        marginal_other_variables, marginal_variable_nudged, sorted(list(label_nudged_variable))\n",
    "    )\n",
    "\n",
    "def nudge_distribution_local_non_causal(joint, nudge_label, nudge_size, number_of_nudges):\n",
    "    \"\"\"\n",
    "    nudge the the variable with nudge label while keeping the \n",
    "    marginal of the other variables constant\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    joint: a numpy array\n",
    "        Representing a discrete probability distribution\n",
    "    nudge_label: an integer\n",
    "    nudge_size: a (small) number\n",
    "    number_of_nudges: an integer\n",
    "    \n",
    "    Returns: a numpy array, representing the nudged probability distribution\n",
    "    \n",
    "    \"\"\"\n",
    "    nudged_joint = np.copy(joint)\n",
    "    nudged_joint = nudged_joint.swapaxes(nudge_label, len(joint.shape)-1)\n",
    "    nudge_states = nudge.select_random_states(nudged_joint.shape[:-1], number_of_nudges) \n",
    "    \n",
    "    nudged_states_marginal = np.random.choice(joint.shape[nudge_label], 2, replace=False)\n",
    "    nudge_state_plus, nudge_state_minus = nudged_states_marginal[0], nudged_states_marginal[1]   \n",
    "    for state in nudge_states:\n",
    "        plus_state = tuple(copy.copy(state) + [nudge_state_plus])\n",
    "        minus_state = tuple(copy.copy(state) + [nudge_state_minus])        \n",
    "        size = min(nudged_joint[minus_state], 1-nudged_joint[plus_state], nudge_size)\n",
    "        nudged_joint[plus_state] += size\n",
    "        nudged_joint[minus_state] -= size\n",
    "    \n",
    "    nudged_joint = nudged_joint.swapaxes(nudge_label, len(joint.shape)-1)\n",
    "    return nudged_joint\n",
    "    \n",
    "def impact_nudge_causal_output(distribution, function_indices, new_input_distribution):\n",
    "    \"\"\"\n",
    "    Calculate the impact of a nudge of the input distribution on the output. \n",
    "    Assuming the output is causally determined using using the input.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a ProbabilityArray object\n",
    "    function_indices: a set of integers\n",
    "    new_input_distribution: a numpy array\n",
    "        It represents the input distribution after the nudge\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    A numpy array representing a probability distribution\n",
    "    \n",
    "    \"\"\"\n",
    "    variable_indices = set(range(len(distribution.probability_distribution.shape))) - function_indices\n",
    "    marginal_output_old = distribution.marginalize(function_indices)\n",
    "    conditional, marginal_labels, conditional_labels = (\n",
    "        distribution.find_conditional(function_indices, variable_indices)\n",
    "    )\n",
    "    distribution_new = ProbabilityArray(probability_distributions.compute_joint(\n",
    "        new_input_distribution, conditional, conditional_labels\n",
    "    ))\n",
    "    marginal_output_new = distribution_new.marginalize(function_indices)  \n",
    "    kl_divergence = entropy(marginal_output_old, marginal_output_new) \n",
    "    return kl_divergence\n",
    "\n",
    "def calculate_amount_and_size_nudges(total_nudge_size, number_of_states):\n",
    "    \"\"\"\n",
    "    Calculate the nudge size and the number of nudges that need to be performed \n",
    "    to nudge a variable with the total nudge size\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    total_nudge_size: a number\n",
    "        How much the variable need to be nudged\n",
    "    number_of_states: a number\n",
    "        The total number of states of the joint distribution\n",
    "        \n",
    "    Returns: local_nudge, number_of_nudges\n",
    "    -------\n",
    "    local_nudge: a number \n",
    "        The size of the local nudge to be performed on the joint distribution\n",
    "    number_of_nudges: integer\n",
    "        How often the nudge need to be performed\n",
    "    \n",
    "    \"\"\"\n",
    "    max_local_nudge = min(total_nudge_size, 0.1/number_of_states)\n",
    "    number_of_nudges = max(int(total_nudge_size/max_local_nudge), 1)\n",
    "    return max_local_nudge, number_of_nudges\n",
    "    \n",
    "def calculate_nudge_impact(number_of_variables, number_of_states, total_nudge_size):\n",
    "    \"\"\" \n",
    "    For now calculate the impact of a local non-causal nudge on the input variables\n",
    "    on the completely causally determined output variable\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    number_of_variables: integer\n",
    "    number_of_states: integer\n",
    "    total_nudge_size: number\n",
    "    \n",
    "    \"\"\"\n",
    "    total_number_of_states = number_of_states**number_of_variables\n",
    "    max_local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "    pdf = JointProbabilityMatrix(number_of_variables+1, number_of_states, 'random')\n",
    "    distribution = ProbabilityArray(pdf.joint_probabilities.joint_probabilities)\n",
    "    function_labels, label_nudged_variable = set([number_of_variables]), 0\n",
    "    input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge_distribution_local_non_causal(\n",
    "        input_distribution, 0, max_local_nudge, number_of_nudges\n",
    "    )\n",
    "    return impact_nudge_causal_output(distribution, function_labels,\n",
    "                                      new_input_distribution)\n",
    "\n",
    "number_of_variables = 1\n",
    "NUMBER_OF_STATES = 5\n",
    "TOTAL_NUDGE_SIZE = 0.005    \n",
    "nudge_impact = calculate_nudge_impact(number_of_variables, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE)\n",
    "print(nudge_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "difference_distributions = []\n",
    "for number_of_variables in range(1, 7, 1):\n",
    "    number_of_states, number_of_distributions = 5, 200\n",
    "    marginal_outputs = []\n",
    "    for i in range(number_of_distributions):\n",
    "        pdf = JointProbabilityMatrix(number_of_variables+1, number_of_states, 'random')\n",
    "        distribution = ProbabilityArray(pdf.joint_probabilities.joint_probabilities)\n",
    "        function_label, label_nudged_variable = number_of_variables, 0\n",
    "        marginal_outputs.append(distribution.marginalize(set([function_label])))\n",
    "\n",
    "    kl_divergences = []\n",
    "    for i in range(int(number_of_distributions/2)):\n",
    "        kl_divergences.append(entropy(marginal_outputs[i].flatten(), marginal_outputs[i+1].flatten()))\n",
    "\n",
    "    difference_distributions.append(np.mean(kl_divergences))\n",
    "    print(np.mean(kl_divergences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "The impact of a nudge on an input variable (with no causal impact on the other input variables)\n",
    "on the output variable, for different number of input variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 7, 5, 0.01\n",
    "NUMBER_OF_SAMPLES = 200\n",
    "impact_nudge_dict = {}\n",
    "\n",
    "for number_of_variables in range(1, MAX_NUMBER_OF_VARIABLES, 1):\n",
    "    print(number_of_variables)\n",
    "    impact_nudges = []\n",
    "    for i in range(NUMBER_OF_SAMPLES):\n",
    "        print(\"sample number {}\".format(i))\n",
    "        impact_nudges.append(\n",
    "            calculate_nudge_impact(number_of_variables, \n",
    "                                   NUMBER_OF_STATES, \n",
    "                                   TOTAL_NUDGE_SIZE)\n",
    "        )\n",
    "    \n",
    "    impact_nudge_dict[number_of_variables] = impact_nudges\n",
    "    #with open(\"back_up_number_variables_output.json\", 'w') as f:\n",
    "    #    json.dump(impact_nudge_dict, f)\n",
    "\n",
    "#print(impact_nudge_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_range, mean_impact_nudge, std_impact_nudge, batches_std = (\n",
    "    find_mean_std_mse(impact_nudge_dict, 10)\n",
    ")\n",
    "\n",
    "xlabel = \"number of input variables\"\n",
    "ylabel = \"impact of the nudge\"\n",
    "title = \"Impact of a nudge on 1 input variable on output variable for different amount of input variables\"\n",
    "plotting.plot_mean_and_confidence(\n",
    "    variable_range, mean_impact_nudge, std_impact_nudge,\n",
    "    \"std\", xlabel, ylabel, title\n",
    ")\n",
    "\n",
    "plotting.plot_mean_and_confidence(\n",
    "    variable_range, mean_impact_nudge, batches_std,\n",
    "    \"std of batched means\", xlabel, ylabel, title\n",
    ")\n",
    "\n",
    "plotting.plot_mean_and_confidence(\n",
    "    variable_range, np.array(mean_impact_nudge)/np.array(difference_distributions), batches_std,\n",
    "    \"std of batched means\", xlabel, \"normalised impact of the nudge\", \"normalised values\"\n",
    ")\n",
    "\n",
    "fit = powerlaw.Fit(mean_impact_nudge)\n",
    "print(fit.distribution_compare(\"power_law\", \"exponential\"))\n",
    "print(fit.distribution_compare(\"power_law\", \"lognormal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "The relation between nudge impact and the mutual information between the output variable and\n",
    "the nudged input variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 2, 5, 0.01\n",
    "NUMBER_OF_SAMPLES = 3\n",
    "\n",
    "local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "    TOTAL_NUDGE_SIZE, NUMBER_OF_STATES**NUMBER_OF_VARIABLES\n",
    ")\n",
    "impact_nudges_and_mi = []\n",
    "for i in range(NUMBER_OF_SAMPLES):\n",
    "    if i%20==0 and i != 0:\n",
    "        print(\"sample number {}\".format(i))\n",
    "    \n",
    "    #calculate the distribution\n",
    "    pdf = JointProbabilityMatrix(number_of_variables+1, NUMBER_OF_STATES, 'random')\n",
    "    distribution = ProbabilityArray(pdf.joint_probabilities.joint_probabilities)\n",
    "    function_label, label_nudged_variable = NUMBER_OF_VARIABLES, 0\n",
    "    function_labels = set([function_label])\n",
    "    input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "    \n",
    "    #calculate mutual information\n",
    "    mutual_information = calculate_mutual_information(distribution, \n",
    "                                                      set([function_label]),\n",
    "                                                      set([label_nudged_variable]))\n",
    "    \n",
    "    #calculate_nudge_impact\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    nudge_impacts = []\n",
    "    for _ in range(5):\n",
    "        new_input_distribution = nudge_distribution_local_non_causal(\n",
    "            input_distribution, 0, local_nudge, number_of_nudges\n",
    "        )\n",
    "        nudge_impacts.append(impact_nudge_causal_output(\n",
    "            distribution, function_labels, new_input_distribution\n",
    "        ))\n",
    "    nudge_impact = np.mean(nudge_impacts)\n",
    "    impact_nudges_and_mi.append((nudge_impact, mutual_information))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "impact_nudges = [item[0] for item in impact_nudges_and_mi] \n",
    "mutual_information_sizes = [item[1] for item in impact_nudges_and_mi]\n",
    "plt.plot(mutual_information_sizes, impact_nudges, 'o')\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Experiment:\n",
    "Change the output so as to minimize the nudge impact. See what happens with the mutual information between\n",
    "the nudged variable and the output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_nudge_impact(distribution, output_label, nudge_label, number_of_nudges, local_nudge_size):\n",
    "    input_variable_labels = (set(range(len(distribution.probability_distribution.shape))) -\n",
    "                             set([output_label]))\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge_distribution_local_non_causal(\n",
    "        input_distribution, nudge_label, local_nudge_size, number_of_nudges\n",
    "    )\n",
    "    return impact_nudge_causal_output(distribution, set([output_label]),\n",
    "                                      new_input_distribution)\n",
    "\n",
    "def minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                          evaluations_per_trial, mutation_size, number_of_mutations,\n",
    "                          total_nudge_size, nudge_label):\n",
    "    \"\"\"\n",
    "    Mutate the distribution to minimize nudge impact and maximize entropy\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    initial_distribution: a numpy array\n",
    "        Representing a discrete probability distribution\n",
    "    function_label: an integer\n",
    "    nudge_size: a (small) number\n",
    "    number_of_nudges: an integer\n",
    "    \n",
    "    \"\"\"\n",
    "    total_number_of_states = reduce(lambda x, y: x*y, initial_distribution.shape)\n",
    "    local_nudge_size, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "                             \n",
    "    distribution = initial_distribution\n",
    "    nudge_impacts = []\n",
    "    for i in range(evaluations_per_trial):\n",
    "        nudge_impacts.append(get_nudge_impact(\n",
    "            ProbabilityArray(initial_distribution), output_label, nudge_label, number_of_nudges, local_nudge_size\n",
    "        ))                        \n",
    "    prev_nudge_impact = np.mean(nudge_impacts)\n",
    "    #print(prev_nudge_impact)\n",
    "             \n",
    "    for i in range(number_of_trials):\n",
    "        #print(i)\n",
    "        #print(\"number of mutations {}\".format(number_of_mutations))\n",
    "        proposed_distribution = nudge.mutate_distribution(\n",
    "            distribution, output_label, int(number_of_mutations), mutation_size\n",
    "        ) \n",
    "        #print(\"found proposal distribution\")\n",
    "        nudge_impacts = []\n",
    "        for j in range(evaluations_per_trial):\n",
    "            nudge_impacts.append(get_nudge_impact(\n",
    "                ProbabilityArray(proposed_distribution), output_label, nudge_label,\n",
    "                number_of_nudges, local_nudge_size\n",
    "            ))\n",
    "        if np.mean(nudge_impacts) < prev_nudge_impact:\n",
    "            prev_nudge_impact = np.mean(nudge_impacts)\n",
    "            distribution = proposed_distribution\n",
    "            \n",
    "        #print(prev_nudge_impact)\n",
    "    \n",
    "    return distribution, prev_nudge_impact\n",
    "\n",
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 3, 4 \n",
    "pdf = JointProbabilityMatrix(NUMBER_OF_VARIABLES+1, NUMBER_OF_STATES, 'random')\n",
    "initial_distribution = pdf.joint_probabilities.joint_probabilities\n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "\n",
    "number_of_trials = 50\n",
    "evaluations_per_trial = 10\n",
    "mutation_size = 0.2 / (4.0**3)\n",
    "number_of_mutations = int(0.1 * 4**3)\n",
    "a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                      evaluations_per_trial, mutation_size, number_of_mutations, 0.01, 0)\n",
    "\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 3, 4 \n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "number_of_trials = 50\n",
    "evaluations_per_trial = 10\n",
    "mutation_size = 0.2 / (4.0**3)\n",
    "number_of_mutations = int(0.1 * 4**3)\n",
    "\n",
    "mi_before = []\n",
    "mi_after = []\n",
    "\n",
    "impact_before = []\n",
    "impact_after = []\n",
    "\n",
    "for count in range(50):\n",
    "    if count%10==0:\n",
    "        print(count)\n",
    "    pdf = JointProbabilityMatrix(NUMBER_OF_VARIABLES+1, NUMBER_OF_STATES, 'random')\n",
    "    initial_distribution = pdf.joint_probabilities.joint_probabilities\n",
    "    a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                          evaluations_per_trial, mutation_size, number_of_mutations, 0.01, 0)\n",
    "\n",
    "\n",
    "    mi_before.append(calculate_mutual_information(\n",
    "        ProbabilityArray(initial_distribution), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "    ))\n",
    "    mi_after.append(calculate_mutual_information(\n",
    "        ProbabilityArray(a[0]), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "    ))\n",
    "    \n",
    "print(np.mean(mi_before))\n",
    "print(np.mean(mi_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mi_before)\n",
    "print(mi_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conditional_distribution(self, selected_indices, conditional_indices):\n",
    "    \"\"\"create the conditional distribution for the selected_indices given \n",
    "    the conditional_indices for the joint_distribution\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    joint_distribution: numpy array\n",
    "    selected_indices: list of integers\n",
    "    conditional_indices: list of integers\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    joint_distribution = self.marginalize_distribution(selected_indices+conditional_indices)\n",
    "    marginal_conditional = self.marginalize_distribution(conditional_indices)\n",
    "    conditional_distribution = np.copy(joint_distribution) \n",
    "    it = np.iter(joint_distribution, flags='multi_index')\n",
    "    while not it.finished:\n",
    "        conditional_arguments = tuple([it.multi_index[i] for i in conditional_indices])\n",
    "        conditional_distribution[it.multi_index] = (\n",
    "            conditional_distribution[it.multi_index] /\n",
    "            marginal_conditional[conditional_arguments]\n",
    "        )\n",
    "        it.iternext()\n",
    "        \n",
    "    return conditional_distribution\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
