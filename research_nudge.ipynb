{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import json\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "import powerlaw\n",
    "from jointpdf.jointpdf import JointProbabilityMatrix\n",
    "from jointpdf.jointpdf import FullNestedArrayOfProbabilities\n",
    "\n",
    "from extension_probability_matrix import JointProbabilityMatrixExtended\n",
    "import probability_distributions\n",
    "from probability_distributions import ProbabilityArray\n",
    "from simulate import find_mean_std_mse\n",
    "import nudge\n",
    "import plotting\n",
    "\n",
    "import information_theory\n",
    "from information_theory import calculate_mutual_information\n",
    "\n",
    "import maximum_nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distribution(shape, method, arguments=None):\n",
    "    if method=='random_biased':\n",
    "        distribution = np.random.random(shape)\n",
    "        distribution = distribution/np.sum(distribution)\n",
    "        return distribution\n",
    "    elif method=='random_dirichlet':\n",
    "        return probability_distributions.compute_joint_uniform_random(shape)\n",
    "    elif method=='fixed_entropy':\n",
    "        return probability_distributions.generate_probability_distribution_with_certain_entropy(\n",
    "            shape, arguments['entropy_size']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('provide a valid method')\n",
    "        \n",
    "def calculate_amount_and_size_nudges(total_nudge_size, number_of_states, threshold=10):\n",
    "    \"\"\"\n",
    "    Calculate the nudge size and the number of nudges that need to be performed \n",
    "    to nudge a variable with the total nudge size. Assuming the distribution is\n",
    "    not too peaked, in other words, not too many states should have a probability\n",
    "    that is 10 times smaller than normal.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    total_nudge_size: a number\n",
    "        How much the variable need to be nudged\n",
    "    number_of_states: a number\n",
    "        The total number of states of the joint distribution\n",
    "    threshold: a float \n",
    "        Indicating how much smaller than uniform the value of the number\n",
    "        at the 95-99 percentile of points is. Defaults to 10 \n",
    "        \n",
    "    Returns: local_nudge, number_of_nudges\n",
    "    -------\n",
    "    local_nudge: a number \n",
    "        The size of the local nudge to be performed on the joint distribution\n",
    "    number_of_nudges: integer\n",
    "        How often the nudge need to be performed\n",
    "    \n",
    "    \"\"\"\n",
    "    assumed_min_size = 1.0/threshold\n",
    "    max_local_nudge = min(total_nudge_size, 0.1/number_of_states)\n",
    "    number_of_nudges = int(np.ceil(total_nudge_size/max_local_nudge))\n",
    "    local_nudge = total_nudge_size/float(number_of_nudges) \n",
    "    return local_nudge, number_of_nudges\n",
    "\n",
    "def percentage_max_entropy(shape, percentage):\n",
    "    \"\"\" \n",
    "    Return the percentage of the max-entropy given the shape\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    shape: iterable\n",
    "    percentage: float\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.log2(reduce(lambda x,y: x*y, shape)) * percentage\n",
    "\n",
    "def percentage_states_max_entropy(shape, percentage):\n",
    "    \"\"\" \n",
    "    Return the percentage of the max-entropy given the shape\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    shape: iterable\n",
    "    percentage: float\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.log2(reduce(lambda x,y: x*y, shape) * percentage)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make one cell for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_and_confidence(plot_range, mean, mean_label, confidence_interval, \n",
    "                             confidence_interval_title):\n",
    "    \"\"\"\n",
    "    Plot the mean and some kind of confidence interval (standard deviation or\n",
    "    mean-squared-error)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    plot_range: iterable\n",
    "    mean: an iterable\n",
    "        the mean of the values at that point\n",
    "    confidence_interval: an iterable\n",
    "        Representing the  interval of confidence in that point. \n",
    "        The iterable should have length plot_range.\n",
    "    confidence_interval_title: a string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lower_bound = np.array(mean)-np.array(confidence_interval)\n",
    "    upper_bound = np.array(mean)+np.array(confidence_interval)\n",
    "    plt.plot(plot_range, mean, label=mean_label)\n",
    "    plt.fill_between(plot_range, lower_bound, upper_bound, \n",
    "                     label='{}'.format(confidence_interval_title),\n",
    "                     alpha=0.2)\n",
    "    \n",
    "def plot_results(*args, **kwargs):\n",
    "    \"\"\"plot results from simulations\n",
    "    \n",
    "    Parameters:\n",
    "        args: 1 or more dicts. The dicts should have for the keys numerical\n",
    "            input values and for the values iterables of numbers.\n",
    "        kwargs: at least the arguments xlabel, ylabel, title\n",
    "        \n",
    "    \"\"\"\n",
    "    for argument in args:\n",
    "        data, meta_dict = argument\n",
    "        variable_range, mean, std, batches_std = (\n",
    "            find_mean_std_mse(data, 10)\n",
    "        )\n",
    "        \n",
    "        if kwargs['std_of_batches']: \n",
    "            plot_mean_and_confidence(variable_range, mean, meta_dict['mean_label'], \n",
    "                                     batches_std, \"batches stdev\")\n",
    "        else:\n",
    "            plot_mean_and_confidence(variable_range, mean, meta_dict['mean_label'], \n",
    "                                     std, \"stdev\")\n",
    "    \n",
    "    plt.xlabel(kwargs['xlabel'])\n",
    "    plt.ylabel(kwargs['ylabel'])\n",
    "    plt.legend()\n",
    "    plt.title(kwargs['title'])\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "Check the distance between a Dirichlet distribution and the uniform distribution for an \n",
    "increasing number of states.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72925374023794931, 1.1975269908246697, 1.5694527160727687, 1.8609560045587208, 2.0769602020711666, 2.307307466114302, 2.4766999619354029, 2.6389008649611787, 2.7804125876881929, 2.9093737894638712, 3.0358629228092204, 3.1470645144038558, 3.2491725864193275, 3.3353921392111636, 3.4308883874902762, 3.5359194681336805, 3.5978649995760459, 3.6784909098721972, 3.7479936828664986, 3.8138356384701519, 3.8950302125972178, 3.9503673921305715, 4.0010745889674579, 4.0617308867862842, 4.11723740251926, 4.1738235992121036, 4.2211069626082507, 4.2722107819394823, 4.324442003609053, 4.3701812365477091, 4.4209683413815402, 4.4514212344032913, 4.5060261726988884, 4.5349695481301353, 4.5849716462888281, 4.6174737408267585, 4.6591701155111398, 4.6955803586742473, 4.732822451963778, 4.7695136549160813, 4.7996753193550017, 4.8295098398365663, 4.8594710136848471, 4.8917985496417735, 4.9271508325104421, 4.9551355360063969, 4.9884282711096199, 5.0163865545695554, 5.04840309036046, 5.0836124911575045, 5.1016704637496186, 5.1295453537927598, 5.158192832482893, 5.1824073811101687, 5.2109098098190092, 5.2313357696427341, 5.2609252166578191, 5.2805840747489148, 5.3102197110500775, 5.3382397195838394, 5.3548126805209799, 5.3796423149947987, 5.3969176780690287, 5.4204231782519079, 5.4442402169837409, 5.4674883019271077, 5.4874603611436621, 5.5100741548300993, 5.5369910282371935, 5.5485674351344496, 5.5709503555821227, 5.5864704019475928, 5.6084139091240104, 5.6255832686199589, 5.6515530593617296, 5.6639370609193627, 5.6834520472179593, 5.7011924175052844, 5.7196121867306555, 5.7401773741778745, 5.7568988659074751, 5.7696571189066379, 5.7910565584014524, 5.8066089804998811, 5.8251021473002824, 5.8429539882437149, 5.8582325710207463, 5.8727338825889071, 5.8890688522674797, 5.9098741261366747, 5.9245014852818914, 5.9368921516864637, 5.9511337537082847, 5.9686969959217171, 5.9772848396484894, 5.9980348891949342, 6.0150897934061538, 6.0264796936337026, 6.0432709684438084, 6.0540869420072765, 6.0707528824290042, 6.0831743856954672, 6.094983358806588, 6.1114680390110276, 6.127476003651676, 6.1437190571483571, 6.1470344919715005, 6.161107080229578, 6.1751019463697112, 6.1898436614650114, 6.2068287479007598, 6.2157393705806054, 6.2295945211580008, 6.2422099907211788, 6.2548593822883287, 6.2656683414531216, 6.2755903709327763, 6.2910577692402416, 6.3028875718950541, 6.3149192461768138, 6.3278473360048988, 6.3424041880499482, 6.3511371013696536, 6.3623896731109166, 6.3759052138227545, 6.3871296272157432, 6.3951642062015317, 6.4075341271461568, 6.4178182340737777, 6.4318788369800801, 6.4363180984986927, 6.4509073213177128, 6.4631759524360692, 6.4707129855147425, 6.4795463566652085, 6.4968084512850828, 6.5062674364320685, 6.5137711155595666, 6.5268024946244241, 6.5342980405383848, 6.545494140857314, 6.554582718570324, 6.5645125699453439, 6.5746049073913895, 6.5845239795099877, 6.5907590985866413, 6.6032814841950582, 6.6134531640532979, 6.6230308519323264, 6.6344734997820707, 6.6438350995322333, 6.6528235985963677, 6.6607241986844983, 6.670258650292916, 6.6785890955530567, 6.6901864802976654, 6.6960167313491823, 6.7080375293325361, 6.7150436695591109, 6.7255543488050451, 6.7316035447436668, 6.7428759637610591, 6.7504255936628788, 6.7612596224448893, 6.7684486382588425, 6.7794839802824773, 6.7883067681684546, 6.7967749111399538, 6.8027858098756022, 6.8081718591459541, 6.8219454325367694, 6.8315194510649144, 6.8376296781251789, 6.8474610602299082, 6.8526229408877279, 6.8619339845625875, 6.8710369600566432, 6.8787374158262029, 6.8841055234491417, 6.8944049451903231, 6.9004846991420488, 6.9113584666774841, 6.9187014948962515, 6.9231877410475606, 6.9312610274180226, 6.9428991358950753, 6.9484265008524186, 6.9553567089887443, 6.9662158187761891, 6.9707068532862158, 6.9778789304696875, 6.9862223242295007, 6.9920639150158648, 7.0010587616029998, 7.0087666284932721, 7.0149897322990258, 7.0226964427837153, 7.0305847591334221, 7.038690408463407, 7.0450506933500003, 7.0519412837589677, 7.060271273751912, 7.0669875111663565, 7.075045888715831, 7.080258962257469, 7.0884962347694982, 7.0923631551596005, 7.1018703027534471, 7.1083687587439286, 7.1134196388911084, 7.120129950538387, 7.1275997921548333, 7.137097349284419, 7.1468862607224652, 7.1485670357091644, 7.1535523317220848, 7.1594785857864318, 7.1707849261977454, 7.1756900597996172, 7.1797539089044919, 7.1908408810145197, 7.1935451720249377, 7.198586728004166, 7.2072585336570043, 7.2123860711012711, 7.2171794349035103, 7.2277721630745981, 7.2329592358563808, 7.239377673631874, 7.2456945998978739, 7.2512601580908713, 7.2573427515636233, 7.2616673428515019, 7.2689632143491032, 7.2751238310629978, 7.2812909605926039, 7.2883918432771075, 7.2930276946988579, 7.2987617288122308, 7.3064835277550557, 7.3095258185059047, 7.3184251315966486, 7.3246421259846137, 7.3309731999548005, 7.3359292247216841, 7.3392689578403099, 7.346940562223736, 7.3525854377487967]\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 1000\n",
    "min_number_of_states = 2\n",
    "max_number_of_states = 250\n",
    "\n",
    "RUN = True\n",
    "if RUN:\n",
    "    entropies_dirichlet = []\n",
    "    for i in range(min_number_of_states, max_number_of_states, 1):\n",
    "        distances = []\n",
    "        for _ in range(SAMPLE_SIZE):\n",
    "            dirichlet_dist = np.random.dirichlet([1]*i)\n",
    "            #print(dirichlet_dist)\n",
    "            distance = entropy(dirichlet_dist, base=2)\n",
    "            distances.append(distance)\n",
    "\n",
    "        entropies_dirichlet.append(np.mean(distances))\n",
    "\n",
    "    print(entropies_dirichlet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHqrZ2utnCM0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f6432da10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if RUN:\n",
    "    plt.plot(list(range(2,250,1)), entropies_dirichlet, label=\"entropy Dirichlet\")\n",
    "    plt.plot(list(range(2,250,1)), 0.9*np.log2(list(range(2,250,1))), label=\"90% max entropy\")\n",
    "    plt.plot(list(range(2,250,1)), np.log2(list(range(2,250,1))), label=\"max entropy\")\n",
    "    plt.xlabel(\"number of states\")\n",
    "    plt.ylabel(\"entropy\")\n",
    "    plt.title('entropy Dirichlet weights close to maximum')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2A\n",
    "\n",
    "See what the distance is between 2 randomly generated functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the average \"distance\" (KL-divergence) between randomly (probability masses states are distributed according to Dirichlet distribution) generated distributions. The distance decreases, since, the number of\n",
    "states that are close to uniform increases as the number of states for a distribution grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_states, number_of_variables = 5, 4\n",
    "shape = tuple([number_of_states]*(number_of_variables+1))\n",
    "total_nudge_size = 0.01\n",
    "total_number_of_states = number_of_states**number_of_variables\n",
    "max_local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "    total_nudge_size, total_number_of_states\n",
    ")\n",
    "RUN = False\n",
    "if RUN:\n",
    "    total_nudge_sizes = []\n",
    "    for i in range(50):\n",
    "        print(i)\n",
    "        #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "        distribution = ProbabilityArray(generate_distribution(\n",
    "            shape, 'fixed_entropy', \n",
    "            {\"entropy_size\":percentage_states_max_entropy(shape, 0.1)}\n",
    "        ))\n",
    "        function_labels, label_nudged_variable = set([number_of_variables]), 0\n",
    "        input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "        input_distribution = distribution.marginalize(input_variable_labels)\n",
    "        marginal_nudged_old = ProbabilityArray(input_distribution).marginalize(\n",
    "            set([label_nudged_variable])\n",
    "        ) \n",
    "\n",
    "        new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "            input_distribution, 0, max_local_nudge, number_of_nudges\n",
    "        )\n",
    "        marginal_nudged_new = ProbabilityArray(new_input_distribution).marginalize(\n",
    "            set([label_nudged_variable])\n",
    "        ) \n",
    "        total_nudge_sizes.append(np.sum(np.absolute(marginal_nudged_old-marginal_nudged_new)))\n",
    "\n",
    "    print(np.mean(total_nudge_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_states, number_of_distributions = 5, 20\n",
    "difference_distributions = []\n",
    "RUN = False\n",
    "if RUN:\n",
    "    for number_of_variables in range(1, 6, 1):\n",
    "        marginal_outputs = []\n",
    "        shape = tuple([number_of_states]*(number_of_variables+1))\n",
    "        for i in range(number_of_distributions):\n",
    "            print(i)\n",
    "            #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "            distribution = ProbabilityArray(generate_distribution(\n",
    "                shape, 'fixed_entropy', \n",
    "                {\"entropy_size\":percentage_max_entropy(shape, 0.75)}\n",
    "            ))\n",
    "            function_label, label_nudged_variable = number_of_variables, 0\n",
    "            marginal_outputs.append(distribution.marginalize(set([function_label])))\n",
    "\n",
    "        kl_divergences = []\n",
    "        for i in range(int(number_of_distributions/2.0)):\n",
    "            kl_divergences.append(entropy(marginal_outputs[i].flatten(), marginal_outputs[i+1].flatten()))\n",
    "\n",
    "        difference_distributions.append(np.mean(kl_divergences))\n",
    "        print(np.mean(kl_divergences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2B \n",
    "\n",
    "The actual experiment- for non-causal nudges. Both for local and not local nudges. Local nudges can be performed with vector and focused nudges, while non-local nudges are always vector nudges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "    \n",
    "def product(it):\n",
    "    \"\"\"calculate the product of all terms in the iterable\"\"\"\n",
    "    return reduce(lambda x, y: x*y, it)\n",
    "    \n",
    "def calculate_focused_nudge_impact(distribution, total_nudge_size):\n",
    "    \"\"\" \n",
    "    For now calculate the impact of a local non-causal nudge on the input variables\n",
    "    on the completely causally determined output variable\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a ProbabilityArray object\n",
    "    total_nudge_size: number\n",
    "    \n",
    "    \"\"\"\n",
    "    number_of_variables = len(distribution.probability_distribution.shape)\n",
    "    total_number_of_states = product(distribution.probability_distribution.shape)\n",
    "    max_local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "    function_labels, label_nudged_variable = set([number_of_variables-1]), 0\n",
    "    input_variable_labels = set(range(number_of_variables)) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, 0, max_local_nudge, number_of_nudges\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, function_labels,\n",
    "                                            new_input_distribution)\n",
    "\n",
    "def calculate_non_local_nudge_impact(distribution, total_nudge_size, nudged_variables):\n",
    "    \"\"\" \n",
    "    Calculate the impact of a non-local non-causal nudge (using a vector-nudge) \n",
    "    on the input variables on the completely causally determined output variable\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a ProbabilityArray object\n",
    "    total_nudge_size: number\n",
    "    nudged_variables: a list of integers\n",
    "    \n",
    "    \"\"\"\n",
    "    number_of_variables = len(distribution.probability_distribution.shape)\n",
    "    function_labels, label_nudged_variable = set([number_of_variables-1]), 0\n",
    "    input_variable_labels = set(range(number_of_variables)) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_non_local_non_causal(\n",
    "        input_distribution, nudged_variables, total_nudge_size, 'random'\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, function_labels,\n",
    "                                            new_input_distribution)\n",
    "\n",
    "number_of_variables = 5\n",
    "NUMBER_OF_STATES = 4\n",
    "TOTAL_NUDGE_SIZE = 0.01\n",
    "shape = tuple([NUMBER_OF_STATES] * (number_of_variables))\n",
    "distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "#distribution = ProbabilityArray(generate_distribution(\n",
    "#    shape, 'fixed_entropy', \n",
    "#    {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "#))\n",
    "\n",
    "focused_nudge_impact = calculate_focused_nudge_impact(distribution, TOTAL_NUDGE_SIZE)\n",
    "print(focused_nudge_impact)\n",
    "\n",
    "nudged_variables = [0] \n",
    "vector_nudge_impact = calculate_non_local_nudge_impact(\n",
    "    distribution, TOTAL_NUDGE_SIZE, nudged_variables\n",
    ")\n",
    "print(vector_nudge_impact)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment \n",
    "\n",
    "Look at differences of impact for local vector and focused nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_variables = 4\n",
    "NUMBER_OF_STATES = 4\n",
    "TOTAL_NUDGE_SIZE = 0.01\n",
    "nudged_variables = [0]\n",
    "number_of_samples = 100\n",
    "\n",
    "focused_nudge_impacts = []\n",
    "vector_nudge_impacts = []\n",
    "RUN = False\n",
    "if RUN:\n",
    "    for i in range(number_of_samples):\n",
    "        if i%10==0:\n",
    "            print(i)\n",
    "\n",
    "        shape = tuple([NUMBER_OF_STATES] * (number_of_variables))\n",
    "        #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "        distribution = ProbabilityArray(generate_distribution(\n",
    "            shape, 'fixed_entropy', \n",
    "            {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "        ))        \n",
    "        focused_nudge_impact = calculate_focused_nudge_impact(distribution, TOTAL_NUDGE_SIZE)\n",
    "        focused_nudge_impacts.append(focused_nudge_impact)\n",
    "\n",
    "        vector_nudge_impact = calculate_non_local_nudge_impact(\n",
    "            distribution, TOTAL_NUDGE_SIZE, nudged_variables\n",
    "        )\n",
    "        vector_nudge_impacts.append(vector_nudge_impact)\n",
    "\n",
    "    print(\"mean & std focused nudge {} ({})\".format(\n",
    "        np.mean(focused_nudge_impacts), np.std(focused_nudge_impacts)\n",
    "    ))\n",
    "    print(\"mean & std vector nudge {} ({})\".format(\n",
    "        np.mean(vector_nudge_impacts), np.std(vector_nudge_impacts)\n",
    "    ))\n",
    "    differences = np.array(focused_nudge_impacts) - np.array(vector_nudge_impacts)\n",
    "    print(\"mean & std difference focused minus vector {} ({})\".format(\n",
    "        np.mean(differences), np.std(differences)\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "The impact of a vector/focused nudge on the input variables \n",
    "(with no causal impact on the other input variables)\n",
    "on the output variable, for different number of input variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 5, 5, 0.01\n",
    "nudged_variables = [0]\n",
    "NUMBER_OF_SAMPLES = 10\n",
    "\n",
    "impact_focused_nudge_dict = {}\n",
    "impact_vector_nudge_dict = {}\n",
    "RUN = False\n",
    "if RUN:\n",
    "    for number_of_variables in range(1, MAX_NUMBER_OF_VARIABLES, 1):\n",
    "        print(number_of_variables)\n",
    "        focused_nudge_impacts = []\n",
    "        vector_nudge_impacts = []\n",
    "        for i in range(NUMBER_OF_SAMPLES):\n",
    "            if i%5 == 0: \n",
    "                print(\"sample number {}\".format(i))\n",
    "\n",
    "            shape = tuple([NUMBER_OF_STATES] * (number_of_variables+1))\n",
    "            #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "            distribution = ProbabilityArray(generate_distribution(\n",
    "                shape, 'fixed_entropy', \n",
    "                {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "            ))\n",
    "            focused_nudge_impact = calculate_focused_nudge_impact(distribution, TOTAL_NUDGE_SIZE)\n",
    "            focused_nudge_impacts.append(focused_nudge_impact)\n",
    "            vector_nudge_impact = calculate_non_local_nudge_impact(\n",
    "                distribution, TOTAL_NUDGE_SIZE, nudged_variables\n",
    "            )\n",
    "            vector_nudge_impacts.append(vector_nudge_impact)\n",
    "\n",
    "        impact_focused_nudge_dict[number_of_variables] = focused_nudge_impacts\n",
    "        impact_vector_nudge_dict[number_of_variables] = vector_nudge_impacts\n",
    "        #with open(\"back_up_number_variables_output.json\", 'w') as f:\n",
    "        #    json.dump(impact_nudge_dict, f)\n",
    "\n",
    "    #print(impact_nudge_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    plot_results(\n",
    "        (impact_focused_nudge_dict, {'mean_label': 'focused'}), \n",
    "        (impact_vector_nudge_dict, {'mean_label': 'vector'}),\n",
    "        xlabel=\"number of input variables\", ylabel = \"KL-divergence\", \n",
    "        title=\"the impact of the nudge given a number of variables\", std_of_batches=False\n",
    "    )\n",
    "    \n",
    "\n",
    "#plotting.plot_mean_and_confidence(\n",
    "#    variable_range, np.array(mean_impact_nudge)/np.array(difference_distributions), batches_std,\n",
    "#    \"std of batched means\", xlabel, \"normalised impact of the nudge\", \"normalised values\"\n",
    "#)\n",
    "\n",
    "#fit = powerlaw.Fit(mean_impact_nudge)\n",
    "#print(fit.distribution_compare(\"power_law\", \"exponential\"))\n",
    "#print(fit.distribution_compare(\"power_law\", \"lognormal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_STATES = 5\n",
    "MAX_PERCENTAGE_ENTROPY = 75\n",
    "number_of_samples = 100\n",
    "uniform = np.ones(NUMBER_OF_STATES)/float(NUMBER_OF_STATES)\n",
    "print(uniform)\n",
    "for number_of_input_variables in range(1,6,1):\n",
    "    distances_uniform = []\n",
    "    shape = tuple([NUMBER_OF_STATES] * (number_of_input_variables+1))\n",
    "    for _ in range(number_of_samples):\n",
    "        #distribution = generate_distribution(shape, 'random_dirichlet')\n",
    "        distribution = generate_distribution(\n",
    "            shape, 'fixed_entropy', \n",
    "            {\"entropy_size\":percentage_max_entropy(shape, MAX_PERCENTAGE_ENTROPY/100)}\n",
    "        )\n",
    "        marginal_output = ProbabilityArray(distribution).marginalize(set([number_of_input_variables]))\n",
    "        distances_uniform.append(np.sum(np.absolute(marginal_output-uniform)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2C\n",
    "\n",
    "Compare local vector nudges to synergistic nudges (nudges on the total distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 5, 5, 0.01\n",
    "NUMBER_OF_SAMPLES = 50\n",
    "\n",
    "impact_local_nudge_dict = {}\n",
    "impact_synergistic_nudge_dict = {}\n",
    "RUN = False\n",
    "if RUN:\n",
    "    for number_of_input_variables in range(1, MAX_NUMBER_OF_VARIABLES, 1):\n",
    "        print(number_of_input_variables)\n",
    "        synergistic_nudge_impacts = []\n",
    "        local_nudge_impacts = []\n",
    "        for i in range(NUMBER_OF_SAMPLES):\n",
    "            if i%10 == 0: \n",
    "                print(\"sample number {}\".format(i))\n",
    "\n",
    "            nudged_variables = list(range(number_of_input_variables))\n",
    "            random.shuffle(nudged_variables)\n",
    "\n",
    "            shape = tuple([NUMBER_OF_STATES] * (number_of_input_variables+1))\n",
    "            #distribution = generate_distribution(shape, 'random_dirichlet')\n",
    "            distribution = generate_distribution(\n",
    "                shape, 'fixed_entropy', \n",
    "                {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "            )\n",
    "\n",
    "            distribution_copy = np.copy(distribution)\n",
    "\n",
    "            distribution = ProbabilityArray(distribution)\n",
    "            distribution_copy = ProbabilityArray(distribution_copy)\n",
    "\n",
    "            local_nudge_impact = calculate_non_local_nudge_impact(\n",
    "                distribution, TOTAL_NUDGE_SIZE, [0]\n",
    "            )\n",
    "            local_nudge_impacts.append(local_nudge_impact)\n",
    "\n",
    "            synergistic_nudge_impact = calculate_non_local_nudge_impact(\n",
    "                distribution_copy, TOTAL_NUDGE_SIZE, [0]\n",
    "            )\n",
    "            synergistic_nudge_impacts.append(synergistic_nudge_impact)\n",
    "            #print(\"difference local-synergistic {}\".format(local_nudge_impact-synergistic_nudge_impact))\n",
    "\n",
    "\n",
    "\n",
    "        impact_synergistic_nudge_dict[number_of_input_variables] = synergistic_nudge_impacts\n",
    "        impact_local_nudge_dict[number_of_input_variables] = local_nudge_impacts\n",
    "        #with open(\"back_up_number_variables_output.json\", 'w') as f:\n",
    "        #    json.dump(impact_nudge_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RUN:\n",
    "    plot_results(\n",
    "        (impact_local_nudge_dict, {'mean_label': 'local'}), \n",
    "        (impact_synergistic_nudge_dict, {'mean_label': 'synergetic'}),\n",
    "        xlabel=\"number of input variables\", ylabel = \"KL-divergence\", \n",
    "        title=\"Compare local and synergetic nudge impacts\", std_of_batches=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import probability_distributions\n",
    "import nudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 3, 4 \n",
    "#pdf = JointProbabilityMatrix(NUMBER_OF_VARIABLES+1, NUMBER_OF_STATES, 'random')\n",
    "#initial_distribution = pdf.joint_probabilities.joint_probabilities\n",
    "shape = [NUMBER_OF_STATES]*(NUMBER_OF_VARIABLES+1)\n",
    "\n",
    "initial_distribution = generate_distribution(\n",
    "    shape, 'fixed_entropy', \n",
    "    {\"entropy_size\":percentage_max_entropy(shape, 0.75)}\n",
    ")\n",
    "\n",
    "new_distribution = nudge.mutate_distribution_with_fixed_marginals(\n",
    "    np.copy(initial_distribution), 3, 50, 0.001\n",
    ") \n",
    "\n",
    "a = probability_distributions.ProbabilityArray(initial_distribution).marginalize(set([0]))\n",
    "b = probability_distributions.ProbabilityArray(new_distribution).marginalize(set([0]))\n",
    "np.allclose(a, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 4:\n",
    "Change the output so as to minimize the nudge impact. See what happens with the mutual information between\n",
    "the nudged variable and the output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_nudge_impact(distribution, output_label, nudge_label, number_of_nudges, local_nudge_size):\n",
    "    input_variable_labels = (set(range(len(distribution.probability_distribution.shape))) -\n",
    "                             set([output_label]))\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, nudge_label, local_nudge_size, number_of_nudges\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, set([output_label]),\n",
    "                                      new_input_distribution)\n",
    "\n",
    "def minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                          evaluations_per_trial, mutation_size, number_of_mutations,\n",
    "                          total_nudge_size, nudge_label):\n",
    "    \"\"\"\n",
    "    Mutate the distribution to minimize nudge impact and maximize entropy\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    initial_distribution: a numpy array\n",
    "        Representing a discrete probability distribution\n",
    "    function_label: an integer\n",
    "    nudge_size: a (small) number\n",
    "    number_of_nudges: an integer\n",
    "    \n",
    "    \"\"\"\n",
    "    total_number_of_states = reduce(lambda x, y: x*y, initial_distribution.shape)\n",
    "    local_nudge_size, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "                             \n",
    "    distribution = initial_distribution\n",
    "    nudge_impacts = []\n",
    "    for i in range(evaluations_per_trial):\n",
    "        nudge_impacts.append(get_nudge_impact(\n",
    "            ProbabilityArray(initial_distribution), output_label, nudge_label, number_of_nudges, local_nudge_size\n",
    "        ))                        \n",
    "    prev_nudge_impact = np.mean(nudge_impacts)\n",
    "    initial_nudge_impact = prev_nudge_impact\n",
    "    #print(prev_nudge_impact)\n",
    "             \n",
    "    for i in range(number_of_trials):\n",
    "        #print(i)\n",
    "        #print(\"number of mutations {}\".format(number_of_mutations))\n",
    "        proposed_distribution = nudge.mutate_distribution_with_fixed_marginals(\n",
    "            distribution, output_label, int(number_of_mutations), mutation_size\n",
    "        ) \n",
    "        #print(\"found proposal distribution\")\n",
    "        nudge_impacts = []\n",
    "        for j in range(evaluations_per_trial):\n",
    "            nudge_impacts.append(get_nudge_impact(\n",
    "                ProbabilityArray(proposed_distribution), output_label, nudge_label,\n",
    "                number_of_nudges, local_nudge_size\n",
    "            ))\n",
    "        if np.mean(nudge_impacts) < prev_nudge_impact:\n",
    "            prev_nudge_impact = np.mean(nudge_impacts)\n",
    "            distribution = proposed_distribution\n",
    "            \n",
    "        #print(prev_nudge_impact)\n",
    "    \n",
    "    return distribution, prev_nudge_impact, initial_nudge_impact, prev_nudge_impact\n",
    "\n",
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 3, 4 \n",
    "#pdf = JointProbabilityMatrix(NUMBER_OF_VARIABLES+1, NUMBER_OF_STATES, 'random')\n",
    "#initial_distribution = pdf.joint_probabilities.joint_probabilities\n",
    "shape = [NUMBER_OF_STATES]*(NUMBER_OF_VARIABLES+1)\n",
    "initial_distribution = generate_distribution(\n",
    "    shape, 'fixed_entropy', \n",
    "    {\"entropy_size\":percentage_max_entropy(shape, 0.75)}\n",
    ")\n",
    "\n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "\n",
    "number_of_trials = 50\n",
    "evaluations_per_trial = 10\n",
    "mutation_size = 0.2 / (4.0**3)\n",
    "number_of_mutations = int(0.1 * 4**3)\n",
    "a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                      evaluations_per_trial, mutation_size, number_of_mutations, 0.01, 0)\n",
    "\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 3, 5 \n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "number_of_trials = 40\n",
    "evaluations_per_trial = 500\n",
    "\n",
    "mutation_size = 0.2/(NUMBER_OF_STATES**NUMBER_OF_VARIABLES)\n",
    "number_of_mutations = int(0.1 * NUMBER_OF_STATES**NUMBER_OF_VARIABLES)\n",
    "\n",
    "NUMBER_OF_SAMPLES = 5\n",
    "PERCENTAGE_MAX_ENTROPY = 0.75\n",
    "NUDGE_SIZE = 0.01\n",
    "\n",
    "mi_before = []\n",
    "mi_after = []\n",
    "impact_before = []\n",
    "impact_after = []\n",
    "\n",
    "DATA_PATH = \"data_experiments/\"\n",
    "FILE_NAME = \"minimize_individual_focused_nudge_impact_inspect_change_MI_3var_5states.json\"\n",
    "RUN = True\n",
    "if RUN:\n",
    "    for count in range(NUMBER_OF_SAMPLES):\n",
    "        print(count)\n",
    "\n",
    "        shape = [NUMBER_OF_STATES] * (NUMBER_OF_VARIABLES+1)\n",
    "        #initial_distribution = generate_distribution(shape, 'random_dirichlet')\n",
    "        initial_distribution = generate_distribution(\n",
    "            shape, 'fixed_entropy', \n",
    "            {\"entropy_size\":percentage_max_entropy(shape, PERCENTAGE_MAX_ENTROPY)}\n",
    "        )\n",
    "\n",
    "        a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                                evaluations_per_trial, mutation_size, number_of_mutations, NUDGE_SIZE, 0)\n",
    "\n",
    "        impact_before.append(a[2])\n",
    "        impact_after.append(a[3])\n",
    "        mi_before.append(calculate_mutual_information(\n",
    "            ProbabilityArray(initial_distribution), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "        ))\n",
    "        mi_after.append(calculate_mutual_information(\n",
    "            ProbabilityArray(a[0]), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "        ))\n",
    "        with open(DATA_PATH + FILE_NAME, 'w') as f:\n",
    "            json.dump(\n",
    "                {\n",
    "                    \"impact_before\": impact_before,\n",
    "                    \"impact_after\": impact_after,\n",
    "                    \"mi_before\": mi_before,\n",
    "                    \"mi_after\": mi_after\n",
    "                },\n",
    "                f,\n",
    "                indent=2\n",
    "            )\n",
    "\n",
    "    print(\"mean impact before {}\".format(np.mean(impact_before)))\n",
    "    print(\"mean impact before {}\".format(np.mean(impact_after)))\n",
    "\n",
    "    print(\"mean mi before {}\".format(np.mean(mi_before)))\n",
    "    print(\"mean mi after {}\".format(np.mean(mi_after)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impact_before = 4.26328397408e-06\n",
    "impact_after = 2.55118132475e-06\n",
    "\n",
    "mi_before = 0.0169666085862\n",
    "mi_after = 0.0158801512352\n",
    "\n",
    "expected_change = (impact_before-impact_after)*4261\n",
    "print(\"expected change {}\".format(expected_change))\n",
    "expected_mi_after = mi_before - expected_change \n",
    "print(expected_mi_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tryout cell to generate a joint with a certain entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = tuple([5, 5, 5, 5, 5])\n",
    "entropy_size = percentage_states_max_entropy(shape, 0.1)\n",
    "print(entropy_size)\n",
    "dist = generate_distribution(shape, method='fixed_entropy', arguments={\"entropy_size\": entropy_size})\n",
    "print(entropy(dist.flatten(), base=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 5 \n",
    "\n",
    "Now assume that the nudge on the local variable caually impacts the other input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_input_variables = 3\n",
    "number_of_states = 5\n",
    "nudge_size = 0.01\n",
    "\n",
    "input_distribution = generate_distribution()\n",
    "nudge_labels = [0]\n",
    "other_input_labels = list(range(1, number_of_input_variables))\n",
    "\n",
    "def calculate_new_distribution_after_nudge(distribution, nudge_labels, other_variable_labels):\n",
    "    \"\"\"\n",
    "    Perform a nudge on a subset of the variables and assume\n",
    "    they causally impact the other variables, and return the new\n",
    "    distribution\n",
    "    \n",
    "    Note:\n",
    "    ----\n",
    "    If the nudged variables contain 0 states than those states are removed\n",
    "    from the entire distribution\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a numpy array\n",
    "    nudge_labels: A list of integers\n",
    "        The variables that will be nudged\n",
    "    other_variable_labels: A list of integers\n",
    "    \n",
    "    Returns: a numpy array\n",
    "    -------\n",
    "    The new distribution\n",
    "    \n",
    "    \"\"\"\n",
    "    marginal_nudge = ProbabilityArray(distribution).marginalize(set(nudge_labels))\n",
    "    if np.all(marginal_nudge!=0):\n",
    "        conditional_on_nudge, other_labels, nudge_labels_old = (\n",
    "            ProbabilityArray(input_distribution).find_conditional(set(other_labels), set(nudge_labels))\n",
    "        )\n",
    "    else:\n",
    "        #adjust this to multiple nudge on input states\n",
    "        \n",
    "        for label in nudge_labels:\n",
    "            zero_states = [count for count, state in enumerate(marginal_nudge) if state == 0]\n",
    "            for zero_state in zero_states:\n",
    "                input_distribution = np.delete(input_distribution, zero_state, nudge_label)\n",
    "\n",
    "        marginal_nudge = ProbabilityArray(input_distribution).marginalize(set(nudge_labels))\n",
    "        conditional_on_nudge, other_labels, nudge_labels_old = (\n",
    "            ProbabilityArray(input_distribution).find_conditional(set(other_input_labels), set(nudge_labels))\n",
    "        )\n",
    "\n",
    "    marginal_nudged, nudges_states = nudge.nudge(\n",
    "        marginal_variable_old, nudge_size\n",
    "    )\n",
    "    input_distribution_new = probability_distributions.compute_joint(\n",
    "        marginal_nudged, conditional_on_nudge, nudge_labels_old\n",
    "    ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 6\n",
    "#### find the maximal local non-causal additive nudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nudge_impact(old_input, new_input, conditional_output, measure=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Find the impact of a nudge transforming the old input into\n",
    "    the new input.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    old_input: nd-array\n",
    "        representing a probability distribution\n",
    "    new_input: nd-array\n",
    "        representing a probability distribution\n",
    "    conditional_output: nd-array\n",
    "        represening the probability distribution, the last variable\n",
    "        should be the conditional output (in tree form the leaves should be\n",
    "        the conditional output)\n",
    "    measure: string\n",
    "        Should be in: {\"absolute\", \"kl-divergence\"}\n",
    "        \n",
    "    Returns: a number\n",
    "    \n",
    "    \"\"\"\n",
    "    number_of_input_vars = len(old_input.shape)\n",
    "    old_joint = probability_distributions.compute_joint(\n",
    "        old_input, conditional_output, set(range(0, number_of_input_vars, 1))\n",
    "    )\n",
    "    print(\"old joint {}\".format(old_joint))\n",
    "    old_output = ProbabilityArray(old_joint).marginalize(set([number_of_input_vars]))\n",
    "    new_joint = probability_distributions.compute_joint(\n",
    "        new_input, conditional_output, set(range(0, number_of_input_vars, 1))\n",
    "    )\n",
    "    new_output = ProbabilityArray(new_joint).marginalize(set([number_of_input_vars]))\n",
    "    if measure==\"absolute\":\n",
    "        return np.sum(np.absolute(old_output.flatten()-new_output.flatten()))\n",
    "    elif measure==\"kl-divergence\":\n",
    "        return entropy(old_output.flatten(), new_output.flatten(), base=2)\n",
    "    else:\n",
    "        raise ValueError(\"provide a valid measure\")\n",
    "        \n",
    "old_input = np.array([0.1, 0.2, 0.05, 0.3, 0.35])\n",
    "new_input = np.array([0.12, 0.18, 0.06, 0.31, 0.33])\n",
    "cond_output = np.array([\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.2, 0.5, 0.3],\n",
    "    [0.15, 0.45, 0.4],\n",
    "    [0.46, 0.18, 0.36],\n",
    "    [0.32, 0.43, 0.25]\n",
    "])\n",
    "find_nudge_impact(old_input, new_input, cond_output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First do it for distributions randomly drawn from the entire space of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import maximum_nudges\n",
    "from maximum_nudges import find_maximum_local_nudge\n",
    "from maximum_nudges import find_max_control_impact\n",
    "import nudge_new\n",
    "\n",
    "amount_of_states = 5\n",
    "amount_of_input_vars = 5\n",
    "number_of_samples = 50\n",
    "nudge_size = 0.01\n",
    "\n",
    "input_vars_to_random_local_impacts = {}\n",
    "input_vars_to_max_local_impacts = {}\n",
    "input_vars_to_random_control_impacts = {}\n",
    "input_vars_to_max_control_impacts = {}\n",
    "for input_vars in range(1, amount_of_input_vars+1, 1):\n",
    "    print(input_vars)\n",
    "    random_local_nudge_impacts = []\n",
    "    max_local_nudge_impacts = []\n",
    "    random_control_nudge_impacts = []\n",
    "    max_control_nudge_impacts = []\n",
    "    for i in range(number_of_samples):\n",
    "        shape = [amount_of_states]*(input_vars+1)\n",
    "        joint_distribution = generate_distribution(shape, \"random_dirichlet\")\n",
    "        input_dist = ProbabilityArray(joint_distribution).marginalize(set(list(range(input_vars))))\n",
    "        cond_output, output_label, input_labels = ProbabilityArray(joint_distribution).find_conditional(\n",
    "            set([input_vars]), set(list(range(input_vars)))\n",
    "        )\n",
    "\n",
    "        #find the nudge impacts\n",
    "        input_locally_nudged = nudge_new.local_non_causal(input_dist, nudge_size)\n",
    "        random_local_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_locally_nudged, cond_output\n",
    "        )\n",
    "        random_local_nudge_impacts.append(random_local_impact)\n",
    "        \n",
    "        temp_cond_output = np.reshape(cond_output, (amount_of_states**input_vars, amount_of_states))\n",
    "        #tryout\n",
    "        max_local_impact1 = maximum_nudges.find_maximum_local_nudge_without_conditional(\n",
    "            input_dist, temp_cond_output, nudge_size\n",
    "        )\n",
    "        max_local_impact = find_maximum_local_nudge(\n",
    "            input_dist, temp_cond_output, nudge_size\n",
    "        )\n",
    "        if abs(max_local_impact-max_local_impact1) > 10**(-7):\n",
    "            raise ValueError()\n",
    "\n",
    "        max_local_nudge_impacts.append(max_local_impact)\n",
    "        \n",
    "        input_control_nudged = nudge_new.control_non_causal(input_dist, nudge_size)\n",
    "        random_control_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_control_nudged, cond_output\n",
    "        )\n",
    "        random_control_nudge_impacts.append(random_control_impact)\n",
    "        \n",
    "        _, _, max_control_impact = find_max_control_impact(\n",
    "            input_dist, cond_output, nudge_size\n",
    "        )\n",
    "        max_control_nudge_impacts.append(max_control_impact)\n",
    "        \n",
    "    input_vars_to_random_local_impacts[input_vars] = random_local_nudge_impacts\n",
    "    input_vars_to_max_local_impacts[input_vars] = max_local_nudge_impacts\n",
    "    input_vars_to_random_control_impacts[input_vars] = random_control_nudge_impacts\n",
    "    input_vars_to_max_control_impacts[input_vars] = max_control_nudge_impacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_range, mean_random_local, std_random_local, batch_std_random_local = find_mean_std_mse(\n",
    "    input_vars_to_random_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_local, std_max_local, batch_std_max_local = find_mean_std_mse(\n",
    "    input_vars_to_max_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_random_control, std_random_control, batch_std_random_control = find_mean_std_mse(\n",
    "    input_vars_to_random_control_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_control, std_max_control, batch_std_max_control = find_mean_std_mse(\n",
    "    input_vars_to_max_control_impacts, batch_size=5\n",
    ")\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_max_local, label=\"max local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"random control\")\n",
    "plt.plot(plot_range, mean_max_control, label=\"max control\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"rendom control\")\n",
    "\n",
    "lower_bound_random_local = np.array(mean_random_local)-np.array(std_random_local)\n",
    "upper_bound_random_local = np.array(mean_random_local)+np.array(std_random_local)\n",
    "plt.fill_between(plot_range, lower_bound_random_local, upper_bound_random_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "\n",
    "lower_bound_random_control = np.array(mean_random_control)-np.array(std_random_control)\n",
    "upper_bound_random_control = np.array(mean_random_control)+np.array(std_random_control)\n",
    "plt.fill_between(plot_range, lower_bound_random_control, upper_bound_random_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plot_results(\n",
    "#    (input_vars_to_max_impacts, {'mean_label': 'max_local_nudges'}), \n",
    "#    xlabel=\"number of input variables\", ylabel = \"absolute impact\", \n",
    "#    title=\"maximum local non-causal additive nudges\", std_of_batches=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now do it for distributions with a limited entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import maximum_nudges\n",
    "from maximum_nudges import find_maximum_local_nudge\n",
    "from maximum_nudges import find_max_control_impact\n",
    "import nudge_new\n",
    "import evolutionary_algorithms as ea\n",
    "from probability_distributions import produce_distribution_with_entropy_evolutionary_old as get_entropy_dist\n",
    "\n",
    "amount_of_states = 5\n",
    "amount_of_input_vars = 4\n",
    "number_of_samples = 5\n",
    "nudge_size = 0.01\n",
    "entropy_amount = 0.9\n",
    "\n",
    "input_vars_to_random_local_impacts = {}\n",
    "input_vars_to_max_local_impacts = {}\n",
    "input_vars_to_random_control_impacts = {}\n",
    "input_vars_to_max_control_impacts = {}\n",
    "for input_vars in range(1, amount_of_input_vars+1, 1):\n",
    "    print(input_vars)\n",
    "    random_local_nudge_impacts = []\n",
    "    max_local_nudge_impacts = []\n",
    "    random_control_nudge_impacts = []\n",
    "    max_control_nudge_impacts = []\n",
    "    for i in range(number_of_samples):\n",
    "        #if i%2==0 and input_vars>2:\n",
    "        #    print(i)\n",
    "        #shape = [amount_of_states]*(input_vars+1)\n",
    "        #joint_distribution = generate_distribution(shape, \"fixed_entropy\", {\"entropy_size\": 0.9})\n",
    "        #input_dist = ProbabilityArray(joint_distribution).marginalize(set(list(range(input_vars))))\n",
    "        #cond_output, output_label, input_labels = ProbabilityArray(joint_distribution).find_conditional(\n",
    "        #    set([input_vars]), set(list(range(input_vars)))\n",
    "        #)\n",
    "\n",
    "        input_shape = [amount_of_states]*(input_vars)\n",
    "        max_entropy = np.log2(amount_of_states**input_vars)\n",
    "        entropy_size = max_entropy * entropy_amount\n",
    "        input_dist = get_entropy_dist(tuple(input_shape), entropy_size, 1200, initial_dist=\"random\")\n",
    "        print(\"percentage max entropy dist {}\".format(entropy(input_dist, base=2)/max_entropy))\n",
    "        input_dist = np.reshape(input_dist, tuple(input_shape))\n",
    "        #input_dist = generate_distribution(input_shape, \"fixed_entropy\", {\"entropy_size\": entropy_amount})\n",
    "        #input_dist = generate_distribution(input_shape, 'random_dirichlet')\n",
    "        cond_shape = [amount_of_states]*(input_vars+1)\n",
    "        cond_output = [\n",
    "            probability_distributions.compute_joint_uniform_random((amount_of_states,))\n",
    "            for i in range(amount_of_states**(input_vars))\n",
    "        ]\n",
    "        cond_output = np.array(cond_output)\n",
    "        cond_output = np.reshape(cond_output, cond_shape)\n",
    "\n",
    "        #find the nudge impacts\n",
    "        input_locally_nudged = nudge_new.local_non_causal_without_conditional(input_dist, nudge_size)\n",
    "        random_local_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_locally_nudged, cond_output\n",
    "        )\n",
    "        random_local_nudge_impacts.append(random_local_impact)\n",
    "        \n",
    "        temp_cond_output = np.reshape(cond_output, (amount_of_states**input_vars, amount_of_states))\n",
    "        max_local_impact = maximum_nudges.find_maximum_local_nudge_without_conditional(\n",
    "            input_dist, temp_cond_output, nudge_size\n",
    "        )\n",
    "        max_local_nudge_impacts.append(max_local_impact)\n",
    "        \n",
    "        input_control_nudged = nudge_new.control_non_causal(input_dist, nudge_size, True)\n",
    "        random_control_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_control_nudged, cond_output\n",
    "        )\n",
    "        random_control_nudge_impacts.append(random_control_impact)\n",
    "        \n",
    "        _, _, max_control_impact = find_max_control_impact(\n",
    "            input_dist, cond_output, nudge_size\n",
    "        )\n",
    "        max_control_nudge_impacts.append(max_control_impact)\n",
    "        \n",
    "    input_vars_to_random_local_impacts[input_vars] = random_local_nudge_impacts\n",
    "    input_vars_to_max_local_impacts[input_vars] = max_local_nudge_impacts\n",
    "    input_vars_to_random_control_impacts[input_vars] = random_control_nudge_impacts\n",
    "    input_vars_to_max_control_impacts[input_vars] = max_control_nudge_impacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_range, mean_random_local, std_random_local, batch_std_random_local = find_mean_std_mse(\n",
    "    input_vars_to_random_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_local, std_max_local, batch_std_max_local = find_mean_std_mse(\n",
    "    input_vars_to_max_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_random_control, std_random_control, batch_std_random_control = find_mean_std_mse(\n",
    "    input_vars_to_random_control_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_control, std_max_control, batch_std_max_control = find_mean_std_mse(\n",
    "    input_vars_to_max_control_impacts, batch_size=5\n",
    ")\n",
    "\n",
    "lower_bound_max_local = np.array(mean_max_local)-np.array(std_random_local)\n",
    "upper_bound_max_local = np.array(mean_max_local)+np.array(std_random_local)\n",
    "lower_bound_max_control = np.array(mean_max_control)-np.array(std_random_control)\n",
    "upper_bound_max_control = np.array(mean_max_control)+np.array(std_random_control)\n",
    "\n",
    "lower_bound_random_local = np.array(mean_random_local)-np.array(std_random_local)\n",
    "upper_bound_random_local = np.array(mean_random_local)+np.array(std_random_local)\n",
    "lower_bound_random_control = np.array(mean_random_control)-np.array(std_random_control)\n",
    "upper_bound_random_control = np.array(mean_random_control)+np.array(std_random_control)\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_max_local, label=\"max local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"random control\")\n",
    "plt.plot(plot_range, mean_max_control, label=\"max control\")\n",
    "\n",
    "plt.fill_between(plot_range, lower_bound_random_local, upper_bound_random_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_random_control, upper_bound_random_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_max_local, upper_bound_max_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_max_control, upper_bound_max_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"rendom control\")\n",
    "\n",
    "plt.fill_between(plot_range, lower_bound_random_local, upper_bound_random_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_random_control, upper_bound_random_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plot_results(\n",
    "#    (input_vars_to_max_impacts, {'mean_label': 'max_local_nudges'}), \n",
    "#    xlabel=\"number of input variables\", ylabel = \"absolute impact\", \n",
    "#    title=\"maximum local non-causal additive nudges\", std_of_batches=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from probability_distributions import produce_distribution_with_entropy_evolutionary as get_entropy_dist\n",
    "\n",
    "shape = tuple([5,5,5,5,5])\n",
    "entropy_size = np.log2(5**5) * 0.95\n",
    "print(\"the wanted entropy {}\".format(entropy_size))\n",
    "dist = get_entropy_dist(shape, entropy_size, 500)\n",
    "print(entropy(dist, base=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cond_nudge = np.array([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6]\n",
    "    ],\n",
    "    [\n",
    "        [7,8,9],\n",
    "        [10,11,12]\n",
    "    ]\n",
    "])\n",
    "a = np.take(cond_nudge, 1, axis=2).flatten()\n",
    "print(range(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
