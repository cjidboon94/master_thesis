{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import json\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "import powerlaw\n",
    "from jointpdf.jointpdf import JointProbabilityMatrix\n",
    "from jointpdf.jointpdf import FullNestedArrayOfProbabilities\n",
    "\n",
    "from extension_probability_matrix import JointProbabilityMatrixExtended\n",
    "import probability_distributions\n",
    "from probability_distributions import ProbabilityArray\n",
    "from simulate import find_mean_std_mse\n",
    "import nudge\n",
    "import plotting\n",
    "\n",
    "import information_theory\n",
    "from information_theory import calculate_mutual_information\n",
    "\n",
    "import nudge_new\n",
    "import maximum_nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_distribution(shape, method, arguments=None):\n",
    "    if method=='random_biased':\n",
    "        distribution = np.random.random(shape)\n",
    "        distribution = distribution/np.sum(distribution)\n",
    "        return distribution\n",
    "    elif method=='random_dirichlet':\n",
    "        return probability_distributions.compute_joint_uniform_random(shape)\n",
    "    elif method=='fixed_entropy':\n",
    "        return probability_distributions.generate_probability_distribution_with_certain_entropy(\n",
    "            shape, arguments['entropy_size']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('provide a valid method')\n",
    "        \n",
    "def calculate_amount_and_size_nudges(total_nudge_size, number_of_states, threshold=10):\n",
    "    \"\"\"\n",
    "    Calculate the nudge size and the number of nudges that need to be performed \n",
    "    to nudge a variable with the total nudge size. Assuming the distribution is\n",
    "    not too peaked, in other words, not too many states should have a probability\n",
    "    that is 10 times smaller than normal.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    total_nudge_size: a number\n",
    "        How much the variable need to be nudged\n",
    "    number_of_states: a number\n",
    "        The total number of states of the joint distribution\n",
    "    threshold: a float \n",
    "        Indicating how much smaller than uniform the value of the number\n",
    "        at the 95-99 percentile of points is. Defaults to 10 \n",
    "        \n",
    "    Returns: local_nudge, number_of_nudges\n",
    "    -------\n",
    "    local_nudge: a number \n",
    "        The size of the local nudge to be performed on the joint distribution\n",
    "    number_of_nudges: integer\n",
    "        How often the nudge need to be performed\n",
    "    \n",
    "    \"\"\"\n",
    "    assumed_min_size = 1.0/threshold\n",
    "    max_local_nudge = min(total_nudge_size, 0.1/number_of_states)\n",
    "    number_of_nudges = int(np.ceil(total_nudge_size/max_local_nudge))\n",
    "    local_nudge = total_nudge_size/float(number_of_nudges) \n",
    "    return local_nudge, number_of_nudges\n",
    "\n",
    "def percentage_max_entropy(shape, percentage):\n",
    "    \"\"\" \n",
    "    Return the percentage of the max-entropy given the shape\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    shape: iterable\n",
    "    percentage: float\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.log2(reduce(lambda x,y: x*y, shape)) * percentage\n",
    "\n",
    "def percentage_states_max_entropy(shape, percentage):\n",
    "    \"\"\" \n",
    "    Return the percentage of the max-entropy given the shape\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    shape: iterable\n",
    "    percentage: float\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.log2(reduce(lambda x,y: x*y, shape) * percentage)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make one cell for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_and_confidence(plot_range, mean, mean_label, confidence_interval, \n",
    "                             confidence_interval_title):\n",
    "    \"\"\"\n",
    "    Plot the mean and some kind of confidence interval (standard deviation or\n",
    "    mean-squared-error)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    plot_range: iterable\n",
    "    mean: an iterable\n",
    "        the mean of the values at that point\n",
    "    confidence_interval: an iterable\n",
    "        Representing the  interval of confidence in that point. \n",
    "        The iterable should have length plot_range.\n",
    "    confidence_interval_title: a string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lower_bound = np.array(mean)-np.array(confidence_interval)\n",
    "    upper_bound = np.array(mean)+np.array(confidence_interval)\n",
    "    plt.plot(plot_range, mean, label=mean_label)\n",
    "    plt.fill_between(plot_range, lower_bound, upper_bound, \n",
    "                     label='{}'.format(confidence_interval_title),\n",
    "                     alpha=0.2)\n",
    "    \n",
    "def plot_results(*args, **kwargs):\n",
    "    \"\"\"plot results from simulations\n",
    "    \n",
    "    Parameters:\n",
    "        args: 1 or more dicts. The dicts should have for the keys numerical\n",
    "            input values and for the values iterables of numbers.\n",
    "        kwargs: at least the arguments xlabel, ylabel, title\n",
    "        \n",
    "    \"\"\"\n",
    "    for argument in args:\n",
    "        data, meta_dict = argument\n",
    "        variable_range, mean, std, batches_std = (\n",
    "            find_mean_std_mse(data, 10)\n",
    "        )\n",
    "        \n",
    "        if kwargs['std_of_batches']: \n",
    "            plot_mean_and_confidence(variable_range, mean, meta_dict['mean_label'], \n",
    "                                     batches_std, \"batches stdev\")\n",
    "        else:\n",
    "            plot_mean_and_confidence(variable_range, mean, meta_dict['mean_label'], \n",
    "                                     std, \"batches stdev\")\n",
    "    \n",
    "    plt.xlabel(kwargs['xlabel'])\n",
    "    plt.ylabel(kwargs['ylabel'])\n",
    "    plt.legend()\n",
    "    plt.title(kwargs['title'])\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "Check the distance between a Dirichlet distribution and the uniform distribution for an \n",
    "increasing number of states.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72796092165768855, 1.1966011378651769, 1.5540368838931808, 1.8442217805559904, 2.0885981448614483, 2.2820284528837016, 2.4691461576507296, 2.6479747730907603, 2.7905086651147304, 2.9142831752869549, 3.0437849545115632, 3.1488330007809924, 3.2483987999065849, 3.3444644148242206, 3.4338631763511938, 3.512809146018296, 3.6009932080789824, 3.6767648583382591, 3.7525834962104136, 3.8198052027010072, 3.876073899442861, 3.931713029219738, 4.0126659149558481, 4.0604426318578284, 4.1179811262604158, 4.1771474176841803, 4.2279432127045826, 4.2705638560697423, 4.3270898530045594, 4.3695774101677616, 4.407336651472062, 4.4539609081935376, 4.5056324466152562, 4.5460579771447627, 4.5811534955280102, 4.6213160172846868, 4.6571526237434222, 4.6952168052745966, 4.7332664453851976, 4.7619486042415629, 4.8030125901772394, 4.8339328573246805, 4.8624715836457835, 4.9031840251724077, 4.9277034231550187, 4.9606645117851285, 4.984241212288814, 5.0151590321228889, 5.0485041050729089, 5.0806462060590185, 5.1015812498525559, 5.1241158569624368, 5.1582289082654498, 5.1812449186114478, 5.2070324137388413, 5.2330138999171796, 5.2584096568062533, 5.284347655983515, 5.3095902857033419, 5.3290011344187027, 5.3553907079748964, 5.3799539854882692, 5.4039112743042379, 5.4272389441815481, 5.4416593642369175, 5.4655791663075126, 5.4897266018679076, 5.5087336718472963, 5.5305235395997734, 5.54743904265331, 5.5692311729813024, 5.5897208637326825, 5.609322164284376, 5.6309884864260784, 5.6437043253788648, 5.6639517632304974, 5.685099206066786, 5.7018209012320078, 5.7229693647095541, 5.7358869681644888, 5.7545093783716803, 5.7746631796850378, 5.7929064421103353, 5.809397083905095, 5.8217860652332201, 5.8439151493086259, 5.8580361554308222, 5.8804117943334795, 5.8877372988871537, 5.9024680296888334, 5.919889121439355, 5.9382266742324044, 5.9551979098213392, 5.9685511061237166, 5.9805362213362168, 5.9974060574442607, 6.0154123269984243, 6.0335347983757712, 6.0380929640169123, 6.0554801173256987, 6.0693950623056319, 6.0870102264604897, 6.098188155273661, 6.1072140527589927, 6.1278389219195502, 6.1425644468571736, 6.1543967706817932, 6.1620063015333137, 6.1772354140304593, 6.1926999389368236, 6.2068469194589166, 6.2148462469520895, 6.2269819343245656, 6.239508006220813, 6.2516591126761112, 6.266083906474627, 6.2777872556170653, 6.2907653617891484, 6.3080250996182325, 6.3144032315147909, 6.3252404950210623, 6.3407766777884067, 6.3490960415404087, 6.3597702574607311, 6.3746308356287811, 6.3861130990831265, 6.3977821021278904, 6.4075389021664781, 6.4139669960301395, 6.4302994839952481, 6.4364091110761477, 6.4527901848735914, 6.4613461416701519, 6.4723855629407598, 6.4819649857170774, 6.4927036165583836, 6.5016300255943191, 6.5085764742176879, 6.5256718501635342, 6.5328346839854463, 6.5457894354893487, 6.5577034891293771, 6.565508635708567, 6.5780767377671037, 6.5875804335173083, 6.5950925013996509, 6.6077514300360987, 6.6142741024697527, 6.6237745345607273, 6.6324208741644215, 6.6421302568427283, 6.6510847571902829, 6.6621851816117443, 6.6707075551216661, 6.678278840524948, 6.6850379760996992, 6.7018740273785724, 6.7066153757573765, 6.7148530409034741, 6.7242714533969776, 6.7382717530620244, 6.7394723241438843, 6.752287212970268, 6.7600518358087465, 6.7662993830637932, 6.7767965551183469, 6.7864908921127771, 6.7918154131863941, 6.8029469232269744, 6.8105687088574696, 6.8215698250598846, 6.8327446287388147, 6.8386532698416538, 6.8450267928008612, 6.8524095672353171, 6.8592364679812201, 6.8682328119607075, 6.8767659049023147, 6.8863593369455449, 6.8952088656613286, 6.9016546748636447, 6.9092998689911322, 6.9147872632700071, 6.9253488087636521, 6.9367448769324129, 6.9447400584191019, 6.9474910673924812, 6.9562145146122729, 6.959977872489211, 6.9724769993214393, 6.9779122559191036, 6.9848851133427923, 6.9928697129666562, 7.002836353585665, 7.0070778357701418, 7.0139892727966782, 7.0236313790871794, 7.0292969578715452, 7.0383163873542776, 7.0465388277658443, 7.0525763471816845, 7.0616119654777956, 7.066799392584568, 7.0735609023353678, 7.0810089031365901, 7.0863710618024358, 7.0926569794844765, 7.1015822249493272, 7.1084690780595086, 7.1186397045478182, 7.1195380430138204, 7.1286099283525832, 7.1355211323512826, 7.1436416790730739, 7.1489164314134452, 7.1512910986367766, 7.1631997862363219, 7.1662938152577551, 7.1735614472824114, 7.1802300907987808, 7.1893865560593877, 7.192713032243617, 7.2004091924838249, 7.208788278955824, 7.2131320601258633, 7.2223533655364589, 7.2263228977004852, 7.2321619171628075, 7.2385508181944296, 7.2407755627529458, 7.2517254890978968, 7.2566236851791146, 7.2631774836092005, 7.266675037980141, 7.2780474209771198, 7.2826822254022083, 7.286669485424321, 7.2932725576116368, 7.2989865376161607, 7.3058778068746983, 7.3075314186208304, 7.3174792040133694, 7.321997362965865, 7.3326755014280698, 7.3372610547237045, 7.3408994908245058, 7.3469244498091539, 7.3504292880645021]\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 1000\n",
    "min_number_of_states = 2\n",
    "max_number_of_states = 250\n",
    "\n",
    "entropies_dirichlet = []\n",
    "for i in range(min_number_of_states, max_number_of_states, 1):\n",
    "    distances = []\n",
    "    for _ in range(SAMPLE_SIZE):\n",
    "        dirichlet_dist = np.random.dirichlet([1]*i)\n",
    "        #print(dirichlet_dist)\n",
    "        distance = entropy(dirichlet_dist, base=2)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    entropies_dirichlet.append(np.mean(distances))\n",
    "    \n",
    "print(entropies_dirichlet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VNX5wPHvm5CQPQGSsIeEfd9BFFSQ4gqKdanUBVGL\nVuv2a2tt69aKdrEu1VqtC1AV9wUVV7SioCC77DshhLBkIfueOb8/zk0YQhIGzGSSmffzPPPMzF3f\nO3fy5sy5554jxhiUUkr5vyBfB6CUUqppaMJXSqkAoQlfKaUChCZ8pZQKEJrwlVIqQGjCV0qpAKEJ\nXyEihSLSvYH5z4rIvR5sZ5GI3FDPvGQRMSLS6sfE2phE5A8i8oKHyz4gIq94O6Za+7xWRJY05T5b\nChHZKCLjfR1HS6MJv5GJSKqI/MTXcQCIyHgRcTkJvVBE0kXkTREZ5b6cMSbKGLOrvu0YY24yxjzo\n/Yitpkp0xpiHjTF1/oM6Uc3pvJ+s5vhPuT7GmAHGmEW+jqOl0YTfxHzwx5RhjIkCooExwBZgsYhM\n9GRlEQn2ZnBKqaajCb8OItJJRN4RkUwR2S0it7nNe8ApJb8kIgXOT8uRzryXgSTgQ6dEfZdbqel6\nEUkD/ucse6Gzbq5TFdLPbR+pIvJ7EdkkIodFZI6IhDnzNojIFLdlQ0QkS0SGNXRMxko3xtwHvAD8\nzW0bRkR6Oq/nisgzIvKxiBQBE5xps9yWv0hE1opIvojsFJFz3XbVTUS+dT6bz0Ukvp7POFZEXhSR\n/SKyT0RmiUiw8zk8C5zqfIa5daw7QUTWu71fKCIr3N4vFpGpHp7LV9zeXyMie0QkW0TuraPUHnoC\n5z1MRF5xtpUrIitEpH09n0VXEXnXiTFbRP5Vz3KnOdvJc55Pc5t3rYjscmLbLSJXus27TkQ2O9+l\nz0SkW13bB75xnnOd4zhVRIJE5B7ncznkHH9sPfGNF/sr8i5n2f0iMlVEzheRbSKSIyJ/cFt+tIgs\ndT6f/SLyLxEJdTvWLBHp6rwf4sTf13lfc26c8/iW83kXiMh6Eekt9m/okIjsFZGz3fZ71Hl1/x7I\nkb/XGc56h0XkJhEZJSLrnFjrPD8tgjFGH24P7D/BVcB9QCjQHdgFnOPMfwAoBc4HgoG/AMvc1k8F\nfuL2PhkwwEtAJBAO9AaKgElACHAXsAMIddvGBqAr0Bb4FpjlzLsLeMNt+xcB6+s5lvFAeh3TzwJc\nQKTz3gA9nddzgTxgrPNZhDnTqvc/2pk/yZnfGejrzFsE7HSOL9x5/9dan0Mr5/17wH+czyQRWA7c\n6My7FljSwDkKd85BvPP5HQT2YX/FhAMlQDsPz+Urzuv+QCEwzln2H0BF9bk8ifN+I/AhEOEsPwKI\nqeNYgoEfgMedzyIMGFf7c3C+B4eBq4FWwDTnfTtnvXygj7NsR2CA2/djB9DPWe8e4Lt6PtejzpEz\n7Tpn/e5AFPAu8HID37dK5/MOAX4BZAKvOudmgHNuUpzlR2B/dbZy9r0ZuMNtew9hC0jhwHrgV3V9\n3m7n5hxnWy8Bu4E/usWxu4Fz5f49qP4MnnXOxdnOtudjv6edgUPAmb7OVSeV33wdQHN7AKcAabWm\n/R6Y4/bl+MJtXn+gpIEvU/UXqLvbtHuBN93eB2ET1ni3bdzkNv98YKfzuhNQgJM8gLeBu+o5lvHU\nnfD7OjF1dt7XTvgv1Vp+LkcS/n+Ax+vZ3yLgHrf3NwOf1vocWgHtgTIg3G3ZacBXzutraSDhO8ss\nBn6KTRifA28C5wITgHUncC6r/9DvA15zWy4CKOfopHIi5/064Dtg8HGO41RsUmxVx7yazwGb6JfX\nmr/UWSYSyAUucf9MnWU+Aa6v9V0rBrrVsb+ac+Q27UvgZrf3fbD/COuKdzw2oQc776Od7Z3itswq\nYGo9n8UdwHtu70Oc5dcDnwJS1+ftnJuFbvOmYP95144jrp5z5f49qP4MOrvNzwZ+5vb+Hdz+MbWk\nh1bpHKsb0Mn56ZbrVCn8AZukqh1we10MhMnx6+b3ur3uBOypfmOMcTnzO9ez/B5nHYwxGdgS/yUi\nEgecB8zz5MDcdMZ+qY+pLqlj37V1xZbi61P7s4mqY5lu2D/m/W6f8X+wJShPfY1NMGc4rxcBZzqP\nr932c7xzWa0TbsdtjCnG/qE3dGwNnfeXgc+A10UkQ0T+LiIhdSzXFdhjjKms70Dd4ttTa9oebGIq\nAn4G3IT9TD+qrvrAfgb/dDv+HEA4+rt2Ivvdw5F/2nXJNsZUOa9LnOeDbvNLcL4TTrXLAhE5ICL5\nwMPYX20AGGMqsIWNgcCjxsm29ai9j6w64qjru+jp9uo8hpZGE/6x9mJ//sW5PaKNMed7uH59X0r3\n6RnYP0QARESwf/j73Jbp6vY6yVmn2n+Bq4DLgKXGGPf1PHExsNpJFMeLtba9QI8T3F9d2ygD4t0+\n4xhjzAAP9l+tdsL/mmMT/omcy/1Al+o3IhKOrS7x1FExG2MqjDF/Msb0B04DJgPX1LHeXiDJgwLD\nUd8ZRxLOd8YY85kxZhK2OmcL8Lzb9m+s9RmEG2O+O94x1LPfJGy1zcE6lj1Rzzix9jLGxGD/GUv1\nTBHpDNwPzAEeFZHWjbBPsNWpEW7vOzTSdps9TfjHWg4UiMjvRCRc7IXEgVKrKWMDDmLrOxvyJnCB\niEx0Sn2/xiZA9z/CW0Ski4i0xdZFvuE2bz4wHLgdW195XGJ1FpH7gRuwf1wn40VghhN7kLPNvsdd\ny40xZj+2GuZREYlxttNDRM50FjkIdKm+gFeP77DVC6OxVR0bsYnpFI5cfDyRc/k2MMW5WBiK/Zkv\ndSxXn6POu9gLy4PEtnLKx1aDuOpYbzn2n81fRSRS7MXesXUs9zHQW0R+LiKtRORn2GqlBSLSXuyF\n9Ejs96jQbV/PAr8XkQFOXLEiclk9x5DprOf+/X0NuFNEUkQkClsKf8ODXySeiMZ+NoXOd+iX1TOc\nQtBc7Pfteuxn1FhNg9cCV4ht8DASuLSRttvsacKvxfkZOBkYir3wk4Vt1VJny4Q6/AW4x/kJ/Zt6\n9rEVW0J/ytn+FGCKMabcbbFXsUlxF7YKZZbb+iXYesQU7EW0hnQSkUJsElgBDMJeK/jcw+OpHfty\nYAb2ImMetjRdu+TpiWuwF0c3YS8+vo0tnYK9ULcROCAiWfXEUQSsBja6fW5LsdUjh5xlPD6Xzj+M\nW4HXscmlEHtxrszD46l93js4x5SPvRj5Nbaap/Z+q7DnvyeQBqRjq2dqL5ftHMuvsVVNdwGTjTFZ\n2L/j/8OWxnOwv3J+6az3HrZF1utOtckGbDXgMZxqrIeAb53jGAPMduL+BvsZljqfU2P4DfBz7DWp\n5zm6UHMbtorvXqcqZwa2oHF6I+z3Xuyv1MPAn7B/awFBGq4WU74gIqnADcaYLxpY5j6gtzHmqiYL\nLIA4pdlcbHXDbl/Ho1Rj0BJ+C+RU81wPPOfrWPyJiEwRkQinauQf2NYhqb6NSqnGowm/hRGRX2Av\nxH1ijPnmeMurE3IRtlokA+gFXHGcliFKtShapaOUUgFCS/hKKRUgmlWvePHx8SY5OdnXYSilVIux\natWqLGNMgifLNquEn5yczMqVK30dhlJKtRgiUvsO7HpplY5SSgUITfhKKRUgNOErpVSAaFZ1+HWp\nqKggPT2d0tJSX4eiGllYWBhdunQhJKSuTiSVUo3NqwlfRO7EdtRlsHctzjDGnFDmTk9PJzo6muTk\nZGx/SsofGGPIzs4mPT2dlJQUX4ejVEDwWpWO07XpbcBIY8xA7Mg+V5zodkpLS2nXrp0mez8jIrRr\n105/uSnVhLxdh98KCHf6+o7g6D7dPabJ3j/peVWqaXmtSscYs09E/oHt8rUE+LyuLnlFZCYwEyAp\nKclb4SilVPNRXgS5aXA4FQ7vgcoSGHen13frzSqdNtjOqFKww6RFisgxXfkaY54zxow0xoxMSPDo\nZrFmb/78+WzatKlJ97lo0SJiY2MZNmwYffr04YwzzmDBggU185999lleeqnusVIamle97cmTJ9c5\nb/z48ce9We6JJ56guLjYg6NQyk+4qiB3L+z+Bla/DF8+CO/cAC/8BB7pBQ93gn+PgdeugE9/B8ue\nbZKwvHnR9ifY4eUyAUTkXexQb694cZ/Nwvz585k8eTL9+/c/Zl5lZSWtWnnnYz/99NNrkvzatWuZ\nOnUq4eHhTJw4kZtuuqnOdSorK+ud11ieeOIJrrrqKiIiIo6/sFItRWWZLZ0f3g05u53nXfZ17h6o\nchvPSIIhtgu06QZ9zoW4btAm2T7iukFkfH17aVTeTPhpwBgRicBW6UwEWmS/Ca+88gpPPvkk5eXl\nnHLKKfz73/8mODiYqKgobr/9dhYsWEB4eDjvv/8+O3fu5IMPPuDrr79m1qxZvPPOO1x//fUMHTqU\nJUuWMG3aNC655BKuu+46srKySEhIYM6cOSQlJXHttdcSFhbGypUryc/P57HHHmPy5MmcccYZPPnk\nkwwdOhSAcePG8fTTTzNkyJB6Yx46dCj33Xcf//rXv5g4cSIPPPAAUVFR/OY3v2H8+PFHxVNQUFAz\nb8eOHdx0001kZmYSHBzMW2+9BUBhYSGXXnopGzZsYMSIEbzyyivH1MF//vnn3H///ZSVldGjRw/m\nzJnD7NmzycjIYMKECcTHx/PVV19570Qp1dhK848k9Jxdbsk9FfLSOWoY4NAoaJsCif2g7/nQJsW+\nb5MMMV0g2Pet4L1Zh/+9iLyNHYauEljDjxyw408fbmRTRn5jhFejf6cY7p8yoN75mzdv5o033uDb\nb78lJCSEm2++mXnz5nHNNddQVFTEmDFjeOihh7jrrrt4/vnnueeee7jwwguZPHkyl156ZKjM8vLy\nmqqPKVOmMH36dKZPn87s2bO57bbbmD9/PgCpqaksX76cnTt3MmHCBHbs2MH111/P3LlzeeKJJ9i2\nbRulpaUNJvtqw4cP55FHHqlznns8DzzwQM30K6+8krvvvpuLL76Y0tJSXC4Xe/fuZc2aNWzcuJFO\nnToxduxYvv32W8aNG1ezXlZWFrNmzeKLL74gMjKSv/3tbzz22GPcd999PPbYY3z11VfExzdNKUap\nE1KcA9k7IXvHscm9OPvoZSPioW136Haak9C7O0k9xZbSm3lDBK/+yzHG3I8ddb7F+vLLL1m1ahWj\nRtlxr0tKSkhMTAQgNDS0pm57xIgRLFy4sN7t/OxnR4YpXbp0Ke++a4eivfrqq7nrrrtq5l1++eUE\nBQXRq1cvunfvzpYtW7jssst48MEHeeSRR5g9ezbXXnutR7E3NNaBezzVCgoK2LdvHxdffDFgb4yq\nNnr0aLp06QLYXw+pqalHJfxly5axadMmxo6142+Xl5dz6qmnehSnUl5XXmyTePYO57HzyOuSHLcF\nxVa9tE2BvpOPJPO23W1JPSzGV0fQKHz/G+MENFQS9xZjDNOnT+cvf/nLMfNCQkJqqjWCg4OprKys\ndzuRkZEe7a92NYmIEBERwaRJk3j//fd58803WbVqlUfbWrNmDf369ftR8VRr3bp1zeu6jtUYw6RJ\nk3jttddOaLtKNZqqCtvypSapuyX3/H1HLxvdCdr1gP4XQrue9tG2h61jb9W67u37gRaV8H1h4sSJ\nXHTRRdx5550kJiaSk5NDQUEB3bp1q3ed6OhoCgoK6p1/2mmn8frrr3P11Vczb948Tj/99Jp5b731\nFtOnT2f37t3s2rWLPn36AHDDDTcwZcoUTj/9dNq0aXPcuNetW8eDDz7ICy+84PGxRkdH06VLF+bP\nn8/UqVMpKyujqqrKo3XHjBnDLbfcwo4dO+jZsydFRUXs27eP3r1713weWqWjGkVRFmRuhaytR5fU\nD6eCy60gEhYL7XpB8ulOUu/hJPbu0DrKZ+H7kib84+jfvz+zZs3i7LPPxuVyERISwtNPP91gwr/i\niiv4xS9+wZNPPsnbb799zPynnnqKGTNm8Mgjj9RctK2WlJTE6NGjyc/P59lnn62pVhkxYgQxMTHM\nmDGj3v0uXryYYcOGUVxcTGJiIk8++SQTJ048oeN9+eWXufHGG7nvvvsICQmpuWh7PAkJCcydO5dp\n06ZRVlYGwKxZs+jduzczZ87k3HPPpVOnTnrRVnnG5YK8vZC17Uhyz9xm37tXwbQKt4m8/QDof9GR\nknq7nhDRttnXqTe1ZjWm7ciRI03tNt2bN2+ut1rC31x77bXHXOytlpGRwfjx49myZQtBQf7TyWkg\nnV9Vh8pyyNnpJPVtR56zd0CF270bEe0gvg8k9D76OaYz+NHfw8kQkVXGmJGeLKsl/BbgpZde4o9/\n/COPPfaYXyV7FUAqSm0iP7QZMjc7pfWttkWMcas2jE2yyTz5dCepO4k9sp3vYvcjWsJXPqXn189U\nVdrWMIc22eRe/ZyzE4zLLhPUyla71JTW+ziJvReEnlhjAqUlfKWUt1XXsbsn9UObbam95g5TsRdI\nE/vBgIvtc2J/W+cerGMg+IImfKVUw0py4eAGOLAeDm50qmW2QHnhkWViutiE3mOCTeqJ/WzJPSTc\nd3GrY2jCV0pZLpftA+bA+iMJ/sAGyEs7skxEO5vQh155pMSe2Nc2gVTNniZ8pQJRRYmtijmwwS3B\nb4By5/4RCbJt2LuOglHXQYdB0H4QRLf3bdzqR9GE30I98cQTzJw5U3ugVMdXkgv7f4CMNUeSe9a2\nIxdRQ6NtO/YhV0CHgTa5J/SDUP1u+RtN+C1UQ10OV1VVERwc7IOolM+5J/f9ayFjre0ErFpMF5vQ\n+11onzsMhLjkgG/L3hTKKqvYvL+ALfvzOZhfxqGCUg4VlHGooIxWQcI7vzzN6zFowj+O1NRUzj33\nXMaMGcN3333HqFGjmDFjBvfffz+HDh1i3rx5jB49muXLl3P77bdTWlpKeHg4c+bMoU+fPjz++OOs\nX7+e2bNns379eqZNm8by5cuPStRVVVXcfffdLFq0iLKyMm655RZuvPFGFi1axAMPPEB8fPxR3RI/\n9dRTx3Q5HBUVxY033sgXX3zB008/TVlZGb/5zW+orKxk1KhRPPPMM7Ru3Zrk5GQuv/xyPvnkE8LD\nw3n11Vdp3749gwcPZtu2bYSEhJCfn8+QIUNq3qtmqjq5719rE3zt5B6bBJ2GwvCroeNQ+9D27F5T\nWlFFRm4JGbmlZOSWkJZTTEZuCbklFWzYl8ehgrKjlm8TEUL7mDASolvTtW3T/JpqWQn/k7vtT9LG\n1GEQnPfXBhfZsWMHb731FrNnz2bUqFG8+uqrLFmyhA8++ICHH36Y+fPn07dvXxYvXkyrVq344osv\n+MMf/sA777zD7bffzvjx43nvvfd46KGH+M9//nNMqfzFF18kNjaWFStWUFZWxtixYzn77LMB6uyW\n+Lbbbjumy+GioiJOOeUUHn30UUpLS+nVqxdffvklvXv35pprruGZZ57hjjvuACA2Npb169fz0ksv\ncccdd7BgwQLGjx/PRx99xNSpU3n99df56U9/qsm+OSkvtsk9fQVkrNbk7iOlFVXsyixif14J+/Ns\nYl+Xnsem/fnkFJUftWxwkNAhJozosFaM6xlPSnwk3ROiGNwllvYxYYS2avpfVS0r4ftISkoKgwYN\nAmDAgAFMnDgREWHQoEGkpqYCkJeXx/Tp09m+fTsiQkVFBQBBQUHMnTuXwYMHc+ONN9Z0H+zu888/\nZ926dTX97uTl5bF9+3ZCQ0OP2y1xteDgYC655BIAtm7dSkpKCr179wZg+vTpPP300zUJf9q0aTXP\nd95px9G84YYb+Pvf/87UqVOZM2cOzz//fKN8duokuFy2a4H0FbBvJaSvtM0hq+9IjU2CTkM0uXtJ\nUVklqdlFpGYVk5pdxO6sItKyi8ktKSc1q5jyKlfNssFBQq/EKM4Z0J4ubSLoGBtGp7hwOseF+yyp\nN6RlJfzjlMS9xb1r4KCgoJr3QUFBNd0E33vvvUyYMIH33nuP1NRUxo8fX7PO9u3biYqKIiMjo87t\nG2N46qmnOOecc46avmjRouN2S1wtLCzM43p79y6Yq1+PHTuW1NRUFi1aRFVVFQMHDvRoW6oRFGXZ\npF6d3PethrI8O691DHQebge47jISOo+AqETfxusHSsqrSM0uYk92EbuziknNKmJ3dhGpWUXHVL0k\nRrcmuV0k3eOjOLN3AkO6xtE5LpyOseEkRLcmOKjldNDWshJ+M5aXl0fnzp0BmDt37lHTb7vtNr75\n5ht+9atf8fbbbx/TOdo555zDM888w1lnnUVISAjbtm2r2VZ9GupyuE+fPqSmptZ0Vfzyyy9z5pln\n1sx/4403uPvuu3njjTeOGqTkmmuu4ec//zn33nvvyXwEyhOuKlta3/u9faSvsN36gh33tH1/GPhT\nJ7mPtF0O6AXVk3K4qJwdmYWkZReTllPM3hz7nJZTfExSj49qTUp8BGf0TiAlPpLkdpEkx0eQ3C6S\nyNb+kyb950h87K677mL69OnMmjWLCy64oGb6nXfeyS233ELv3r158cUXmTBhAmeccUbNqFlgq1NS\nU1MZPnw4xhgSEhJqhjysT0NdDoeFhTFnzhwuu+yymou27gOVHz58mMGDB9O6deujBiy58sorueee\ne2qqfFQjKC+ypfa0ZbB3GexdcaSte3RH6DIKRl5nk3unodqXzAmqrHKRllPMhox8dhwsoKi8ih2H\nCtlywLaEqSYCnWLD6do2nPF9EujaJoLk+EhS4iPp1i6C6LDAuF7ltc7TRKQP8IbbpO7AfcaYJ+pb\nRztP877k5GRWrlxZ5y+Dt99+m/fff5+XX365yeLxu/Obv98m9rTv7fP+dU7du9i7UpPGHHnEdtX+\n2j1gjOFQQRmpWUXsySkmLbuY3dlF7DxUyK7Mopo6dREIaxVMSnwkfTtG07dDNL3aR5PcLpJOcWG0\nbuWfTZWbRedpxpitwFAnoGBgH/Cet/anfpxbb72VTz75hI8//tjXobQsh/dA6hL72POt7ZoA7MAc\nXUbauvekU+3r8DjfxtoCHC4qZ8uBArYcyGfLfvu87WAhJRVHulAODhI6x4XTK9HWqfdMjKJfxxj6\ndoimVbBWfzWkqap0JgI7jTF7mmh/qh7VrYpqe+qpp5o2kJbKPcGnLjnSz0x4W+h2GoyeaRN8h0HQ\nKtS3sTZTxhj2Oc0Z03KKST9czO6sIrYdLCTTrW69XWQofTtGM210EinxESS1i6Rb2wg6twknRBP7\nSWmqhH8FUOfo1iIyE5gJdni/uhhjjhncW7V8zWkshnod3mNL7qlLIHWxHSQbbIJPHgun/QqSx9mu\nCPTi6lFcLkNWYRl7DxezdGc22w4WsiurkN2ZRRSVHymxx0WE0K1tBGf2TqB3++rSegwJ0f47mLiv\neD3hi0gocCHw+7rmG2OeA54DW4dfe35YWBjZ2dm0a9dOk74fMcaQnZ1dM2Zvs1GYCbsW2UfqN8cm\n+FM1wdclr6SCtXtzWb3nMD+k53Iov4y0nGIKy2wzYhHo0iaclPgoRnZrS4/EKIZ0iaV7QhRRftQK\nprlrik/6PGC1MebgyazcpUsX0tPTyczMbOSwlK+FhYXV3FTmMxUlkLYUdn4Fu746cid3WJxN7Jrg\nj1JWaVvBbMrIZ/P+Ajbvzyctp5h9uSUABAn0bh9N57hwhneLo3f7aNrHhDE6uS1tIrWKy9eaIuFP\no57qHE+EhISQkpLSiOGogOZy2d4id/7PJvi0ZVBZCkEh0PUUOOteO4hHx6EQ5J+tOjxRUeUi/XAJ\nu7MK2XmoiM3789m0P58dhwqpdNkf4mEhQfTpEMPolLb0SIhkeFIbBneN0xJ7M+bVMyMikcAk4EZv\n7kepBhXnwI4vYPvntiRfnGWnJ/SzbeC7T7AXXFtH+TZOHymrrGLDvjyW7cph9Z7D7MoqIi2nmCrX\nkRrW9jGt6dcxhrP6JtKvYwz9O8WQ3C6yRd1lqryc8I0xRYB28qGaljFwYJ1N8Ns+t10WGBdExEOP\ns2wJvvt4iOnk60ibXHZhGZv3F7Bpf15NlYx7qd02cYzm/EEdSImPIiU+gpT4KNpqdYxf0N9eyj+U\nFdgLrds/h+0LoWC/nd5pGJxxF/Q6274OkHr4kvIqMgvK2JNTxHc7s5069/yjuhToEBNGv47RnNU3\nkcFdYhmV3JZ2Udoyxp9pwlctV34GbPnIPlKXgKvCdjbW4yyb4HtNCoiOxkorqth+sJDU7CJ2Zhay\nJi2XpbuyKa+0d6C2ChJ6JkYxrlc8/TvG0M95aKk98GjCVy1L5lbYssAm+X2r7LR2PWHML6H3OfbC\na7B/94tSVFbJ5v35bNiXx7r0PBZuOkiBW/PHnglRXHVKN/p1jCYhujWjU9oSEap/6koTvmruXC6b\n2KuTfPZ2O73zCJh4H/SdAgm9fRujF+UWl7Mxwyb3jRn5bMjIY3dWEdX3rLWLDGXSgPb8pF97uidE\n0q1tJOGhgdu6SDVME75qflwu2zZ+47uweQEUHoCgVpB8OpxyI/S9wC8vuBaUVrAxI5/vdmSxISOf\nLfvzycgrrZnfKTaMAZ1juWhIZwZ0imFg51jax7TWGxKVxzThq+bB5bJ9w298FzbOt0m+Vbith+83\nxdbJ+1HnYy6XYetB20pm5Z7DfL8rm52ZRYDtHKxnQhSjUtrSt0MMAzvHMKBTrNa5qx9NE77yHWPs\n+KwbnCSfnw7BrW2SH3Ax9D7Xb9rGG2P4IT2Pdem5rEw9zJIdWTVjoEa3bsXI5DZcPKwz/TrGMCql\nLTEB0j+7alqa8FXTy9oB616HdW/a7oSDQqDnRFsn3+c8CIvxdYQ/WmFZJevSc1mTlltT/56WUwxA\nfFQoZ/ZOYFzPeAZ1iaVHQpTewKSahCZ81TSKc2DDO/DD6/ZGKAmyNz+d+TtbJ9/Cq2v255Xw9dZM\n1u61SX77oQKqb1RNbhdBnw7R/OqsnpzZO4HEaK13V76hCV95T2UZbPsM1r1hn10VkDgAJj0Igy6D\nmI6+jvCkGGPYn1fKxox8Plm/ny0HCth8IB9jIDY8hKFd4zh3YAeGJsUxrGsccRFa966aB034qvHt\n/wFWvwRtS+qdAAAgAElEQVTr34bSXIhqb1vXDLnCDgzSAqVlF/PV1kMs25XNitTDZBXaO1bjImyC\nP3tALy4Y1JGeiVFaelfNliZ81TjKCmyCXzUX9q+1F1/7TYEh02zVTXDL+qrtzCxk+e4cftiby/LU\nHHY5LWg6x4Vzeq94hifF0SPR9u0e2iowumtQLV/L+itUzYsx9qaoVXNtS5uKIjtQ93l/h8GXQ3gb\nX0fosd1ZRXy7I4vtBwtYtiuHrQcLAFtFMywpjqvHdGNCn0SS4yN9HKlSJ08Tvjpx5UW2Xn7Fi7Zv\n+ZAIGPhTGH6tHay7BVRpVLkMP6Tn8vXWTBZty+SHvbkAhIcEMywpjvtH92d8n0SS20VoFY3yG5rw\nledydsOKF2DNy1CaB+0HwQWP2QuwLaAp5cH8Ur7elsnX2zJZsj2LvJIKggSGdI3jd+f25YJBHenS\nJpwgbSKp/JQmfNUwY+zIUN8/B9s+tc0p+18Io2+EpDHNujRfUFrBl5sP8c32TDbsy2PbwUIAEqNb\nc3b/9pzZx7aF11Y0KlBowld1qyiBta/C9/+BrK128JDTf21HiIrt7Ovo6lTlMmw7WMD6fXl8vvEg\n32zPpLzSRXxUKAM6xXLJ8C6c0TuBvh2itZpGBSRN+OpoxTm2bv77Z+1QgB2HwtRnbVcHIWG+ju4Y\nLpdh0bZDLFi3n6+3ZpLtdFfQISaMK09J4oJBHRme1EaraZRCE76qlpsGS/9t289XFNnOysbeDt3G\nNrtqm4P5pSzaeohVew6zbFcOaTnFxIaHML5PAmf2TmBAp1h6JUZpkleqFm8PYh4HvAAMBAxwnTFm\nqTf3qU5Q5jZY/A/bhl7EXoA97VZoP8DXkR2lsKySzzYc4L01+/h2ZxbG2Juehie14ddn9+b8QR0J\nCdb28Eo1xNsl/H8CnxpjLhWRUCDCy/tTnsrcCt88YhN9SDicchOcejPEdvF1ZDU2ZeTz2vI0vtp6\niIP5pVRUGbq2DefWCT2ZPKQTvfSuVqVOiNcSvojEAmcA1wIYY8qBcm/tT3no0Bb45u/2RqmQCBh7\nG5x6K0Ql+DoyjDFsP1TIwk0H+XTDAdbvyyO0VRBn9UnkwiGdOKtvIiO6tdEkr9RJ8mYJPwXIBOaI\nyBBgFXC7MabIfSERmQnMBEhKSvJiOAEueyf8bxZsfA9CI2HcHTbRR7bzdWTszSnmrZV7+eCHDFKz\nbRfCQ7vGce/k/lwyvLM2m1SqkYipHhyzsTcsMhJYBow1xnwvIv8E8o0x99a3zsiRI83KlSu9Ek/A\nKjgIX//Ndn/QKgzG3ASn/goi2vo0rOo6+flr97FkRxYA43rGc86ADkzq3572Mc2vRZBSzZGIrDLG\njPRkWW+W8NOBdGPM9877t4G7vbg/5a40H757EpY+DVXltv38mXdBVKLPQsotLmfud6l8tyObdfty\nKa1w0bVtOHdM7M2lI7vQOS7cZ7EpFQi8lvCNMQdEZK+I9DHGbAUmApu8tT/lqCyHlS/aC7LF2TDw\nEpjwR2jXwyfhGGP4fncOLyzezeLtmZRVuhieFMcVo5KYMsS2kdc6eaWahrdb6dwKzHNa6OwCZnh5\nf4Ft+0L49PeQvR1SzoRJf4JOw3wSys7MQl79Po3PNh4g/XAJ8VGtmTY6iStGd6Vvh+bf745S/sir\nCd8YsxbwqG5J/QjZO22i3/4ZtO0BP38Tep/T5GGUV7pYuOkg877fw3c7s2kVJIzvk8CvJvRk6rDO\nhIUEN3lMSqkj9E7blqys0DaxXPpve0F20oO2PX2rpmvVYoxh+e4cPtlwgAXr9pNVWEbnuHB+e04f\nLhvZhcRovfiqVHOhCb+l2vopfPwbyNsLQ6+EifdDdPsm231ZZRUfrM1g9repbN6fT+tWQZzeK4Er\nT0nijN4JBGu3Bko1O5rwW5r8/fDp72DT+5DQF2Z8Ct1ObbLdH8wv5bXlabyybA9ZheX0aR/N3y8Z\nzJQhnQgP1SobpZozTfgthcsFq2bDF3+CyjI46x447fYmqb6pqHKxYF0Gc75NZV16HgBn9U3kurEp\njO3ZTlvZKNVCaMJvCXLT4P1bYPc3kHIGTH6iSZpZFpZV8vryNGYv2U1GXik9E6P47Tl9OG9gB7on\nRHl9/0qpxqUJvzkzBtbOg0/uBuOyiX7EtV7vrnhvTjH//S6VN1bspaCsklNS2jLr4oGM752oXQ4r\n1YJpwm+uCg7Ch7fZYQW7jYWLnoa2KV7bnTGG1WmHeXHJbj7dcAAR4YJBHbl+XApDusZ5bb9Kqaaj\nCb852vY5zL8JyovgnL/YppZB3uvrfdWeHP72yVaWp+YQGx7CzDN6MP20bnSM1a4OlPInmvCbk6oK\n+PLPtg+c9gPh0tmQ0McruyqrrOLzjQd5d3U6X23NJCG6NQ9M6c/lo7oSEapfC6X8kf5lNxe5e+Ht\n6yB9OYyYAef+xQ5M0shcLsN7a/bx2MJt7MstIT4qlN+e04cZY5M10Svl5/QvvDnY+gm8dxO4qmyp\nfuAlXtnNtzuyeOijzWzan8+gzrHMmjpQb5JSKoBowvcll8t2jbDoL9BxCFw6p9GbWxpjWLnnME9/\ntYNFWzPpHBfOP68YypTBnbTFjVIBRhO+r5QV2FL9lgUw5Ocw+XEIadx+ZzZm5PHggk0s22Uvxv7+\nvL5MPy1ZOzFTKkBpwveFnN3w2jTI2gbn/tW2wmnEtvWHCkp59LNtvLlqL3HhIXoxVikFaMJveukr\n4dXL7Y1UV78L3cc32qZLK6qY/e1unv7fDsqrXFw/NoVbJ/YiNjyk0fahlGq5NOE3pc0L4J0bILoD\nXPVOo9XXV7kM765O5/GF28jIK2VS//b84fx+pMRHNsr2lVL+QRN+U/n+P/DJ76DzCJj2OkQlNMpm\nU7OK+NVrq9mwL58hXWL5x+VDOK1HfKNsWynlXzThe5sx8NVDdozZPhfAJS9AaMSP3mxWYRkvLN7N\nS0tTCQkO4slpw5gyuKP2XKmUqpdXE76IpAIFQBVQaYwJrOEOjYHP/gDL/g3DroYp/4SgH9dCprLK\nxdNf7eSZr3dQVunigkEdufu8vnRp8+P/iSil/FtTlPAnGGOymmA/zYvLBR/dCavm2lY45/zlR/eH\nk5ZdzB1vrGF1Wi6TB3fk/yb11m6KlVIe0yodb3BVwfybYd3rMO7/YOJ9P6rZpTG2O4T73t+ICPzz\niqFcNLRzIwaslAoE3k74BvhcRAzwH2PMc7UXEJGZwEyApKQkL4fTBFwu263xutdhwj1w5m9/1OY2\n7MvjTx9uZEXqYUYnt+Wxnw3R6hul1EnxKOGLyCBjzPqT2P44Y8w+EUkEForIFmPMN+4LOP8EngMY\nOXKkOYl9NB/GwGe/hzWvwBm//VHJvrpN/eMLtxEbHsqDFw3g56d0035vlFInzdMS/r9FpDUwF5hn\njMnzZCVjzD7n+ZCIvAeMBr5peK0W7H+z4PtnYczNMOGPJ72ZXZmFzJi7gj3ZxZzdvz1/vWQwbSO9\nP3atUsq/eZTwjTGni0gv4DpglYgsB+YYYxbWt46IRAJBxpgC5/XZwJ8bI+hm6dt/wuJ/wPBr4JyH\nT7rOfuGmg/zunXUI8Mr1pzCul7apV0o1Do/r8I0x20XkHmAl8CQwTGyj7z8YY96tY5X2wHtOu/BW\nwKvGmE8bIebmZ8O7sPA+GPBTO+7sSST7w0XlPPDhRt5fm0HfDtE8c9UIvVNWKdWoPK3DHwzMAC4A\nFgJTjDGrRaQTsBQ4JuEbY3YBQxox1uZp73Lb62XXMTD1mZNqZ78nu4irX1xORm4Jd/ykFzeP70lo\nK+8NaaiUCkyelvCfAl7EluZLqicaYzKcUn9gytkNr10BMZ3gildPuHtjYwzvrN7HrI82IcCbN53K\n8KQ23olVKRXwPK3DP1NEQoG+ThPLrcaYcmfey94MsNkqOQzzLrNt7q98GyLbndDqFVUu7nt/A68t\n38uo5Db8/dIhWoWjlPIqT6t0zgf+A+wEBEgRkRuNMZ94M7hmy+WCd34Bh1PhmvchvucJrZ5XXMEv\n563iu53Z3DKhB7+e1EdHn1JKeZ2nVTqPYbtI2AEgIj2Aj4DATPjf/B12LIQLHoXksSe06u6sIq6f\nu4K9h4t59LIhXDKii5eCVEqpo3ma8Auqk71jF7ZTtMCz7XNY9FcYMg1GXn9Cqy7dmc1Nr6wiSGDe\nDWMYndLWS0EqpdSxPE34K0XkY+BNbHcJlwErROSnAPU0y/Q/+Rnw3kxoPxAueOyEml++sSKNP763\ngeT4SGZPH0VSO+0eQSnVtDxN+GHAQeBM530mEA5Mwf4D8P+E76qCd2dCZRlcNtfjPu2rXIa/fLyZ\nF5bs5ozeCTw1bZgOOaiU8glPW+nM8HYgzd53T0LqYrjwXx5fpDXG8Nu3f+Dd1fu49rRk7rmgH62C\ntX29Uso3PMo+ItJFRN4TkUPO4x0RCZyrjRlrbD85/afCsKs8WsUYwyOfbeXd1fu44ye9eODCAZrs\nlVI+5WkGmgN8AHRyHh860/xfZTnMvwUiE2CKZ90muFyGBxds5t+LdjJtdBK3T+zVBIEqpVTDPE34\nCcaYOcaYSucxF2icUbibuyWPwaGNto+c8OPfBVtZ5eJ376xj9re7mTE2mYemDtRxZpVSzYKnCT9b\nRK4SkWDncRWQ7c3AmoUDG+zg44Muhz7nHnfxssoqbn1tDW+tSueOn/Tivsn99YYqpVSz4WnCvw64\nHDgA7AcuxXam5r+qR64Ki4Nz/3rcxY0x/P7d9Xyy4QD3Tu7PHT/prSV7pVSzctxWOiISDPzUGHNh\nE8TTfKx9Bfatgouf86ifnOcX7+Ld1fu48ye9uX5cShMEqJRSJ+a4JXxjTBUwrQliaT5KDsMXD0DS\nqTD48uMu/uzXO3n44y2cP6gDt551Yv3qKKVUU/H0xqtvReRfwBtAUfVEY8xqr0Tla189bJP+eX8/\nbqucD3/I4K+fbGHKkE48dvkQrbNXSjVbnib8oc6z+xCFBjirccNpBg5ughUv2H5yOg5ucNGNGXn8\n9u0fGNmtDY9eNoQQbWevlGrGPE341zsjWNUQke5eiMf3vvwzhEbDhD80uFhOUTkzX1pFXHgo/75q\nuI5QpZRq9jzNUm/XMe0tT1Z0mnGuEZEFnoflI2nfw7ZPYNztEFF/T5YVVS5umbeazMIynrtmBInR\nJzbSlVJK+UKDJXwR6QsMAGKre8Z0xGA7VPPE7cBmZ53myxh7oTaqPZxyUwOLGe7/YCNLd2Xz6GVD\nGNwlruliVEqpH+F4VTp9gMlAHLZnzGoFwC+Ot3Gnv50LgIeA/zvJGJvGji8g7Ts7qElo/UMNPrZw\nG69+n8Yvx/fQwUuUUi1KgwnfGPM+8L6InGqMWXoS238CuAuIrm8BEZkJzARISko6iV00AmPgq4eg\nTTIMu6bexbYcyOfpr3Zw6Ygu3HVOn6aLTymlGoGnF213iMgfgGT3dYwx19W3gohMBg4ZY1aJyPj6\nljPGPAc8BzBy5EjjYTyNa/fXtkfMKf+EVqF1LmKM4eGPtxAdFsI9F/TTu2iVUi2Opwn/fWAx8AVQ\n5eE6Y4ELnQHQw4AYEXnFGONZ/8JNacnjENXBDltYj5eX7eGbbZncO7k/cRF1/1NQSqnmzNOEH2GM\n+d2JbNgY83vg9wBOCf83zTLZ71sNuxbBpD9Dq9Z1LrJsVzZ//nATE/smMuO05CYNTymlGounzTIX\nOCV1//PtE9A6FkbU3RfcvtwSbpm3mqR2ETx+xVC9k1Yp1WJ5mvBvBz4UkRIRyReRAhHJ93QnxphF\nxpjJJxeiF+Xsgk0fwKjrIezYVqMul+HO19dSXuni+WtGEhOmY9EqpVouT6t0YoErgRRjzJ9FJAno\n6L2wmsjKOSBBMLruFqZzv0tleWoOj1w6mB4JUU0cnFJKNS5PS/hPA2M40mtmAfAvr0TUVCrLYO08\n6HMexHQ6ZvaBvFL+8flWxvdJ4FJtb6+U8gOelvBPMcYMF5E1AMaYwyLSspuqbP4QirNhZN0tSx/+\neDOVLsOfL9QhCpVS/sHTEn6FMxCKARCRBMDltaiawsrZ9kar7hOOmbV0ZzYf/JDBTWf2IKldRNPH\nppRSXuBpwn8SeA9IFJGHgCXAw16Lytsyt8Keb2HEtRB09EdQUeXigQ820qVNODeP7+Gb+JRSygs8\nqtIxxswTkVXARECAqcaYzV6NzJtWzYWgEBh67G0Bb69KZ+vBAp69agRhIcFNH5tSSnmJp3X4GGO2\nAFu8GEvTcFXBhneg9zkQlXDUrLLKKp76cjtDu8ZxzoD2PgpQKaW8I/BG7djzLRQehIGXHDPrte/T\nyMgr5ddn99YLtUopvxN4CX/DuxASaUv4bvKKK3jiy+2c2r0d43rG+yg4pZTynsBK+FUVsOl92/a+\nVp/3T/5vO/klFdw3pb+W7pVSfimwEv6ur6Ek55jqnEMFpbyybA+XDO9Cv47Ne2AupZQ6WYGV8De8\nYztK6znxqMkvLN5tx6md0NNHgSmllPcFTsKvLIMtH0G/yUd1g5xTVM4ry/Zw4ZBOJMfXP7ShUkq1\ndIGT8FMXQ1ke9L/oqMmzl+ympKJKS/dKKb8XOAl/22fQKhxSzqiZlFdSwX+/S+W8gR3o1b7eYXeV\nUsovBEbCNwa2fQrdx0NIeM3kN1akUVBWyc3jtXSvlPJ/gZHwM7dAbtpRbe8rq1z897s9nJLSloGd\nY30YnFJKNY3ASPg7vrDPvSbVTPp04wH25ZZw/bgUHwWllFJNKzAS/q5FEN8bYo8MZDJ7yW66tYtg\nYj/tM0cpFRi8lvBFJExElovIDyKyUUT+5K19NaiyDPZ8Z+vvHWvSDrM6LZcZpyUTrIOSK6UChMe9\nZZ6EMuAsY0yhiIQAS0TkE2PMMi/u81jpK6Ci+KiE/9LSPUS3bsWlI7s2aShKKeVLXivhG6vQeRvi\nPIy39levXV/bgcq7jQWgqKySTzccYPKQTkS19ub/O6WUal68WocvIsEishY4BCw0xnxfxzIzRWSl\niKzMzMxs/CDSlkLHIRAeB8DCTQcpqahi6tBjBy5XSil/5tWEb4ypMsYMBboAo0VkYB3LPGeMGWmM\nGZmQkHDsRn6MynJIXwldx9RMmr92H51iwxiV3LZx96WUUs1ck7TSMcbkAl8B5zbF/mocWAeVJZBk\nE35WYRmLt2dx4dDOBOnFWqVUgPFmK50EEYlzXocDk2jqIRLTltpnJ+F/tG4/VS7D1GFanaOUCjze\nvGrZEfiviARj/7G8aYxZ4MX9HSttGbRJgegOgK3O6dshmr4dtM97pVTg8VrCN8asA4Z5a/seSV8J\n3c8EYG9OMWvScvnduX19GpJSSvmK/95pm78fCg9Ap+EAfLbxAADnD+rgy6iUUspn/DfhZ6yxz53s\nj4zPNx6kb4dourXTQU6UUoHJvxO+BEGHQWQWlLFiTw7nDNDSvVIqcPl3wk/oC6ERLNp6CGNgUn/t\nKE0pFbj8M+EbA/vX1lTnLN2VTdvIUPp31NY5SqnA5Z8Jv+AAFGVCh8EYY/h+Vw6npLTVm62UUgHN\nPxN+5mb73L4/6YdL2Jdbwqk92vk2JqWU8jH/TPiHnISf2J+lO7MBGNNdE75SKrD5acLfBJEJEBnP\nst3ZtIsMpVdilK+jUkopn/LThL8ZEvsBsCI1h1HJbRHR+nulVGDzv4TvcsGhLZDYnwN5pezNKWFk\nchtfR6WUUj7nfwk/by9UFEFiP1ak5gAwOkX7vldKKf9L+Jlb7XNCX1ak5hARGqzt75VSCn9M+Dm7\n7HPbHqxIPczwpDa0Cva/w1RKqRPlf5kwZxeERpMXFMuWA/k6lKFSSjn8M+G3TWF1Wi7GwCi9YKuU\nUoDfJvzurEjNoVWQMCxJE75SSoG/JfyqSsjdU5PwB3aOJTw02NdRKaVUs+DNQcy7ishXIrJJRDaK\nyO3e2leNvL3gqqQyNpkf0vO0Okcppdx4cxDzSuDXxpjVIhINrBKRhcaYTV7bo9NCZ690oLyykkFd\n4ry2K6WUamm8VsI3xuw3xqx2XhcAm4HO3tofUJPwN5bGA2j7e6WUctMkdfgikgwMA76vY95MEVkp\nIiszMzN/3I5y0yA4lDWHWxMWEkRKvI5fq5RS1bye8EUkCngHuMMYk197vjHmOWPMSGPMyISEhB+3\ns/wMiO7Ipv2F9GkfTbAOeKKUUjW8mvBFJASb7OcZY9715r4AyM/AxHRi84F8+ml1jlJKHcWbrXQE\neBHYbIx5zFv7OUpBBqXhHcgtrtCEr5RStXizhD8WuBo4S0TWOo/zvbY3YyA/g0yxI1v17RDttV0p\npVRL5LVmmcaYJUDTVaIXZ0NVOftctu19r/aa8JVSyp3/3Gmbvw+AnWVxtIkIoW1kqI8DUkqp5sWP\nEn4GAJsKI+mRoOPXKqVUbX6X8NfkRtA9QdvfK6VUbX6V8I0Es7UoQkv4SilVB79K+BURibgI0oSv\nlFJ18J+EX5BBYYjtQ6dHoiZ8pZSqzX8SfnE2ORJLqyCha5twX0ejlFLNjh8l/ByyXVF0igvXQcuV\nUqoO/pMZi3M4UB5BFy3dK6VUnbw5AErTKS+GyhL2usI14SulVD38o4RfnA3A3rIIurSJ8HEwSinV\nPPlHwi/JAeCwiaJrWy3hK6VUXfwj4Tsl/MMmWkv4SilVDz9J+LaEn0O01uErpVQ9/CTh2xJ+YVAM\n7aPDfByMUko1T36S8G0JPyo2niAdx1YpperkJwk/mwKJIjFOu1RQSqn6+E3CzyWGxJjWvo5EKaWa\nLW8OYj5bRA6JyAZv7aOaKckhyxVJYrQmfKWUqo83S/hzgXO9uP0arsJssl1RJOoFW6WUqpfXEr4x\n5hsgx1vbP2pfxVkcNtEkaAlfKaXq5fM6fBGZKSIrRWRlZmbmyW2j5DA5RGuVjlJKNcDnCd8Y85wx\nZqQxZmRCQsLJbIBvx/2XV6p+oiV8pZRqQMvvLVOEba16s9dUaR2+Uko1wOcl/MaQWVhGaKsgYsJb\n/v8vpZTyFm82y3wNWAr0EZF0EbneW/vKzC8jIao1InqXrVJK1cdrRWJjzDRvbbu2QwVletOVUkod\nh39U6RTYEr5SSqn6+UXCP1RQqiV8pZQ6jhaf8I0xjO+TyIhubXwdilJKNWstvlmLiPD4z4b6Ogyl\nlGr2WnwJXymllGc04SulVIDQhK+UUgFCE75SSgUITfhKKRUgNOErpVSA0ISvlFIBQhO+UkoFCDHG\n+DqGGiKSCew5gVXigSwvhdOc6XEHjkA8ZgjM4z7ZY+5mjPFo9KhmlfBPlIisNMaM9HUcTU2PO3AE\n4jFDYB53UxyzVukopVSA0ISvlFIBoqUn/Od8HYCP6HEHjkA8ZgjM4/b6MbfoOnyllFKea+klfKWU\nUh7ShK+UUgGixSZ8ETlXRLaKyA4RudvX8XiLiKSKyHoRWSsiK51pbUVkoYhsd55b/HBfIjJbRA6J\nyAa3aXUep1hPOud+nYgM913kP049x/2AiOxzzvlaETnfbd7vnePeKiLn+CbqH0dEuorIVyKySUQ2\nisjtznS/Pt8NHHfTnW9jTIt7AMHATqA7EAr8APT3dVxeOtZUIL7WtL8Ddzuv7wb+5us4G+E4zwCG\nAxuOd5zA+cAngABjgO99HX8jH/cDwG/qWLa/811vDaQ4fwPBvj6GkzjmjsBw53U0sM05Nr8+3w0c\nd5Od75Zawh8N7DDG7DLGlAOvAxf5OKamdBHwX+f1f4GpPoylURhjvgFyak2u7zgvAl4y1jIgTkQ6\nNk2kjaue467PRcDrxpgyY8xuYAf2b6FFMcbsN8asdl4XAJuBzvj5+W7guOvT6Oe7pSb8zsBet/fp\nNPzBtWQG+FxEVonITGdae2PMfuf1AaC9b0LzuvqOMxDO/6+c6ovZblV2fnfcIpIMDAO+J4DOd63j\nhiY63y014QeSccaY4cB5wC0icob7TGN/+/l929pAOU7HM0APYCiwH3jUt+F4h4hEAe8Adxhj8t3n\n+fP5ruO4m+x8t9SEvw/o6va+izPN7xhj9jnPh4D3sD/pDlb/pHWeD/kuQq+q7zj9+vwbYw4aY6qM\nMS7geY78jPeb4xaREGzSm2eMedeZ7Pfnu67jbsrz3VIT/gqgl4ikiEgocAXwgY9janQiEiki0dWv\ngbOBDdhjne4sNh143zcRel19x/kBcI3TemMMkOdWFdDi1aqfvhh7zsEe9xUi0lpEUoBewPKmju/H\nEhEBXgQ2G2Mec5vl1+e7vuNu0vPt6yvXP+KK9/nYq9w7gT/6Oh4vHWN37FX6H4CN1ccJtAO+BLYD\nXwBtfR1rIxzra9ifsxXYusrr6ztObGuNp51zvx4Y6ev4G/m4X3aOa53zR9/Rbfk/Ose9FTjP1/Gf\n5DGPw1bXrAPWOo/z/f18N3DcTXa+tWsFpZQKEC21SkcppdQJ0oSvlFIBQhO+UkoFCE34SikVIDTh\nK6VUgNCEr/ySiCwSEa8Pgi0it4nIZhGZ58GycSJyc2Mtp9SJ0oSvVC0i0uoEFr8ZmGSMudKDZeOc\n5RtrOaVOiCZ85TMikuyUjp93+gf/XETCnXk1JXQRiReRVOf1tSIy3+kvPVVEfiUi/ycia0RkmYi0\nddvF1U7/4htEZLSzfqTTQdVyZ52L3Lb7gYj8D3vzT+1Y/8/ZzgYRucOZ9iz25rhPROTOWssPcPax\n1ukUqxfwV6CHM+0REYkSkS9FZLXYMQ+qe3w9ajlne78VkRXOtv7kdiwficgPTlw/a5QTo/yXr+8+\n00fgPoBkoBIY6rx/E7jKeb0I545KIB5IdV5fi+0mNhpIAPKAm5x5j2M7pKpe/3nn9Rk4/c0DD7vt\nIw57t3aks9106rhrGRiBvRMyEojC3vU8zJmXSq3xCpzpTwFXOq9DgXDneN37vW8FxLgd4w7sXaW1\nlzsbO8C1YAtpC5xjuqT6GJ3lYn19TvXRvB8n8tNVKW/YbYxZ67xehU12x/OVsf2JF4hIHvChM309\nMOGeH14AAAHqSURBVNhtudfA9jkvIjEiEodNnheKyG+cZcKAJOf1QmNMXX3TjwPeM8YUAYjIu8Dp\nwJoGYlwK/FFEugDvGmO2265UjiLAw04PqC5s17d1dXV9tvOo3l8Utl+VxcCjIvI3YIExZnED8Sil\nCV/5XJnb6ypsSRhsyb+6yjGsgXVcbu9dHP2drt1viMEm2UuMMVvdZ4jIKUDRCUXeAGPMqyLyPXAB\n8LGI3AjsqrXYldhfKSOMMRVOtVXtY8WJ+S/GmP8cM8MO93c+MEtEvjTG/LmxjkH5H63DV81VKrYq\nBeDSk9zGzwBEZBy2h8U84DPgVqfnQkRkmAfbWQxMFZEIp9fSi51p9RKR7sAuY8yT2F4fBwMF2Kqo\narHAISfZTwC6OdNrL/cZcJ3Tjzoi0llEEkWkE1BsjHkFeAQ7VKJS9dISvmqu/gG8KXaUr49Ochul\nIrIGCAGuc6Y9CDwBrBORIGA3MLmhjRhjVovIXI50TfuCMaah6hyAy7EXjSuwozc9bIzJEZFvxQ5Y\n/gnwN+BDEVkPrAS2OPvLdl/OGPNbEekHLHX+TxUCVwE9gUdExIXtbfOXnn0sKlBpb5lKKRUgtEpH\nKaUChCZ8pZQKEJrwlVIqQGjCV0qpAKEJXymlAoQmfKWUChCa8JVSKkD8P3jouzV4DoPEAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb1adf5c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(2,250,1)), entropies_dirichlet, label=\"entropy Dirichlet\")\n",
    "plt.plot(list(range(2,250,1)), np.log2(list(range(2,250,1))), label=\"max entropy\")\n",
    "plt.xlabel(\"number of states\")\n",
    "plt.ylabel(\"entropy\")\n",
    "plt.title('entropy Dirichlet weights close to maximum')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2A\n",
    "\n",
    "See what the distance is between 2 randomly generated functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the average \"distance\" (KL-divergence) between randomly (probability masses states are distributed according to Dirichlet distribution) generated distributions. The distance decreases, since, the number of\n",
    "states that are close to uniform increases as the number of states for a distribution grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_states, number_of_variables = 5, 4\n",
    "shape = tuple([number_of_states]*(number_of_variables+1))\n",
    "total_nudge_size = 0.01\n",
    "total_number_of_states = number_of_states**number_of_variables\n",
    "max_local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "    total_nudge_size, total_number_of_states\n",
    ")\n",
    "\n",
    "total_nudge_sizes = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "    distribution = ProbabilityArray(generate_distribution(\n",
    "        shape, 'fixed_entropy', \n",
    "        {\"entropy_size\":percentage_states_max_entropy(shape, 0.1)}\n",
    "    ))\n",
    "    function_labels, label_nudged_variable = set([number_of_variables]), 0\n",
    "    input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    marginal_nudged_old = ProbabilityArray(input_distribution).marginalize(\n",
    "        set([label_nudged_variable])\n",
    "    ) \n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, 0, max_local_nudge, number_of_nudges\n",
    "    )\n",
    "    marginal_nudged_new = ProbabilityArray(new_input_distribution).marginalize(\n",
    "        set([label_nudged_variable])\n",
    "    ) \n",
    "    total_nudge_sizes.append(np.sum(np.absolute(marginal_nudged_old-marginal_nudged_new)))\n",
    "    \n",
    "print(np.mean(total_nudge_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_states, number_of_distributions = 5, 20\n",
    "difference_distributions = []\n",
    "for number_of_variables in range(1, 6, 1):\n",
    "    marginal_outputs = []\n",
    "    shape = tuple([number_of_states]*(number_of_variables+1))\n",
    "    for i in range(number_of_distributions):\n",
    "        print(i)\n",
    "        #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "        distribution = ProbabilityArray(generate_distribution(\n",
    "            shape, 'fixed_entropy', \n",
    "            {\"entropy_size\":percentage_max_entropy(shape, 0.75)}\n",
    "        ))\n",
    "        function_label, label_nudged_variable = number_of_variables, 0\n",
    "        marginal_outputs.append(distribution.marginalize(set([function_label])))\n",
    "\n",
    "    kl_divergences = []\n",
    "    for i in range(int(number_of_distributions/2.0)):\n",
    "        kl_divergences.append(entropy(marginal_outputs[i].flatten(), marginal_outputs[i+1].flatten()))\n",
    "\n",
    "    difference_distributions.append(np.mean(kl_divergences))\n",
    "    print(np.mean(kl_divergences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2B \n",
    "\n",
    "The actual experiment- for non-causal nudges. Both for local and not local nudges. Local nudges can be performed with vector and focused nudges, while non-local nudges are always vector nudges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "    \n",
    "def product(it):\n",
    "    \"\"\"calculate the product of all terms in the iterable\"\"\"\n",
    "    return reduce(lambda x, y: x*y, it)\n",
    "    \n",
    "def calculate_focused_nudge_impact(distribution, total_nudge_size):\n",
    "    \"\"\" \n",
    "    For now calculate the impact of a local non-causal nudge on the input variables\n",
    "    on the completely causally determined output variable\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a ProbabilityArray object\n",
    "    total_nudge_size: number\n",
    "    \n",
    "    \"\"\"\n",
    "    number_of_variables = len(distribution.probability_distribution.shape)\n",
    "    total_number_of_states = product(distribution.probability_distribution.shape)\n",
    "    max_local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "    function_labels, label_nudged_variable = set([number_of_variables-1]), 0\n",
    "    input_variable_labels = set(range(number_of_variables)) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, 0, max_local_nudge, number_of_nudges\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, function_labels,\n",
    "                                            new_input_distribution)\n",
    "\n",
    "def calculate_non_local_nudge_impact(distribution, total_nudge_size, nudged_variables):\n",
    "    \"\"\" \n",
    "    Calculate the impact of a non-local non-causal nudge (using a vector-nudge) \n",
    "    on the input variables on the completely causally determined output variable\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a ProbabilityArray object\n",
    "    total_nudge_size: number\n",
    "    nudged_variables: a list of integers\n",
    "    \n",
    "    \"\"\"\n",
    "    number_of_variables = len(distribution.probability_distribution.shape)\n",
    "    function_labels, label_nudged_variable = set([number_of_variables-1]), 0\n",
    "    input_variable_labels = set(range(number_of_variables)) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_non_local_non_causal(\n",
    "        input_distribution, nudged_variables, total_nudge_size, 'random'\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, function_labels,\n",
    "                                            new_input_distribution)\n",
    "\n",
    "number_of_variables = 5\n",
    "NUMBER_OF_STATES = 4\n",
    "TOTAL_NUDGE_SIZE = 0.01\n",
    "shape = tuple([NUMBER_OF_STATES] * (number_of_variables))\n",
    "distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "#distribution = ProbabilityArray(generate_distribution(\n",
    "#    shape, 'fixed_entropy', \n",
    "#    {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "#))\n",
    "\n",
    "focused_nudge_impact = calculate_focused_nudge_impact(distribution, TOTAL_NUDGE_SIZE)\n",
    "print(focused_nudge_impact)\n",
    "\n",
    "nudged_variables = [0] \n",
    "vector_nudge_impact = calculate_non_local_nudge_impact(\n",
    "    distribution, TOTAL_NUDGE_SIZE, nudged_variables\n",
    ")\n",
    "print(vector_nudge_impact)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment \n",
    "\n",
    "Look at differences of impact for local vector and focused nudges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_variables = 4\n",
    "NUMBER_OF_STATES = 4\n",
    "TOTAL_NUDGE_SIZE = 0.01\n",
    "nudged_variables = [0]\n",
    "number_of_samples = 100\n",
    "\n",
    "focused_nudge_impacts = []\n",
    "vector_nudge_impacts = []\n",
    "for i in range(number_of_samples):\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "        \n",
    "    shape = tuple([NUMBER_OF_STATES] * (number_of_variables))\n",
    "    #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "    distribution = ProbabilityArray(generate_distribution(\n",
    "        shape, 'fixed_entropy', \n",
    "        {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "    ))        \n",
    "    focused_nudge_impact = calculate_focused_nudge_impact(distribution, TOTAL_NUDGE_SIZE)\n",
    "    focused_nudge_impacts.append(focused_nudge_impact)\n",
    "    \n",
    "    vector_nudge_impact = calculate_non_local_nudge_impact(\n",
    "        distribution, TOTAL_NUDGE_SIZE, nudged_variables\n",
    "    )\n",
    "    vector_nudge_impacts.append(vector_nudge_impact)\n",
    "    \n",
    "print(\"mean & std focused nudge {} ({})\".format(\n",
    "    np.mean(focused_nudge_impacts), np.std(focused_nudge_impacts)\n",
    "))\n",
    "print(\"mean & std vector nudge {} ({})\".format(\n",
    "    np.mean(vector_nudge_impacts), np.std(vector_nudge_impacts)\n",
    "))\n",
    "differences = np.array(focused_nudge_impacts) - np.array(vector_nudge_impacts)\n",
    "print(\"mean & std difference focused minus vector {} ({})\".format(\n",
    "    np.mean(differences), np.std(differences)\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "The impact of a vector/focused nudge on the input variables \n",
    "(with no causal impact on the other input variables)\n",
    "on the output variable, for different number of input variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 5, 5, 0.01\n",
    "nudged_variables = [0]\n",
    "NUMBER_OF_SAMPLES = 10\n",
    "\n",
    "impact_focused_nudge_dict = {}\n",
    "impact_vector_nudge_dict = {}\n",
    "for number_of_variables in range(1, MAX_NUMBER_OF_VARIABLES, 1):\n",
    "    print(number_of_variables)\n",
    "    focused_nudge_impacts = []\n",
    "    vector_nudge_impacts = []\n",
    "    for i in range(NUMBER_OF_SAMPLES):\n",
    "        if i%5 == 0: \n",
    "            print(\"sample number {}\".format(i))\n",
    "            \n",
    "        shape = tuple([NUMBER_OF_STATES] * (number_of_variables+1))\n",
    "        #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "        distribution = ProbabilityArray(generate_distribution(\n",
    "            shape, 'fixed_entropy', \n",
    "            {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "        ))\n",
    "        focused_nudge_impact = calculate_focused_nudge_impact(distribution, TOTAL_NUDGE_SIZE)\n",
    "        focused_nudge_impacts.append(focused_nudge_impact)\n",
    "        vector_nudge_impact = calculate_non_local_nudge_impact(\n",
    "            distribution, TOTAL_NUDGE_SIZE, nudged_variables\n",
    "        )\n",
    "        vector_nudge_impacts.append(vector_nudge_impact)\n",
    "    \n",
    "    impact_focused_nudge_dict[number_of_variables] = focused_nudge_impacts\n",
    "    impact_vector_nudge_dict[number_of_variables] = vector_nudge_impacts\n",
    "    #with open(\"back_up_number_variables_output.json\", 'w') as f:\n",
    "    #    json.dump(impact_nudge_dict, f)\n",
    "\n",
    "#print(impact_nudge_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    (impact_focused_nudge_dict, {'mean_label': 'focused'}), \n",
    "    (impact_vector_nudge_dict, {'mean_label': 'vector'}),\n",
    "    xlabel=\"number of input variables\", ylabel = \"KL-divergence\", \n",
    "    title=\"the impact of the nudge given a number of variables\", std_of_batches=False\n",
    ")\n",
    "    \n",
    "\n",
    "#plotting.plot_mean_and_confidence(\n",
    "#    variable_range, np.array(mean_impact_nudge)/np.array(difference_distributions), batches_std,\n",
    "#    \"std of batched means\", xlabel, \"normalised impact of the nudge\", \"normalised values\"\n",
    "#)\n",
    "\n",
    "#fit = powerlaw.Fit(mean_impact_nudge)\n",
    "#print(fit.distribution_compare(\"power_law\", \"exponential\"))\n",
    "#print(fit.distribution_compare(\"power_law\", \"lognormal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2C\n",
    "\n",
    "Compare local vector nudges to synergistic nudges (nudges on the total distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 5, 5, 0.01\n",
    "NUMBER_OF_SAMPLES = 50\n",
    "\n",
    "impact_local_nudge_dict = {}\n",
    "impact_synergistic_nudge_dict = {}\n",
    "for number_of_input_variables in range(1, MAX_NUMBER_OF_VARIABLES, 1):\n",
    "    print(number_of_input_variables)\n",
    "    synergistic_nudge_impacts = []\n",
    "    local_nudge_impacts = []\n",
    "    for i in range(NUMBER_OF_SAMPLES):\n",
    "        if i%10 == 0: \n",
    "            print(\"sample number {}\".format(i))\n",
    "            \n",
    "        nudged_variables = list(range(number_of_input_variables))\n",
    "        random.shuffle(nudged_variables)\n",
    "        \n",
    "        shape = tuple([NUMBER_OF_STATES] * (number_of_input_variables+1))\n",
    "        #distribution = generate_distribution(shape, 'random_dirichlet')\n",
    "        distribution = generate_distribution(\n",
    "            shape, 'fixed_entropy', \n",
    "            {\"entropy_size\":percentage_max_entropy(shape, 0.7)}\n",
    "        )\n",
    "\n",
    "        distribution_copy = np.copy(distribution)\n",
    "        \n",
    "        distribution = ProbabilityArray(distribution)\n",
    "        distribution_copy = ProbabilityArray(distribution_copy)\n",
    "        \n",
    "        local_nudge_impact = calculate_non_local_nudge_impact(\n",
    "            distribution, TOTAL_NUDGE_SIZE, [0]\n",
    "        )\n",
    "        local_nudge_impacts.append(local_nudge_impact)\n",
    "\n",
    "        synergistic_nudge_impact = calculate_non_local_nudge_impact(\n",
    "            distribution_copy, TOTAL_NUDGE_SIZE, [0]\n",
    "        )\n",
    "        synergistic_nudge_impacts.append(synergistic_nudge_impact)\n",
    "        #print(\"difference local-synergistic {}\".format(local_nudge_impact-synergistic_nudge_impact))\n",
    "        \n",
    "\n",
    "        \n",
    "    impact_synergistic_nudge_dict[number_of_input_variables] = synergistic_nudge_impacts\n",
    "    impact_local_nudge_dict[number_of_input_variables] = local_nudge_impacts\n",
    "    #with open(\"back_up_number_variables_output.json\", 'w') as f:\n",
    "    #    json.dump(impact_nudge_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    (impact_local_nudge_dict, {'mean_label': 'local'}), \n",
    "    (impact_synergistic_nudge_dict, {'mean_label': 'synergetic'}),\n",
    "    xlabel=\"number of input variables\", ylabel = \"KL-divergence\", \n",
    "    title=\"Compare local and synergetic nudge impacts\", std_of_batches=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 4:\n",
    "Change the output so as to minimize the nudge impact. See what happens with the mutual information between\n",
    "the nudged variable and the output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_nudge_impact(distribution, output_label, nudge_label, number_of_nudges, local_nudge_size):\n",
    "    input_variable_labels = (set(range(len(distribution.probability_distribution.shape))) -\n",
    "                             set([output_label]))\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, nudge_label, local_nudge_size, number_of_nudges\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, set([output_label]),\n",
    "                                      new_input_distribution)\n",
    "\n",
    "def minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                          evaluations_per_trial, mutation_size, number_of_mutations,\n",
    "                          total_nudge_size, nudge_label):\n",
    "    \"\"\"\n",
    "    Mutate the distribution to minimize nudge impact and maximize entropy\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    initial_distribution: a numpy array\n",
    "        Representing a discrete probability distribution\n",
    "    function_label: an integer\n",
    "    nudge_size: a (small) number\n",
    "    number_of_nudges: an integer\n",
    "    \n",
    "    \"\"\"\n",
    "    total_number_of_states = reduce(lambda x, y: x*y, initial_distribution.shape)\n",
    "    local_nudge_size, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "                             \n",
    "    distribution = initial_distribution\n",
    "    nudge_impacts = []\n",
    "    for i in range(evaluations_per_trial):\n",
    "        nudge_impacts.append(get_nudge_impact(\n",
    "            ProbabilityArray(initial_distribution), output_label, nudge_label, number_of_nudges, local_nudge_size\n",
    "        ))                        \n",
    "    prev_nudge_impact = np.mean(nudge_impacts)\n",
    "    initial_nudge_impact = prev_nudge_impact\n",
    "    #print(prev_nudge_impact)\n",
    "             \n",
    "    for i in range(number_of_trials):\n",
    "        #print(i)\n",
    "        #print(\"number of mutations {}\".format(number_of_mutations))\n",
    "        proposed_distribution = nudge.mutate_distribution_with_fixed_marginals(\n",
    "            distribution, output_label, int(number_of_mutations), mutation_size\n",
    "        ) \n",
    "        #print(\"found proposal distribution\")\n",
    "        nudge_impacts = []\n",
    "        for j in range(evaluations_per_trial):\n",
    "            nudge_impacts.append(get_nudge_impact(\n",
    "                ProbabilityArray(proposed_distribution), output_label, nudge_label,\n",
    "                number_of_nudges, local_nudge_size\n",
    "            ))\n",
    "        if np.mean(nudge_impacts) < prev_nudge_impact:\n",
    "            prev_nudge_impact = np.mean(nudge_impacts)\n",
    "            distribution = proposed_distribution\n",
    "            \n",
    "        #print(prev_nudge_impact)\n",
    "    \n",
    "    return distribution, prev_nudge_impact, initial_nudge_impact, prev_nudge_impact\n",
    "\n",
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 3, 4 \n",
    "#pdf = JointProbabilityMatrix(NUMBER_OF_VARIABLES+1, NUMBER_OF_STATES, 'random')\n",
    "#initial_distribution = pdf.joint_probabilities.joint_probabilities\n",
    "initial_distribution = generate_distribution(\n",
    "    shape, 'fixed_entropy', \n",
    "    {\"entropy_size\":percentage_max_entropy(shape, 0.75)}\n",
    ")\n",
    "\n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "\n",
    "number_of_trials = 50\n",
    "evaluations_per_trial = 10\n",
    "mutation_size = 0.2 / (4.0**3)\n",
    "number_of_mutations = int(0.1 * 4**3)\n",
    "a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                      evaluations_per_trial, mutation_size, number_of_mutations, 0.01, 0)\n",
    "\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 4, 4 \n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "number_of_trials = 50\n",
    "evaluations_per_trial = 10\n",
    "mutation_size = 0.2 / (5.0**4)\n",
    "number_of_mutations = int(0.1 * 5**4)\n",
    "number_of_samples = 20\n",
    "\n",
    "mi_before = []\n",
    "mi_after = []\n",
    "\n",
    "impact_before = []\n",
    "impact_after = []\n",
    "\n",
    "for count in range(number_of_samples):\n",
    "    if count%2==0:\n",
    "        print(count)\n",
    "        \n",
    "    shape = [NUMBER_OF_STATES] * (NUMBER_OF_VARIABLES+1)\n",
    "    #initial_distribution = generate_distribution(shape, 'random_dirichlet')\n",
    "    initial_distribution = generate_distribution(\n",
    "        shape, 'fixed_entropy', \n",
    "        {\"entropy_size\":percentage_max_entropy(shape, 0.6)}\n",
    "    )\n",
    "\n",
    "    a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                          evaluations_per_trial, mutation_size, number_of_mutations, 0.01, 0)\n",
    "\n",
    "    impact_before.append(a[2])\n",
    "    impact_after.append(a[3])\n",
    "    mi_before.append(calculate_mutual_information(\n",
    "        ProbabilityArray(initial_distribution), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "    ))\n",
    "    mi_after.append(calculate_mutual_information(\n",
    "        ProbabilityArray(a[0]), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "    ))\n",
    "    \n",
    "print(\"mean impact before {}\".format(np.mean(impact_before)))\n",
    "print(\"mean impact before {}\".format(np.mean(impact_after)))\n",
    "    \n",
    "print(\"mean mi before {}\".format(np.mean(mi_before)))\n",
    "print(\"mean mi after {}\".format(np.mean(mi_after)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(mi_before)\n",
    "print(mi_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tryout cell to generate a joint with a certain entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = tuple([5, 5, 5, 5, 5])\n",
    "entropy_size = percentage_states_max_entropy(shape, 0.1)\n",
    "print(entropy_size)\n",
    "dist = generate_distribution(shape, method='fixed_entropy', arguments={\"entropy_size\": entropy_size})\n",
    "print(entropy(dist.flatten(), base=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 5 \n",
    "\n",
    "Now assume that the nudge on the local variable caually impacts the other input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_input_variables = 3\n",
    "number_of_states = 5\n",
    "nudge_size = 0.01\n",
    "\n",
    "input_distribution = generate_distribution()\n",
    "nudge_labels = [0]\n",
    "other_input_labels = list(range(1, number_of_input_variables))\n",
    "\n",
    "def calculate_new_distribution_after_nudge(distribution, nudge_labels, other_variable_labels):\n",
    "    \"\"\"\n",
    "    Perform a nudge on a subset of the variables and assume\n",
    "    they causally impact the other variables, and return the new\n",
    "    distribution\n",
    "    \n",
    "    Note:\n",
    "    ----\n",
    "    If the nudged variables contain 0 states than those states are removed\n",
    "    from the entire distribution\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a numpy array\n",
    "    nudge_labels: A list of integers\n",
    "        The variables that will be nudged\n",
    "    other_variable_labels: A list of integers\n",
    "    \n",
    "    Returns: a numpy array\n",
    "    -------\n",
    "    The new distribution\n",
    "    \n",
    "    \"\"\"\n",
    "    marginal_nudge = ProbabilityArray(distribution).marginalize(set(nudge_labels))\n",
    "    if np.all(marginal_nudge!=0):\n",
    "        conditional_on_nudge, other_labels, nudge_labels_old = (\n",
    "            ProbabilityArray(input_distribution).find_conditional(set(other_labels), set(nudge_labels))\n",
    "        )\n",
    "    else:\n",
    "        #adjust this to multiple nudge on input states\n",
    "        \n",
    "        for label in nudge_labels:\n",
    "            zero_states = [count for count, state in enumerate(marginal_nudge) if state == 0]\n",
    "            for zero_state in zero_states:\n",
    "                input_distribution = np.delete(input_distribution, zero_state, nudge_label)\n",
    "\n",
    "        marginal_nudge = ProbabilityArray(input_distribution).marginalize(set(nudge_labels))\n",
    "        conditional_on_nudge, other_labels, nudge_labels_old = (\n",
    "            ProbabilityArray(input_distribution).find_conditional(set(other_input_labels), set(nudge_labels))\n",
    "        )\n",
    "\n",
    "    marginal_nudged, nudges_states = nudge.nudge(\n",
    "        marginal_variable_old, nudge_size\n",
    "    )\n",
    "    input_distribution_new = probability_distributions.compute_joint(\n",
    "        marginal_nudged, conditional_on_nudge, nudge_labels_old\n",
    "    ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 6\n",
    "#### find the maximal local non-causal additive nudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nudge_impact(old_input, new_input, conditional_output, measure=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Find the impact of a nudge transforming the old input into\n",
    "    the new input.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    old_input: nd-array\n",
    "        representing a probability distribution\n",
    "    new_input: nd-array\n",
    "        representing a probability distribution\n",
    "    conditional_output: nd-array\n",
    "        represening the probability distribution, the last variable\n",
    "        should be the conditional output (in tree form the leaves should be\n",
    "        the conditional output)\n",
    "    measure: string\n",
    "        Should be in: {\"absolute\", \"kl-divergence\"}\n",
    "        \n",
    "    Returns: a number\n",
    "    \n",
    "    \"\"\"\n",
    "    number_of_input_vars = len(old_input.shape)\n",
    "    old_joint = probability_distributions.compute_joint(\n",
    "        old_input, conditional_output, set(range(0, number_of_input_vars, 1))\n",
    "    )\n",
    "    print(\"old joint {}\".format(old_joint))\n",
    "    old_output = ProbabilityArray(old_joint).marginalize(set([number_of_input_vars]))\n",
    "    new_joint = probability_distributions.compute_joint(\n",
    "        new_input, conditional_output, set(range(0, number_of_input_vars, 1))\n",
    "    )\n",
    "    new_output = ProbabilityArray(new_joint).marginalize(set([number_of_input_vars]))\n",
    "    if measure==\"absolute\":\n",
    "        return np.sum(np.absolute(old_output.flatten()-new_output.flatten()))\n",
    "    elif measure==\"kl-divergence\":\n",
    "        return entropy(old_output.flatten(), new_output.flatten(), base=2)\n",
    "    else:\n",
    "        raise ValueError(\"provide a valid measure\")\n",
    "        \n",
    "old_input = np.array([0.1, 0.2, 0.05, 0.3, 0.35])\n",
    "new_input = np.array([0.12, 0.18, 0.06, 0.31, 0.33])\n",
    "cond_output = np.array([\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.2, 0.5, 0.3],\n",
    "    [0.15, 0.45, 0.4],\n",
    "    [0.46, 0.18, 0.36],\n",
    "    [0.32, 0.43, 0.25]\n",
    "])\n",
    "find_nudge_impact(old_input, new_input, cond_output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First do it for distributions randomly drawn from the entire space of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import maximum_nudges\n",
    "from maximum_nudges import find_maximum_local_nudge\n",
    "from maximum_nudges import find_max_control_impact\n",
    "import nudge_new\n",
    "\n",
    "amount_of_states = 5\n",
    "amount_of_input_vars = 5\n",
    "number_of_samples = 50\n",
    "nudge_size = 0.01\n",
    "\n",
    "input_vars_to_random_local_impacts = {}\n",
    "input_vars_to_max_local_impacts = {}\n",
    "input_vars_to_random_control_impacts = {}\n",
    "input_vars_to_max_control_impacts = {}\n",
    "for input_vars in range(1, amount_of_input_vars+1, 1):\n",
    "    print(input_vars)\n",
    "    random_local_nudge_impacts = []\n",
    "    max_local_nudge_impacts = []\n",
    "    random_control_nudge_impacts = []\n",
    "    max_control_nudge_impacts = []\n",
    "    for i in range(number_of_samples):\n",
    "        shape = [amount_of_states]*(input_vars+1)\n",
    "        joint_distribution = generate_distribution(shape, \"random_dirichlet\")\n",
    "        input_dist = ProbabilityArray(joint_distribution).marginalize(set(list(range(input_vars))))\n",
    "        cond_output, output_label, input_labels = ProbabilityArray(joint_distribution).find_conditional(\n",
    "            set([input_vars]), set(list(range(input_vars)))\n",
    "        )\n",
    "\n",
    "        #find the nudge impacts\n",
    "        input_locally_nudged = nudge_new.local_non_causal(input_dist, nudge_size)\n",
    "        random_local_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_locally_nudged, cond_output\n",
    "        )\n",
    "        random_local_nudge_impacts.append(random_local_impact)\n",
    "        \n",
    "        temp_cond_output = np.reshape(cond_output, (amount_of_states**input_vars, amount_of_states))\n",
    "        #tryout\n",
    "        max_local_impact1 = maximum_nudges.find_maximum_local_nudge_without_conditional(\n",
    "            input_dist, temp_cond_output, nudge_size\n",
    "        )\n",
    "        max_local_impact = find_maximum_local_nudge(\n",
    "            input_dist, temp_cond_output, nudge_size\n",
    "        )\n",
    "        if abs(max_local_impact-max_local_impact1) > 10**(-7):\n",
    "            raise ValueError()\n",
    "\n",
    "        max_local_nudge_impacts.append(max_local_impact)\n",
    "        \n",
    "        input_control_nudged = nudge_new.control_non_causal(input_dist, nudge_size)\n",
    "        random_control_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_control_nudged, cond_output\n",
    "        )\n",
    "        random_control_nudge_impacts.append(random_control_impact)\n",
    "        \n",
    "        _, _, max_control_impact = find_max_control_impact(\n",
    "            input_dist, cond_output, nudge_size\n",
    "        )\n",
    "        max_control_nudge_impacts.append(max_control_impact)\n",
    "        \n",
    "    input_vars_to_random_local_impacts[input_vars] = random_local_nudge_impacts\n",
    "    input_vars_to_max_local_impacts[input_vars] = max_local_nudge_impacts\n",
    "    input_vars_to_random_control_impacts[input_vars] = random_control_nudge_impacts\n",
    "    input_vars_to_max_control_impacts[input_vars] = max_control_nudge_impacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_range, mean_random_local, std_random_local, batch_std_random_local = find_mean_std_mse(\n",
    "    input_vars_to_random_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_local, std_max_local, batch_std_max_local = find_mean_std_mse(\n",
    "    input_vars_to_max_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_random_control, std_random_control, batch_std_random_control = find_mean_std_mse(\n",
    "    input_vars_to_random_control_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_control, std_max_control, batch_std_max_control = find_mean_std_mse(\n",
    "    input_vars_to_max_control_impacts, batch_size=5\n",
    ")\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_max_local, label=\"max local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"random control\")\n",
    "plt.plot(plot_range, mean_max_control, label=\"max control\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"rendom control\")\n",
    "\n",
    "lower_bound_random_local = np.array(mean_random_local)-np.array(std_random_local)\n",
    "upper_bound_random_local = np.array(mean_random_local)+np.array(std_random_local)\n",
    "plt.fill_between(plot_range, lower_bound_random_local, upper_bound_random_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "\n",
    "lower_bound_random_control = np.array(mean_random_control)-np.array(std_random_control)\n",
    "upper_bound_random_control = np.array(mean_random_control)+np.array(std_random_control)\n",
    "plt.fill_between(plot_range, lower_bound_random_control, upper_bound_random_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plot_results(\n",
    "#    (input_vars_to_max_impacts, {'mean_label': 'max_local_nudges'}), \n",
    "#    xlabel=\"number of input variables\", ylabel = \"absolute impact\", \n",
    "#    title=\"maximum local non-causal additive nudges\", std_of_batches=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now do it for distributions with a limited entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name produce_distribution_with_entropy_evolutionary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c37ac96b426d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaximum_nudges\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_max_control_impact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnudge_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprobability_distributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduce_distribution_with_entropy_evolutionary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mget_entropy_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mamount_of_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name produce_distribution_with_entropy_evolutionary"
     ]
    }
   ],
   "source": [
    "import maximum_nudges\n",
    "from maximum_nudges import find_maximum_local_nudge\n",
    "from maximum_nudges import find_max_control_impact\n",
    "import nudge_new\n",
    "import evolutionary_algorithms as ea\n",
    "from probability_distributions import produce_distribution_with_entropy_evolutionary_old as get_entropy_dist\n",
    "\n",
    "amount_of_states = 5\n",
    "amount_of_input_vars = 4\n",
    "number_of_samples = 5\n",
    "nudge_size = 0.01\n",
    "entropy_amount = 0.9\n",
    "\n",
    "input_vars_to_random_local_impacts = {}\n",
    "input_vars_to_max_local_impacts = {}\n",
    "input_vars_to_random_control_impacts = {}\n",
    "input_vars_to_max_control_impacts = {}\n",
    "for input_vars in range(1, amount_of_input_vars+1, 1):\n",
    "    print(input_vars)\n",
    "    random_local_nudge_impacts = []\n",
    "    max_local_nudge_impacts = []\n",
    "    random_control_nudge_impacts = []\n",
    "    max_control_nudge_impacts = []\n",
    "    for i in range(number_of_samples):\n",
    "        #if i%2==0 and input_vars>2:\n",
    "        #    print(i)\n",
    "        #shape = [amount_of_states]*(input_vars+1)\n",
    "        #joint_distribution = generate_distribution(shape, \"fixed_entropy\", {\"entropy_size\": 0.9})\n",
    "        #input_dist = ProbabilityArray(joint_distribution).marginalize(set(list(range(input_vars))))\n",
    "        #cond_output, output_label, input_labels = ProbabilityArray(joint_distribution).find_conditional(\n",
    "        #    set([input_vars]), set(list(range(input_vars)))\n",
    "        #)\n",
    "\n",
    "        input_shape = [amount_of_states]*(input_vars)\n",
    "        max_entropy = np.log2(amount_of_states**input_vars)\n",
    "        entropy_size = max_entropy * entropy_amount\n",
    "        input_dist = get_entropy_dist(tuple(input_shape), entropy_size, 1200, initial_dist=\"random\")\n",
    "        print(\"percentage max entropy dist {}\".format(entropy(input_dist, base=2)/max_entropy))\n",
    "        input_dist = np.reshape(input_dist, tuple(input_shape))\n",
    "        #input_dist = generate_distribution(input_shape, \"fixed_entropy\", {\"entropy_size\": entropy_amount})\n",
    "        #input_dist = generate_distribution(input_shape, 'random_dirichlet')\n",
    "        cond_shape = [amount_of_states]*(input_vars+1)\n",
    "        cond_output = [\n",
    "            probability_distributions.compute_joint_uniform_random((amount_of_states,))\n",
    "            for i in range(amount_of_states**(input_vars))\n",
    "        ]\n",
    "        cond_output = np.array(cond_output)\n",
    "        cond_output = np.reshape(cond_output, cond_shape)\n",
    "\n",
    "        #find the nudge impacts\n",
    "        input_locally_nudged = nudge_new.local_non_causal_without_conditional(input_dist, nudge_size)\n",
    "        random_local_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_locally_nudged, cond_output\n",
    "        )\n",
    "        random_local_nudge_impacts.append(random_local_impact)\n",
    "        \n",
    "        temp_cond_output = np.reshape(cond_output, (amount_of_states**input_vars, amount_of_states))\n",
    "        max_local_impact = maximum_nudges.find_maximum_local_nudge_without_conditional(\n",
    "            input_dist, temp_cond_output, nudge_size\n",
    "        )\n",
    "        max_local_nudge_impacts.append(max_local_impact)\n",
    "        \n",
    "        input_control_nudged = nudge_new.control_non_causal(input_dist, nudge_size, True)\n",
    "        random_control_impact = nudge_new.find_nudge_impact(\n",
    "            input_dist, input_control_nudged, cond_output\n",
    "        )\n",
    "        random_control_nudge_impacts.append(random_control_impact)\n",
    "        \n",
    "        _, _, max_control_impact = find_max_control_impact(\n",
    "            input_dist, cond_output, nudge_size\n",
    "        )\n",
    "        max_control_nudge_impacts.append(max_control_impact)\n",
    "        \n",
    "    input_vars_to_random_local_impacts[input_vars] = random_local_nudge_impacts\n",
    "    input_vars_to_max_local_impacts[input_vars] = max_local_nudge_impacts\n",
    "    input_vars_to_random_control_impacts[input_vars] = random_control_nudge_impacts\n",
    "    input_vars_to_max_control_impacts[input_vars] = max_control_nudge_impacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_range, mean_random_local, std_random_local, batch_std_random_local = find_mean_std_mse(\n",
    "    input_vars_to_random_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_local, std_max_local, batch_std_max_local = find_mean_std_mse(\n",
    "    input_vars_to_max_local_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_random_control, std_random_control, batch_std_random_control = find_mean_std_mse(\n",
    "    input_vars_to_random_control_impacts, batch_size=5\n",
    ")\n",
    "plot_range, mean_max_control, std_max_control, batch_std_max_control = find_mean_std_mse(\n",
    "    input_vars_to_max_control_impacts, batch_size=5\n",
    ")\n",
    "\n",
    "lower_bound_max_local = np.array(mean_max_local)-np.array(std_random_local)\n",
    "upper_bound_max_local = np.array(mean_max_local)+np.array(std_random_local)\n",
    "lower_bound_max_control = np.array(mean_max_control)-np.array(std_random_control)\n",
    "upper_bound_max_control = np.array(mean_max_control)+np.array(std_random_control)\n",
    "\n",
    "lower_bound_random_local = np.array(mean_random_local)-np.array(std_random_local)\n",
    "upper_bound_random_local = np.array(mean_random_local)+np.array(std_random_local)\n",
    "lower_bound_random_control = np.array(mean_random_control)-np.array(std_random_control)\n",
    "upper_bound_random_control = np.array(mean_random_control)+np.array(std_random_control)\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_max_local, label=\"max local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"random control\")\n",
    "plt.plot(plot_range, mean_max_control, label=\"max control\")\n",
    "\n",
    "plt.fill_between(plot_range, lower_bound_random_local, upper_bound_random_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_random_control, upper_bound_random_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_max_local, upper_bound_max_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_max_control, upper_bound_max_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(plot_range, mean_random_local, label=\"random local\")\n",
    "plt.plot(plot_range, mean_random_control, label=\"rendom control\")\n",
    "\n",
    "plt.fill_between(plot_range, lower_bound_random_local, upper_bound_random_local, \n",
    "                 label='{}'.format(\"random local std\"), alpha=0.2)\n",
    "plt.fill_between(plot_range, lower_bound_random_control, upper_bound_random_control, \n",
    "                 label='{}'.format(\"random control std\"), alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plot_results(\n",
    "#    (input_vars_to_max_impacts, {'mean_label': 'max_local_nudges'}), \n",
    "#    xlabel=\"number of input variables\", ylabel = \"absolute impact\", \n",
    "#    title=\"maximum local non-causal additive nudges\", std_of_batches=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from probability_distributions import produce_distribution_with_entropy_evolutionary as get_entropy_dist\n",
    "\n",
    "shape = tuple([5,5,5,5,5])\n",
    "entropy_size = np.log2(5**5) * 0.95\n",
    "print(\"the wanted entropy {}\".format(entropy_size))\n",
    "dist = get_entropy_dist(shape, entropy_size, 500)\n",
    "print(entropy(dist, base=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cond_nudge = np.array([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6]\n",
    "    ],\n",
    "    [\n",
    "        [7,8,9],\n",
    "        [10,11,12]\n",
    "    ]\n",
    "])\n",
    "a = np.take(cond_nudge, 1, axis=2).flatten()\n",
    "print(range(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
