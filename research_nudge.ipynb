{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import json\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "import powerlaw\n",
    "from jointpdf.jointpdf import JointProbabilityMatrix\n",
    "from jointpdf.jointpdf import FullNestedArrayOfProbabilities\n",
    "\n",
    "from probability_distributions import JointProbabilityMatrixExtended\n",
    "import probability_distributions\n",
    "from probability_distributions import ProbabilityArray\n",
    "from simulate import find_mean_std_mse\n",
    "import nudge\n",
    "\n",
    "import information_theory\n",
    "from information_theory import calculate_mutual_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_distribution(shape, method, arguments=None):\n",
    "    if method=='random_biased':\n",
    "        distribution = np.random.random(shape)\n",
    "        distribution = distribution/np.sum(distribution)\n",
    "        return distribution\n",
    "    elif method=='random_dirichlet':\n",
    "        return probability_distributions.compute_joint_uniform_random(shape)\n",
    "    elif method=='fixed_entropy':\n",
    "        return probability_distributions.generate_probability_distribution_with_certain_entropy(\n",
    "            shape, arguments['entropy_size']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('provide a valid method')\n",
    "        \n",
    "def calculate_amount_and_size_nudges(total_nudge_size, number_of_states, threshold=10):\n",
    "    \"\"\"\n",
    "    Calculate the nudge size and the number of nudges that need to be performed \n",
    "    to nudge a variable with the total nudge size. Assuming the distribution is\n",
    "    not too peaked, in other words, not too many states should have a probability\n",
    "    that is 10 times smaller than normal.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    total_nudge_size: a number\n",
    "        How much the variable need to be nudged\n",
    "    number_of_states: a number\n",
    "        The total number of states of the joint distribution\n",
    "    threshold: a float \n",
    "        Indicating how much smaller than uniform the value of the number\n",
    "        at the 95-99 percentile of points is. Defaults to 10 \n",
    "        \n",
    "    Returns: local_nudge, number_of_nudges\n",
    "    -------\n",
    "    local_nudge: a number \n",
    "        The size of the local nudge to be performed on the joint distribution\n",
    "    number_of_nudges: integer\n",
    "        How often the nudge need to be performed\n",
    "    \n",
    "    \"\"\"\n",
    "    assumed_min_size = 1.0/threshold\n",
    "    max_local_nudge = min(total_nudge_size, 0.1/number_of_states)\n",
    "    number_of_nudges = int(np.ceil(total_nudge_size/max_local_nudge))\n",
    "    local_nudge = total_nudge_size/float(number_of_nudges) \n",
    "    return local_nudge, number_of_nudges\n",
    "\n",
    "def percentage_max_entropy(shape, percentage):\n",
    "    \"\"\" \n",
    "    Return the percentage of the max-entropy given the shape\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    shape: iterable\n",
    "    percentage: float\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.log2(reduce(lambda x,y: x*y, shape)) * percentage\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1:\n",
    "\n",
    "How do mutual information and nudge impact relate for one input variable and one output variable.\n",
    "The joint of the input and output variables is generated randomly biased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_of_nudge_1d(distribution, nudge_size):\n",
    "    \"\"\"\n",
    "    Nudge the input variable and calculate the effect on the output variable\n",
    "    (the KL-devergence of the output variable)\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    distribution: a numpy array\n",
    "        It should represent the joint probability distribution of 1 input\n",
    "        (the first axis) and 1 output variable (the second axis).\n",
    "    nudge_size: a number\n",
    "    \n",
    "    Returns: a number\n",
    "    \"\"\"\n",
    "    probability_array_old = ProbabilityArray(distribution)\n",
    "    marginal_variable_old = probability_array_old.marginalize(set([0]))\n",
    "    marginal_function_old = probability_array_old.marginalize(set([1]))\n",
    "    conditional_joint_old, marginal_labels_old, conditional_labels_old = (\n",
    "        probability_array_old.find_conditional(set([1]), set([0]))\n",
    "    )\n",
    "    marginal_variable_nudged, nudges_states = nudge.nudge(\n",
    "        marginal_variable_old, nudge_size\n",
    "    )\n",
    "    joint_new = ProbabilityArray(probability_distributions.compute_joint(\n",
    "        marginal_variable_nudged, conditional_joint_old, conditional_labels_old\n",
    "    ))\n",
    "    marginal_function_new = joint_new.marginalize(set([1]))  \n",
    "    kl_variable = entropy(marginal_variable_old, marginal_variable_nudged)\n",
    "    kl_function = entropy(marginal_function_old, marginal_function_new) \n",
    "    return kl_variable, kl_function\n",
    "\n",
    "pdf = JointProbabilityMatrix(1, 10, 'random')\n",
    "pdf.append_variables_with_target_mi(1, 0.5)\n",
    "distribution = pdf.joint_probabilities.joint_probabilities\n",
    "effect_of_nudge_1d(distribution, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see whether and how mutual information and response to the nudge co-depend\n",
    "NUMBER_OF_STATES, NUDGE_SIZE = 6, 0.01\n",
    "mutual_information_sizes = np.arange(0.05, 1, 0.05)\n",
    "sample_size = 1\n",
    "effect_nudge_given_mi = {}\n",
    "for mutual_information_size in mutual_information_sizes:\n",
    "    print(\"the mutual information size is {}\".format(mutual_information_size))\n",
    "    nudge_effects = []\n",
    "    for sample in range(sample_size):\n",
    "        pdf = JointProbabilityMatrix(1, NUMBER_OF_STATES, 'random')\n",
    "        pdf.append_variables_with_target_mi(1, mutual_information_size)\n",
    "        distribution = pdf.joint_probabilities.joint_probabilities\n",
    "        nudge_effects.append(effect_of_nudge_1d(distribution, 0.01)[1])\n",
    "        \n",
    "    effect_nudge_given_mi[mutual_information_size] = nudge_effects\n",
    "    #with open(\"back_up2.json\", 'w') as f:\n",
    "    #    json.dump(effect_nudge_given_mi, f)\n",
    "    \n",
    "#print(effect_nudge_given_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "\n",
    "with open(\"data_1_random_input_1_output_diff_MI.json\", 'r') as f:\n",
    "    first = json.load(f)\n",
    "\n",
    "effect_nudge_given_mi = {}\n",
    "    \n",
    "for k, v in first.items():\n",
    "    effect_nudge_given_mi[float(k)] = v\n",
    "    \n",
    "average_effect_nudge_dict = {k:np.mean(v) for k,v in effect_nudge_given_mi.items()}\n",
    "standard_deviation_effect_nudge_dict = {k:np.std(v) for k,v in effect_nudge_given_mi.items()}\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "batches_mean_squared_error = {}\n",
    "for mi, effect_nudge_list in effect_nudge_given_mi.items():\n",
    "    batched_estimates = []\n",
    "    for i in range(len(effect_nudge_list)/BATCH_SIZE):\n",
    "        batched_estimates.append(\n",
    "            np.mean(effect_nudge_list[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "        )\n",
    "    batches_mean_squared_error[mi] = np.std(batched_estimates)\n",
    "\n",
    "batch_std_effect_nudge_ord_dict = collections.OrderedDict(\n",
    "    sorted(batches_mean_squared_error.items(), key= lambda x: x[0])\n",
    ")    \n",
    "average_effect_nudge_ord_dict = collections.OrderedDict(\n",
    "    sorted(average_effect_nudge_dict.items(), key= lambda x: x[0])\n",
    ")\n",
    "std_effect_nudge_ord_dict = collections.OrderedDict(\n",
    "    sorted(standard_deviation_effect_nudge_dict.items(), key= lambda x: x[0])\n",
    ")\n",
    "\n",
    "mi_values = average_effect_nudge_ord_dict.keys()\n",
    "mean_effect_nudge = average_effect_nudge_ord_dict.values()\n",
    "std_effect_nudge = std_effect_nudge_ord_dict.values()\n",
    "batch_std_effect_nudge = batch_std_effect_nudge_ord_dict.values()\n",
    "\n",
    "xlabel = \"mutual information\"\n",
    "ylabel = \"effect of the nudge\"\n",
    "title = \"Effect of a nudge on input variable on output variable for certain MI\"\n",
    "plotting.plot_mean_and_confidence(\n",
    "    mi_values, mean_effect_nudge, std_effect_nudge,\n",
    "    \"std\", xlabel, ylabel, title\n",
    ")\n",
    "plotting.plot_mean_and_confidence(\n",
    "    mi_values, mean_effect_nudge, batch_std_effect_nudge,\n",
    "    \"MSE\", xlabel, ylabel, title\n",
    ")\n",
    "\n",
    "mi_values1, mean_effect_nudge1, std_effect_nudge1, batch_std_effect_nudge1 = (\n",
    "    find_mean_std_mse(effect_nudge_given_mi, batch_size=30)\n",
    ")\n",
    "\n",
    "#print(np.allclose(mi_values1, mi_values))\n",
    "#print(np.allclose(mean_effect_nudge1, mean_effect_nudge))\n",
    "#print(np.allclose(std_effect_nudge1, std_effect_nudge))\n",
    "#print(np.allclose(batch_std_effect_nudge1, batch_std_effect_nudge))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "Research the relation between the impact of a local nudge and the number of input variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2A\n",
    "\n",
    "See what the distance is between 2 randomly generated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_states, number_of_variables = 5, 4\n",
    "shape = tuple([number_of_states]*(number_of_variables+1))\n",
    "total_nudge_size = 0.01\n",
    "total_number_of_states = number_of_states**number_of_variables\n",
    "max_local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "    total_nudge_size, total_number_of_states\n",
    ")\n",
    "\n",
    "total_nudge_sizes = []\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    #distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "    distribution = ProbabilityArray(generate_distribution(\n",
    "        shape, 'fixed_entropy', \n",
    "        {\"entropy_size\":percentage_max_entropy(shape, 0.5)}\n",
    "    ))\n",
    "    function_labels, label_nudged_variable = set([number_of_variables]), 0\n",
    "    input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    marginal_nudged_old = ProbabilityArray(input_distribution).marginalize(\n",
    "        set([label_nudged_variable])\n",
    "    ) \n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, 0, max_local_nudge, number_of_nudges\n",
    "    )\n",
    "    marginal_nudged_new = ProbabilityArray(new_input_distribution).marginalize(\n",
    "        set([label_nudged_variable])\n",
    "    ) \n",
    "    total_nudge_sizes.append(np.sum(np.absolute(marginal_nudged_old-marginal_nudged_new)))\n",
    "    \n",
    "print(np.mean(total_nudge_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2B \n",
    "\n",
    "The actual experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "    \n",
    "def calculate_nudge_impact(number_of_variables, number_of_states, total_nudge_size):\n",
    "    \"\"\" \n",
    "    For now calculate the impact of a local non-causal nudge on the input variables\n",
    "    on the completely causally determined output variable\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    number_of_variables: integer\n",
    "    number_of_states: integer\n",
    "    total_nudge_size: number\n",
    "    \n",
    "    \"\"\"\n",
    "    total_number_of_states = number_of_states**number_of_variables\n",
    "    max_local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "    shape = tuple([number_of_states] * (number_of_variables+1))\n",
    "    distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "    function_labels, label_nudged_variable = set([number_of_variables]), 0\n",
    "    input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, 0, max_local_nudge, number_of_nudges\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, function_labels,\n",
    "                                      new_input_distribution)\n",
    "\n",
    "number_of_variables = 1\n",
    "NUMBER_OF_STATES = 5\n",
    "TOTAL_NUDGE_SIZE = 0.005    \n",
    "nudge_impact = calculate_nudge_impact(number_of_variables, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE)\n",
    "print(nudge_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the average \"distance\" (KL-divergence) between randomly (probability masses states are distributed according to Dirichlet distribution) generated distributions. The distance decreases, since, the number of\n",
    "states that are close to uniform increases as the number of states for a distribution grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_states, number_of_distributions = 5, 20\n",
    "difference_distributions = []\n",
    "for number_of_variables in range(1, 7, 1):\n",
    "    marginal_outputs = []\n",
    "    shape = tuple([number_of_states]*(number_of_variables+1))\n",
    "    for i in range(number_of_distributions):\n",
    "        distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "        function_label, label_nudged_variable = number_of_variables, 0\n",
    "        marginal_outputs.append(distribution.marginalize(set([function_label])))\n",
    "\n",
    "    kl_divergences = []\n",
    "    for i in range(int(number_of_distributions/2)):\n",
    "        kl_divergences.append(entropy(marginal_outputs[i].flatten(), marginal_outputs[i+1].flatten()))\n",
    "\n",
    "    difference_distributions.append(np.mean(kl_divergences))\n",
    "    print(np.mean(kl_divergences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "The impact of a nudge on an input variable (with no causal impact on the other input variables)\n",
    "on the output variable, for different number of input variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 7, 5, 0.01\n",
    "NUMBER_OF_SAMPLES = 20\n",
    "impact_nudge_dict = {}\n",
    "\n",
    "for number_of_variables in range(1, MAX_NUMBER_OF_VARIABLES, 1):\n",
    "    print(number_of_variables)\n",
    "    impact_nudges = []\n",
    "    for i in range(NUMBER_OF_SAMPLES):\n",
    "        print(\"sample number {}\".format(i))\n",
    "        impact_nudges.append(\n",
    "            calculate_nudge_impact(number_of_variables, \n",
    "                                   NUMBER_OF_STATES, \n",
    "                                   TOTAL_NUDGE_SIZE)\n",
    "        )\n",
    "    \n",
    "    impact_nudge_dict[number_of_variables] = impact_nudges\n",
    "    #with open(\"back_up_number_variables_output.json\", 'w') as f:\n",
    "    #    json.dump(impact_nudge_dict, f)\n",
    "\n",
    "#print(impact_nudge_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_range, mean_impact_nudge, std_impact_nudge, batches_std = (\n",
    "    find_mean_std_mse(impact_nudge_dict, 10)\n",
    ")\n",
    "\n",
    "xlabel = \"number of input variables\"\n",
    "ylabel = \"impact of the nudge\"\n",
    "title = \"Impact of a nudge on 1 input variable on output variable for different amount of input variables\"\n",
    "plotting.plot_mean_and_confidence(\n",
    "    variable_range, mean_impact_nudge, std_impact_nudge,\n",
    "    \"std\", xlabel, ylabel, title\n",
    ")\n",
    "\n",
    "plotting.plot_mean_and_confidence(\n",
    "    variable_range, mean_impact_nudge, batches_std,\n",
    "    \"std of batched means\", xlabel, ylabel, title\n",
    ")\n",
    "\n",
    "plotting.plot_mean_and_confidence(\n",
    "    variable_range, np.array(mean_impact_nudge)/np.array(difference_distributions), batches_std,\n",
    "    \"std of batched means\", xlabel, \"normalised impact of the nudge\", \"normalised values\"\n",
    ")\n",
    "\n",
    "fit = powerlaw.Fit(mean_impact_nudge)\n",
    "print(fit.distribution_compare(\"power_law\", \"exponential\"))\n",
    "print(fit.distribution_compare(\"power_law\", \"lognormal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "The relation between nudge impact and the mutual information between the output variable and\n",
    "the nudged input variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES, TOTAL_NUDGE_SIZE = 2, 5, 0.01\n",
    "NUMBER_OF_SAMPLES = 3\n",
    "\n",
    "local_nudge, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "    TOTAL_NUDGE_SIZE, NUMBER_OF_STATES**NUMBER_OF_VARIABLES\n",
    ")\n",
    "impact_nudges_and_mi = []\n",
    "for i in range(NUMBER_OF_SAMPLES):\n",
    "    if i%20==0 and i != 0:\n",
    "        print(\"sample number {}\".format(i))\n",
    "    \n",
    "    #calculate the distribution\n",
    "    distribution = ProbabilityArray(generate_distribution(shape, 'random_dirichlet'))\n",
    "    function_label, label_nudged_variable = NUMBER_OF_VARIABLES, 0\n",
    "    function_labels = set([function_label])\n",
    "    input_variable_labels = set(range(len(distribution.probability_distribution.shape))) - function_labels\n",
    "    \n",
    "    #calculate mutual information\n",
    "    mutual_information = calculate_mutual_information(distribution, \n",
    "                                                      set([function_label]),\n",
    "                                                      set([label_nudged_variable]))\n",
    "    \n",
    "    #calculate_nudge_impact\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    nudge_impacts = []\n",
    "    for _ in range(5):\n",
    "        new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "            input_distribution, 0, local_nudge, number_of_nudges\n",
    "        )\n",
    "        nudge_impacts.append(nudge.impact_nudge_causal_output(\n",
    "            distribution, function_labels, new_input_distribution\n",
    "        ))\n",
    "    nudge_impact = np.mean(nudge_impacts)\n",
    "    impact_nudges_and_mi.append((nudge_impact, mutual_information))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "impact_nudges = [item[0] for item in impact_nudges_and_mi] \n",
    "mutual_information_sizes = [item[1] for item in impact_nudges_and_mi]\n",
    "plt.plot(mutual_information_sizes, impact_nudges, 'o')\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Experiment:\n",
    "Change the output so as to minimize the nudge impact. See what happens with the mutual information between\n",
    "the nudged variable and the output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_nudge_impact(distribution, output_label, nudge_label, number_of_nudges, local_nudge_size):\n",
    "    input_variable_labels = (set(range(len(distribution.probability_distribution.shape))) -\n",
    "                             set([output_label]))\n",
    "    input_distribution = distribution.marginalize(input_variable_labels)\n",
    "    \n",
    "    new_input_distribution = nudge.nudge_distribution_local_non_causal(\n",
    "        input_distribution, nudge_label, local_nudge_size, number_of_nudges\n",
    "    )\n",
    "    return nudge.impact_nudge_causal_output(distribution, set([output_label]),\n",
    "                                      new_input_distribution)\n",
    "\n",
    "def minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                          evaluations_per_trial, mutation_size, number_of_mutations,\n",
    "                          total_nudge_size, nudge_label):\n",
    "    \"\"\"\n",
    "    Mutate the distribution to minimize nudge impact and maximize entropy\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    initial_distribution: a numpy array\n",
    "        Representing a discrete probability distribution\n",
    "    function_label: an integer\n",
    "    nudge_size: a (small) number\n",
    "    number_of_nudges: an integer\n",
    "    \n",
    "    \"\"\"\n",
    "    total_number_of_states = reduce(lambda x, y: x*y, initial_distribution.shape)\n",
    "    local_nudge_size, number_of_nudges = calculate_amount_and_size_nudges(\n",
    "        total_nudge_size, total_number_of_states\n",
    "    )\n",
    "                             \n",
    "    distribution = initial_distribution\n",
    "    nudge_impacts = []\n",
    "    for i in range(evaluations_per_trial):\n",
    "        nudge_impacts.append(get_nudge_impact(\n",
    "            ProbabilityArray(initial_distribution), output_label, nudge_label, number_of_nudges, local_nudge_size\n",
    "        ))                        \n",
    "    prev_nudge_impact = np.mean(nudge_impacts)\n",
    "    initial_nudge_impact = prev_nudge_impact\n",
    "    #print(prev_nudge_impact)\n",
    "             \n",
    "    for i in range(number_of_trials):\n",
    "        #print(i)\n",
    "        #print(\"number of mutations {}\".format(number_of_mutations))\n",
    "        proposed_distribution = nudge.mutate_distribution_with_fixed_marginals(\n",
    "            distribution, output_label, int(number_of_mutations), mutation_size\n",
    "        ) \n",
    "        #print(\"found proposal distribution\")\n",
    "        nudge_impacts = []\n",
    "        for j in range(evaluations_per_trial):\n",
    "            nudge_impacts.append(get_nudge_impact(\n",
    "                ProbabilityArray(proposed_distribution), output_label, nudge_label,\n",
    "                number_of_nudges, local_nudge_size\n",
    "            ))\n",
    "        if np.mean(nudge_impacts) < prev_nudge_impact:\n",
    "            prev_nudge_impact = np.mean(nudge_impacts)\n",
    "            distribution = proposed_distribution\n",
    "            \n",
    "        #print(prev_nudge_impact)\n",
    "    \n",
    "    return distribution, prev_nudge_impact, initial_nudge_impact, prev_nudge_impact\n",
    "\n",
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 3, 4 \n",
    "pdf = JointProbabilityMatrix(NUMBER_OF_VARIABLES+1, NUMBER_OF_STATES, 'random')\n",
    "initial_distribution = pdf.joint_probabilities.joint_probabilities\n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "\n",
    "number_of_trials = 50\n",
    "evaluations_per_trial = 10\n",
    "mutation_size = 0.2 / (4.0**3)\n",
    "number_of_mutations = int(0.1 * 4**3)\n",
    "a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                      evaluations_per_trial, mutation_size, number_of_mutations, 0.01, 0)\n",
    "\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_VARIABLES, NUMBER_OF_STATES = 4, 5 \n",
    "output_label = NUMBER_OF_VARIABLES\n",
    "number_of_trials = 50\n",
    "evaluations_per_trial = 10\n",
    "mutation_size = 0.2 / (5.0**4)\n",
    "number_of_mutations = int(0.1 * 5**4)\n",
    "number_of_samples = 20\n",
    "\n",
    "mi_before = []\n",
    "mi_after = []\n",
    "\n",
    "impact_before = []\n",
    "impact_after = []\n",
    "\n",
    "for count in range(number_of_samples):\n",
    "    if count%2==0:\n",
    "        print(count)\n",
    "        \n",
    "    shape = [NUMBER_OF_STATES] * (NUMBER_OF_VARIABLES+1)\n",
    "    initial_distribution = generate_distribution(shape, 'random_dirichlet')\n",
    "    a=minimize_nudge_greedy(initial_distribution, output_label, number_of_trials, \n",
    "                          evaluations_per_trial, mutation_size, number_of_mutations, 0.01, 0)\n",
    "\n",
    "    impact_before.append(a[2])\n",
    "    impact_after.append(a[3])\n",
    "    mi_before.append(calculate_mutual_information(\n",
    "        ProbabilityArray(initial_distribution), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "    ))\n",
    "    mi_after.append(calculate_mutual_information(\n",
    "        ProbabilityArray(a[0]), set([0]), set([NUMBER_OF_VARIABLES])\n",
    "    ))\n",
    "    \n",
    "print(\"mean impact before {}\".format(np.mean(impact_before)))\n",
    "print(\"mean impact before {}\".format(np.mean(impact_after)))\n",
    "    \n",
    "print(\"mean mi before {}\".format(np.mean(mi_before)))\n",
    "print(\"mean mi after {}\".format(np.mean(mi_after)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mi_before)\n",
    "print(mi_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = tuple([5, 5, 5, 5, 5])\n",
    "entropy_size = percentage_max_entropy(shape, 0.5)\n",
    "dist = generate_distribution(shape, method='fixed_entropy', arguments={\"entropy_size\": entropy_size})\n",
    "print(entropy(dist.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
